{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c55c96-14f7-47ba-b243-74810b410cf4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from pydataquery import DataQuery\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from xbbg import blp\n",
    "import numpy as np\n",
    "import pytz\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "from ipywidgets import interact, Dropdown, HBox, VBox, Button, Output, Text, widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "from adjustText import adjust_text\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import sympy as sp\n",
    "import itertools\n",
    "import warnings\n",
    "import openpyxl\n",
    "import subprocess\n",
    "import time\n",
    "import pyautogui\n",
    "import pygetwindow as gw\n",
    "import pyodbc\n",
    "import ast\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec475d55-89fc-490f-9f7e-11205368f40f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_original = pd.read_parquet(\"Markit CDS.parquet/\")\n",
    "    \n",
    "    to_date = datetime.today().date()\n",
    "    from_date = df_original[\"close_date\"].iloc[-1].date()\n",
    "    \n",
    "    from_date_str = from_date.strftime('%m/%d/%Y')\n",
    "    to_date_str = to_date.strftime('%m/%d/%Y')\n",
    "    \n",
    "    conn_str = (\n",
    "        f'DRIVER={{SQL Server}};'\n",
    "        f'SERVER=BC-ODS-P1;'\n",
    "        f'DATABASE=MarkitDB;'\n",
    "        f'ApplicationIntent=ReadOnly;'\n",
    "        f'Trusted_Connection=Yes;'\n",
    "        f'Authentication=ActiveDirectoryIntegrated;'\n",
    "    )\n",
    "    \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    \n",
    "    query1 = f\"\"\"\n",
    "        DECLARE @FromDate DATE = '{from_date_str}';\n",
    "        DECLARE @ToDate DATE = '{to_date_str}';\n",
    "        \n",
    "        SELECT sc.close_date, r.ticker, c.red, c.tier, c.docclause, c.ccy, sc.tenor, sc.spread\n",
    "        FROM dbo.RedEntities r\n",
    "        INNER JOIN dbo.MarkitCurves c ON r.red = c.red\n",
    "        INNER JOIN dbo.MarkitSpreadCurve sc ON c.curve_id = sc.curve_id\n",
    "        WHERE sc.close_date >= @FromDate AND sc.close_date <= @ToDate;\n",
    "    \"\"\"\n",
    "    \n",
    "    df_new = pd.read_sql(query1, conn)\n",
    "    conn.close()\n",
    "\n",
    "    df_old = df_original[df_original[\"close_date\"]<pd.to_datetime(df_original[\"close_date\"].iloc[-1])]\n",
    "\n",
    "    df1 = pd.concat([df_old, df_new])\n",
    "    df1 = df1.drop_duplicates()\n",
    "    df1.to_parquet(\"Markit CDS.parquet\")\n",
    "except:\n",
    "    df1 = pd.read_parquet(\"Markit CDS.parquet\")\n",
    "    hello = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88addd8-9cd9-4db2-8b2a-d790d057d6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "markit_cds = list(set(df1[\"red\"]))\n",
    "markit_df1 = df1.copy()\n",
    "\n",
    "res_codes = { \"Full Restructuring\": \"CR14\", \"Modified Restructuring\": \"MR14\",\n",
    "          \"Modified-Modified Restructurin\": \"MM14\", \"No Restructuring\": \"XR14\"}\n",
    "\n",
    "excel_df = None\n",
    "all_dq = None\n",
    "all_temp_cds = None\n",
    "\n",
    "for rating_col in[\"IG\",\"HY\",\"EUR_IG\",\"EUR_HY\",\"SNRFIN\",\"SUBFIN\",\"Extras\"]:\n",
    "    dq = pd.read_excel(\"CDX Members.xlsx\", sheet_name=rating_col)\n",
    "    dq[\"Restructuring\"] = dq[\"Restructuring\"].apply(lambda x: res_codes[x])\n",
    "    dq = dq[dq[\"Actual RED Code\"].isin(markit_cds)].reset_index(drop=True).copy()\n",
    "    dq.rename(columns={\"Actual RED Code\": \"red\"}, inplace=True)\n",
    "    \n",
    "    if not \"Family\" in dq.columns:\n",
    "        dq[\"Family\"] = [rating_col]*len(dq)\n",
    "        \n",
    "    if not \"tier\" in dq.columns:\n",
    "        dq[\"tier\"] = \"SNRFOR\" if rating_col != \"SUBFIN\" else \"SUBLT2\"\n",
    "    \n",
    "    dq[\"ccy\"] = dq[\"Family\"].apply(lambda x: \"USD\" if x in [\"IG\",\"HY\"] else \"EUR\")\n",
    "    dq = dq.drop([\"5Y CDS Ticker\",\"ISIN\",\"RED Code\",\"Company Name\",\"Corp Ticker\"],axis=1)\n",
    "    \n",
    "    all_dq = pd.concat([all_dq, dq]).drop_duplicates(keep=\"first\").reset_index(drop=True).copy()\n",
    "\n",
    "unique_all_dq = all_dq.drop(\"Family\",axis=1).drop_duplicates().reset_index(drop=True).copy()\n",
    "unique_all_dq.columns = unique_all_dq.columns.str.replace(\"Restructuring\",\"docclause\")\n",
    "\n",
    "cds_df = pd.merge(left=df1, right = unique_all_dq, on=[\"red\",\"docclause\",\"tier\",\"ccy\"], how=\"inner\")\n",
    "cds_df[\"close_date\"] = pd.to_datetime(cds_df[\"close_date\"])\n",
    "cds_df = cds_df[cds_df[\"tenor\"]!=\"Spot\"]\n",
    "cds_df[\"tenor\"] = cds_df[\"tenor\"].apply(lambda x: eval(x.replace(\"y\",\"*1\").replace(\"m\",\"*(1/12)\")))\n",
    "\n",
    "cds_df[\"ticker_red_tier_ccy_docclause\"] = (cds_df[\"ticker\"].astype(str) + \"_\" + cds_df[\"red\"].astype(str) +\\\n",
    "     \"_\" + cds_df[\"tier\"].astype(str) + \"_\" + cds_df[\"ccy\"].astype(str) + \"_\" + cds_df[\"docclause\"].astype(str))\n",
    "cds_df = cds_df.drop([\"ticker\",\"red\",\"tier\",\"ccy\",\"docclause\"],axis=1)\n",
    "\n",
    "########################### Creating map for family\n",
    "f = all_dq.drop_duplicates().reset_index(drop=True).copy()\n",
    "f1 = f[\"Issuer Equity\"].astype(str) + \"_\" + f[\"red\"].astype(str) + \"_\" +\\\n",
    "f[\"tier\"].astype(str) + \"_\" + f[\"ccy\"].astype(str)  + \"_\" + f[\"Restructuring\"].astype(str)\n",
    "f2 = f[\"Family\"]\n",
    "f_dict = dict(zip(f1,f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf68035-cdde-498d-8ad9-7322fb3a7b76",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "\n",
    "issuers = list(sorted(set(cds_df[\"ticker_red_tier_ccy_docclause\"])))\n",
    "last_dt = max(cds_df[\"close_date\"])\n",
    "\n",
    "all_curves = None\n",
    "\n",
    "try:\n",
    "    all_curves = pd.read_excel(\"All CDS Curves.xlsx/\") ############## made to fail\n",
    "    for issuer in issuers:\n",
    "        df = cds_df[cds_df[\"ticker_red_tier_ccy_docclause\"]==issuer]\n",
    "        df = pd.pivot_table(df, values=\"spread\", index=\"close_date\", columns =\"tenor\")\n",
    "        \n",
    "        if not last_dt in df.index:\n",
    "            df.loc[last_dt] = [np.nan] * len(df.columns)\n",
    "        df = df.sort_index().ffill().copy()\n",
    "        df[f\"{issuer}_curve\"] = [np.nan] * len(df)\n",
    "    \n",
    "        for idx in df.index:\n",
    "            curve = df.loc[[idx],:].dropna(axis=1)\n",
    "            curve = curve.iloc[:,:-1].copy()\n",
    "            x = list((curve.columns))\n",
    "            x2 = [item**2 for item in x]\n",
    "            X = np.column_stack([x, x2])\n",
    "            Y = list(curve.iloc[0])\n",
    "    \n",
    "            if len(X) > 2:\n",
    "                model = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "                df.loc[idx,f\"{issuer}_curve\"] = str([model.params[0], model.params[1], model.params[2]])\n",
    "                \n",
    "                # x_pred = list(np.linspace(min(x), max(x),100))\n",
    "                # x_pred2 = [item**2 for item in x_pred]\n",
    "                # X_pred = np.column_stack([x_pred, x_pred2])\n",
    "                # y_pred = model.predict(sm.add_constant(X_pred))\n",
    "                # plt.plot(x, Y)\n",
    "                # plt.plot(x_pred, y_pred)\n",
    "                # title = f\"{issuer} on {str(idx.date())}\"\n",
    "                # plt.title(title)\n",
    "                # # plt.savefig(f\"Curve Plots v2/{title}.png\")\n",
    "                # plt.show()\n",
    "                # plt.close()\n",
    "                \n",
    "            else:\n",
    "                df.loc[idx,f\"{issuer}_curve\"] = str([np.nan, np.nan, np.nan])\n",
    "    \n",
    "        all_curves = pd.concat([all_curves,df.iloc[:,[-1]]],axis=1)\n",
    "    all_curves.to_excel(\"All CDS Curves.xlsx\")\n",
    "except:\n",
    "    all_curves = pd.read_excel(\"All CDS Curves.xlsx\",index_col=0, parse_dates=True)\n",
    "    hello=1\n",
    "\n",
    "all_curves1 = all_curves.copy()\n",
    "all_curves = all_curves.T.copy()\n",
    "all_curves.index.name = \"ticker_red_tier_ccy_docclause\"\n",
    "all_curves.columns = [f'CDS_{item.date()}' for item in all_curves.columns]\n",
    "all_curves = all_curves.reset_index(drop=False).copy()\n",
    "all_temp_cds = all_curves.copy()\n",
    "all_temp_cds[\"Temp\"] = (all_temp_cds[\"ticker_red_tier_ccy_docclause\"].astype(str).\\\n",
    "    str.split(\"_\", n=1).str[1].str.replace(\"_curve\", \"\", regex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac30843-b275-4f60-b8ed-89788d9c8cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_all_dq[\"Issuer Equity_red_tier_ccy_docclause\"] = (unique_all_dq[\"Issuer Equity\"].astype(str) + \"_\" + unique_all_dq[\"red\"].astype(str) +\\\n",
    "     \"_\" + unique_all_dq[\"tier\"].astype(str) + \"_\" + unique_all_dq[\"ccy\"].astype(str) + \"_\" + unique_all_dq[\"docclause\"].astype(str))\n",
    "unique_all_dq = unique_all_dq.drop([\"Issuer Equity\",\"red\",\"tier\",\"ccy\",\"docclause\"],axis=1)\n",
    "unique_all_dq[\"Temp\"] = unique_all_dq[\"Issuer Equity_red_tier_ccy_docclause\"].astype(str).str.split(\"_\", n=1).str[1]\n",
    "\n",
    "df2 = pd.merge(left=unique_all_dq, right=all_temp_cds, on=\"Temp\", how=\"inner\").drop([\"Temp\",\"ticker_red_tier_ccy_docclause\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8f4cb6-1908-474c-93bb-a6e57a366b48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markit_to_bbg_tier_map = {\"SNRFOR\": \"Sr Unsecured\", \"SUBLT2\": \"Subordinated\"}\n",
    "\n",
    "l1 = [item.split(\"_\")[0] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "l2 = [markit_to_bbg_tier_map[item.split(\"_\")[2]] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "l3 = [item.split(\"_\")[3] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "l4 = [item.split(\" \")[0] for item in df2[\"Bond Name\"]]\n",
    "bbg_bonds_dict = {}\n",
    "\n",
    "for i in range(len(l1)):\n",
    "    bbg_bonds_dict[f\"{l1[i]} Equity_{l2[i]}_{l3[i]}\"] = l4[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4309eab9-0be2-4c88-a272-4099e34a50b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ##########################################################################This Data was copied to All Bonds sheet\n",
    "# bql_list = []\n",
    "\n",
    "# fl = [f\"\"\"=BQL(\"filter(bonds(['\"\"\",\n",
    "#       f\"\"\"']), payment_rank=='\"\"\",\n",
    "#       f\"\"\"' AND crncy=='\"\"\",\n",
    "#       f\"\"\"')\", \"id_isin, id_cusip, name, maturity, amt_outstanding\")\"\"\"]\n",
    "\n",
    "# for item, key in bbg_bonds_dict.items():\n",
    "#     bql_list += [fl[0] + item.split(\"_\")[0] + fl[1] + item.split(\"_\")[1] + fl[2] + item.split(\"_\")[2] + fl[3]]\n",
    "\n",
    "    \n",
    "# bql_list = [item.replace(\"\\\\\", \"\") for item in bql_list]\n",
    "\n",
    "# workbook = openpyxl.load_workbook(r\"J:\\\\HY Basis Data.xlsx\")\n",
    "# sheet = workbook.active\n",
    "\n",
    "# for row in sheet.iter_rows():\n",
    "#     for cell in row:\n",
    "#         cell.value = None\n",
    "\n",
    "# start_col = 1\n",
    "# for item in bql_list:\n",
    "#     cell = sheet.cell(row=2, column=start_col)\n",
    "#     cell.value = item\n",
    "#     start_col += 6\n",
    "# workbook.save(r\"J:\\\\HY Basis Data.xlsx\")\n",
    "\n",
    "# file_path = r\"J:\\\\HY Basis Data.xlsx\"\n",
    "# window_title = \"HY Basis Data - Excel\"\n",
    "\n",
    "# subprocess.Popen(['start', 'excel', file_path], shell=True)\n",
    "# time.sleep(5)\n",
    "\n",
    "# excel_windows = [window for window in gw.getWindowsWithTitle('Excel')]\n",
    "\n",
    "# for window in excel_windows:\n",
    "#     if window_title in window.title:\n",
    "#         # time.sleep(0.5)\n",
    "#         window.activate()\n",
    "#         break\n",
    "\n",
    "# time.sleep(45)\n",
    "# pyautogui.hotkey('ctrl', 's')\n",
    "# time.sleep(1)\n",
    "# # pyautogui.hotkey('alt', 'f4')\n",
    "\n",
    "# time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54affce-efdf-47c5-bfd4-f9eb3af6b60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bonds_map = []\n",
    "markit_to_bbg_tier_map_reverse = dict(zip(list(markit_to_bbg_tier_map.values()), list(markit_to_bbg_tier_map.keys())))\n",
    "\n",
    "for i in range(len(l1)):\n",
    "    bonds_map += [f\"{l1[i]}_{markit_to_bbg_tier_map_reverse[l2[i]]}_{l3[i]}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037cb256-d1d8-4b81-b084-65c8d09d5624",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"All Bonds.xlsx\", sheet_name=\"All Bonds\")\n",
    "l5 = [item.split(\"_\")[0].replace(\" Equity\",\"\") + \"_\" + markit_to_bbg_tier_map_reverse[item.split(\"_\")[1]] +\\\n",
    "      \"_\" + item.split(\"_\")[2] for item in list(bbg_bonds_dict.keys())]\n",
    "l6 = list(bbg_bonds_dict.values())\n",
    "\n",
    "all_df = None\n",
    "\n",
    "for i in range(len(df.columns))[::6]:\n",
    "    x = df.iloc[:,i:i+6].dropna().copy()\n",
    "    # display(l6[int(i/6)].split(\"_\")[0])\n",
    "    # display(df.iloc[:,i:i+6].dropna(how=\"all\"))\n",
    "    if len(x) > 0:\n",
    "        x.columns = ['ID','ISIN', \"CUSIP\", 'Name', 'Maturity','Amt']\n",
    "        x[\"Issuer Equity_tier_ccy\"] = [l5[int(i/6)]] * len(x)\n",
    "        x[\"Bond Name\"] = [l6[int(i/6)]] * len(x)\n",
    "        x[\"Check Col\"] = x.apply(lambda row: row[\"Name\"].split(\" \")[0]==row[\"Bond Name\"],axis=1)\n",
    "        x = x[x[\"Check Col\"]].drop([\"Check Col\",\"Bond Name\"],axis=1)\n",
    "        all_df = pd.concat([all_df, x])\n",
    "\n",
    "all_df['Time'] = round(((pd.to_datetime(all_df['Maturity'])-datetime.now()).dt.days/365),2)\n",
    "all_df = all_df[all_df[\"Time\"]>=0]\n",
    "all_df = all_df[(all_df['Time']>=4) & (all_df['Time']<=10)]\n",
    "all_df = all_df[all_df['Amt']>=300*10**6]\n",
    "all_df = all_df.reset_index(drop=True)\n",
    "excel_df = pd.concat([excel_df, all_df])\n",
    "all_df = excel_df.copy()\n",
    "\n",
    "all_df = all_df.drop_duplicates(keep=\"first\").reset_index(drop=True).copy()\n",
    "\n",
    "########################################################################################### 144A and REGS\n",
    "\n",
    "blist = [f'/isin/{item}@BGN' for item in list(all_df[\"ISIN\"])]\n",
    "blist = blp.bdp(tickers=blist, flds=[\"144A_FLAG\",\"IS_REG_S\"])\n",
    "blist.to_parquet(\"144A.parquet\")\n",
    "blist = pd.read_parquet(\"144A.parquet\")\n",
    "blist.index = [item.rsplit(\"/\",1)[1].split(\"@\")[0] for item in blist.index]\n",
    "\n",
    "blist.columns = [\"144A\",\"REGS\"]\n",
    "blist.index.name = \"ISIN\"\n",
    "blist = blist.reset_index()\n",
    "blist[\"REGS_144A\"] = blist.apply(lambda row: f'{row[\"REGS\"]}_{row[\"144A\"]}',axis=1)\n",
    "order = [\"N_N\", \"Y_N\", \"Y_Y\", \"N_Y\"]\n",
    "\n",
    "all_df = pd.merge(left=all_df, right=blist, on=\"ISIN\", how=\"outer\")\n",
    "all_df = all_df[[item for item in all_df.columns if not item in [\"144A\",\"REGS\"]]]\n",
    "\n",
    "all_df[\"REGS_144A\"] = pd.Categorical(all_df[\"REGS_144A\"], categories=order, ordered=True)\n",
    "all_df = all_df.sort_values(by=\"REGS_144A\")\n",
    "all_df = all_df[~all_df[\"Name\"].duplicated(keep='first')].drop([\"REGS_144A\",\"Time\"],axis=1).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f17b33-0b0e-43d9-adb5-789fcd742d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [f\"/isin/{item}@BGN\" for item in list(all_df[\"ISIN\"])]\n",
    "# bbg = blp.bdh(tickers=t, flds=\"BLOOMBERG_MID_G_SPREAD\", start_date=datetime.now()-timedelta(days=365*5))\n",
    "# bbg.to_parquet(\"Test1.parquet\")\n",
    "bbg = pd.read_parquet(\"Test1.parquet\")\n",
    "\n",
    "bbg1 = bbg.copy()\n",
    "new = []\n",
    "for item in bbg1.columns:\n",
    "    new += [\"BBG_\" + item[0].replace(\"/isin/\",\"\").replace(\"@BGN\",\"\")]\n",
    "bbg1.columns = new\n",
    "bbg1.index = pd.to_datetime(bbg1.index)\n",
    "\n",
    "############################################################ choose bbg or dq sprds\n",
    "\n",
    "bbg1.columns = [item.split(\"_\")[1] for item in bbg1.columns]\n",
    "bbg1.index = [f\"Sprd_{str(item.date())}\" for item in bbg1.index]\n",
    "bbg1 = bbg1.T.copy()\n",
    "bbg1.index.name = \"ISIN\"\n",
    "bbg1 = bbg1.reset_index(drop=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32854e01-4e9d-4968-8aaf-2f12013de97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2a = df2.drop([\"Primary ISIN\",\"Bond Name\"],axis=1).copy()\n",
    "df2a[\"Issuer Equity_tier_ccy\"] = [item.split(\"_\")[0] + \"_\" + item.split(\"_\")[2] +\\\n",
    "               \"_\" + item.split(\"_\")[3] for item in df2a[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "# df2a = df2a.replace(np.nan,\"[np.nan, np.nan, np.nan]\")\n",
    "df3 = pd.merge(left=all_df, right=df2a, on=\"Issuer Equity_tier_ccy\",\\\n",
    "               how=\"inner\").drop([\"ID\",\"Amt\",\"Issuer Equity_tier_ccy\"],axis=1).copy()\n",
    "\n",
    "for dt in pd.to_datetime(bbg.index):\n",
    "    df3[f'Mat_Time_{dt.date()}'] = [((pd.to_datetime(item) - dt).days/365) for item in df3[\"Maturity\"]]\n",
    "\n",
    "df4A = df3.copy()\n",
    "dt_list = [item.replace(\"CDS_\",\"\") for item in df4A.columns if item.startswith(\"CDS_\")]\n",
    "\n",
    "# for dt in dt_list:\n",
    "#     if f\"Mat_Time_{dt}\" in df4A.columns and f\"CDS_{dt}\" in df4A.columns:\n",
    "#         df4A[f'Mat_Matched_CDS_{dt}'] = df4A[f'CDS_{dt}'].apply(lambda x: ast.\\\n",
    "#             literal_eval(x)[0] if isinstance(x,str) else np.nan) +\\\n",
    "#         df4A[f'Mat_Time_{dt}'].apply(lambda x: x) *\\\n",
    "#         df4A[f'CDS_{dt}'].apply(lambda x: ast.literal_eval(x)[1] if isinstance(x,str) else np.nan) +\\\n",
    "#         df4A[f'Mat_Time_{dt}'].apply(lambda x: x**2) *\\\n",
    "#         df4A[f'CDS_{dt}'].apply(lambda x: ast.literal_eval(x)[2] if isinstance(x,str) else np.nan)\n",
    "\n",
    "def safe_literal_eval(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x) if isinstance(x, str) else [np.nan, np.nan, np.nan]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return [np.nan, np.nan, np.nan]\n",
    "\n",
    "for dt in dt_list:\n",
    "    if f\"Mat_Time_{dt}\" in df4A.columns and f\"CDS_{dt}\" in df4A.columns:\n",
    "        cds_values = df4A[f'CDS_{dt}'].apply(safe_literal_eval)\n",
    "        mat_time = df4A[f'Mat_Time_{dt}']\n",
    "\n",
    "        df4A[f'Mat_Matched_CDS_{dt}'] = (\n",
    "            cds_values.apply(lambda x: x[0]) +\n",
    "            mat_time * cds_values.apply(lambda x: x[1]) +\n",
    "            mat_time**2 * cds_values.apply(lambda x: x[2]))\n",
    "\n",
    "df4 = df4A[[\"ISIN\",\"CUSIP\",\"Name\",\"Maturity\",\"Issuer Equity_red_tier_ccy_docclause\"] +\\\n",
    "    [col for col in df4A.columns if col.startswith(\"Mat_Matched_CDS\")]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e39702-b143-44c1-8a89-847a2e625c59",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################### Duration Data\n",
    "\n",
    "dq_bonds = ['US50077LBF22','US49456BAG68','US49456BAR24','US49456BAV36','US49456BAX91','US500255AX28','US50077LAL09','US50077LAV80','US50077LBN55','US526057CY87','US530715AJ01','US501044DV05','US48666KAY55','US48666KAZ21','US48666KBA60','US620076BT59','US626717AP72','US63938CAN83','US63938CAP32','US63938CAQ15','US651229BD74','US549271AF19','US55262CAJ99','US552676AT59','US552676AU23','US552953CJ87','US552953CK50','US55342UAM62','US55616XAM92','US58013MFQ24','US382550BJ95','US382550BK68','US382550BR12','US382550BS94','US404119CA57','US404119CC14','US404119CK30','US404119CQ00','US404119CT49','US337932AL12','US337932AP26','US345370CA64','US345370CX67','US345370DA55','US345370DB39','US35671DBJ37','US35671DCD57','US35671DCF06','US35671DCH61','US36186CBY84','US36962GXZ26','US370334CL64','US370334CT90','US37045VAH33','US37045VAY65','US37045VAZ31','US404119DB22','US404121AK12','US458140BR09','US651229BE57','US44107TBC99','US40434LAN55','US42307TAG31','US432833AF84','US437076CB65','US44106MAY84','US44106MBB72','US44107TAY29','US44107TAZ93','US651229BF23','US89352HBA68','US893830AF64','US902494AZ66','US911363AM11','US911365BL76','US911365BP80','US91324PEJ75','US911365BN33','US88947EAU47','US85172FAR01','US87264ABF12','US87264ABT16','US87264ABW45','US87264ABX28','US87264ACB98','US87264ACQ67','US87264ACV52','US87264ADT97','US87901JAH86','US88033GAV23','US88167AAR23','US88167AAS06','US88167AAT88','US962166BR41','US963320AY28','US963320AZ92','US963320BA33','US963320BC98','US963320BD71','US963320BE54','US969457BB59','US969457BM15','US969457BZ28','US969457CJ76','US988498AN16','US988498AP63','US988498AR20','XS0161100515','US931142FC22','US92343VEU44','US92343VFX73','US92343VGN82','US92343VGY48','US92343VGZ13','US925524AH30','US925524AV24','US92556HAB33','US92556HAD98','US680665AK27','US682691AA80','US682691AE03','US682691AF77','US682691AG50','US682691AJ99','US682691AK62','US682691AL46','US68389XBV64','US68389XCE31','US68389XCH61','US68389XCJ28','US69047QAC69','US674599EL59','US674599EK76','US65339KCU25','US65339KDJ60','US65339KDK34','US65339KDL17',\n",
    "'US674599DD43','US674599DE26','US674599EA94','US674599ED34','US674599EF81','US698900AG20','US75513ECR09','US78355HLC15','US78442FAZ18','US81761LAE20','US828807DT11','US716973AD41','US716973AE24','US717081EW90','US745867AM30','US745867AP60','US745867AT82','US74834LBC37','US30212PBH73','US1248EPCN14','US012873AK13','US012873AH83','US11135FAS02','US11135FBD24','US136385AE19','US134429BJ73','US126650DJ69','US00206RMM15','US126650DU15','US126650ED80','US031162DQ06','US026874DC84','US02406PBB58','US023551AM66','US023551AJ38','US097023CN34','US097023CP81','US097023CY98','US097023DC69','US097023DR39','US097023CJ22','US097023DS12','US023135AP19','US097023AU94','US023551AF16','US058498AW66','US058498AX40','US058498BA38','US07556QBT13','US08652BAB53','US071813BY49','US254709AS70','US244199BJ37','US247361ZT81','US251799AA02','US25179MBF95','US25179SAD27','US247361A329','US23331ABT51','US29273VAU44','US29273VBA70','US29278NAQ60','US30161NAX93','US30212PAR64','US29273VAT70','US29273RBE80','US28368EAD85','US28368EAE68','US292480AM22','US29273VAQ32','US292505AD65','US20030NEE76','US20030NDG34','US20030NBH35','US15089QAZ72','US15089QBA13','US15089QAY08','US00206RCP55','US15089QAP90','US00130HCG83','US15089QAX25','US205887AX04','XS2774392638','XS2655993033','XS3037720227','XS3023963534','XS3126635039','XS3106096178','XS3105513769','XS3091660194','XS2872799734','XS2870878456','XS2864439158','XS2811097075','XS2802883731','XS2826718087','XS2929387996','XS2922654418','XS2914769299','XS2904791774','XS2385393587','XS2116386132','XS2432162654','XS2247549731','XS2189766970','XS2300293003','XS2290544068','XS2056491587','XS2488809612','XS2010039894','FR001400WJR8','FR001400PAJ8','DE000A383HC1','CH0494734418','CH0591979627','DE000A4DFLQ6','US46284VAQ41','US501797AW48','US513272AD65','US513272AE49','US53219LAX73','US46284VAN10','US55617LAR33','US55617LAS16','US62482BAB80','US46284VAL53','US44332PAJ03','US46284VAF85','US37441QAA94','US428040DB25','US431318AV64','US431318AY04','US431318AZ78','US431318BC74','US431318BE31','US431318BG88','US432833AL52','US432833AN19','US432833AQ40','US432833AR23','US432833AS06','US44332PAG63','US62886HBP55','US46284VAJ08','US62886HBR12','US629377CS98','US629377CR16','US780153BV38','US780153BW11','US81211KAK60','US812127AB45','US812127AC28','US82967NBG25','US82967NBM92','US853496AG21','US853496AH04','US893830BZ10','US911365BR47','US92840VAP76','US92840VAR33','US947075AU14','US988498AL59','US780153BU54','US75606DAQ43','US737446AV69','US629377CW01','US629377CX83','US62957HAP01','US62957HAQ83','US63861CAF68','US64110LAU08','US64110LAV80','US677347CH71','US680665AN65','US68622FAB76','US68622TAB70','US737446AP91','US737446AQ74','US737446AR57','US737446AX26','US364760AQ18','US11135FBF71','US11135FBH38','US11135FBK66''US11135FBL40','US11135FBT75','US1248EPCD32','US1248EPCE15','US1248EPCK74','US1248EPCL57','US1248EPCP61','US1248EPCQ45''US1248EPCS01','US1248EPCT83','US126307BA42','US126307BB25','US103304BV23','US126307BD80','US097751CD18','US097751CB51','US00130HCC79','US01883LAD55','US01883LAH69','US03743QAQ10','US04433LAA08','US05368VAA44','US05368VAB27','US053773BH95','US053773BJ51','US053773BK25','US071734AJ60','US071734AL17','US097751AL51','US097751CA78','US097751CC35','US126307BF39','US126307BH94','US126307BK24','US224044CS42','US226373AT56','US23918KAS78','US23918KAT51','US23918KAW80','US23918KAY47','US185899AS01','US185899AR28','US12769GAA85','US12769GAD25','US131347CQ78','US143658BX94','US143658BY77','US364760AP35','US143658BZ43','US17888HAB96','US17888HAC79','US17888HAD52','US185899AL57','US185899AN14','US185899AP61','US185899AQ45','US143658CA82']\n",
    "\n",
    "dq_bonds = list(df4[\"ISIN\"])\n",
    "all_labels = dict(zip(df4[\"ISIN\"],[f\"DB(CREDIT,HY,BOND,{item},MDUR)\" for item in df4[\"CUSIP\"]]))\n",
    "\n",
    "labels = {}\n",
    "for item in dq_bonds:\n",
    "    labels[f\"{item}_Dur\"] = all_labels[item]\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_excel(\"DQ HY Duration Data.xlsx/\",index_col=0, parse_dates=True)\n",
    "    dq = DataQuery(\n",
    "        client_id='jbAIMF2Tkp0JO3sc',\n",
    "        client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "        calendar = 'CAL_USBANK',\n",
    "    )\n",
    "    \n",
    "    job = dq.create_job(expressions = list(labels.values()))\n",
    "    dq.start_date = str((datetime.now()-timedelta(days=5*365)).date())\n",
    "    job.execute(alert_long_requests='ignore')\n",
    "    df = job.to_pivot_table()\n",
    "    df = df.T\n",
    "    df.index.name = 'Date'\n",
    "    df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "    df.columns.name = None\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    for key in labels:\n",
    "        df1[key] = df[labels[key]]\n",
    "    \n",
    "    df1 = df1[list(labels.keys())].copy()\n",
    "    clear_output(wait=False)\n",
    "    df1.dropna(axis=1, how='all', inplace=True)\n",
    "    df1.to_excel(\"DQ HY Duration Data.xlsx\")\n",
    "except:\n",
    "    df1 = pd.read_excel(\"DQ HY Duration Data.xlsx\",index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f99d405-a8e4-42ed-87f2-7eaf2e6e29d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1a = df1.copy()\n",
    "df1a = df1a.T\n",
    "df1a.index = df1a.index.str.replace(\"_Dur\",\"\")\n",
    "df1a.columns = [\"Dur_\" + str(item.date()) for item in df1a.columns]\n",
    "df1a.index.name=\"ISIN\"\n",
    "df1a = df1a.reset_index()\n",
    "\n",
    "df4B = pd.merge(left=df4, right=df1a, on=\"ISIN\", how=\"outer\")\n",
    "\n",
    "####################################################################\n",
    "\n",
    "t = [f\"/isin/{item}@BGN\" for item in list(all_df[\"ISIN\"])]\n",
    "# px = blp.bdh(tickers=t, flds=\"PX_LAST\", start_date=datetime.now()-timedelta(days=365*5))\n",
    "# px.to_parquet(\"Test2.parquet\")\n",
    "px = pd.read_parquet(\"Test2.parquet\")\n",
    "\n",
    "new = []\n",
    "for item in px.columns:\n",
    "    new += [item[0].replace(\"/isin/\",\"\").replace(\"@BGN\",\"\")]\n",
    "px.columns = new\n",
    "px = px.T\n",
    "px.columns = [\"Price_\" + str(item) for item in px.columns]\n",
    "px.index.name= \"ISIN\"\n",
    "px = px.reset_index()\n",
    "\n",
    "####################################################\n",
    "df5a = pd.merge(left=df4B, right=bbg1, on=\"ISIN\", how=\"inner\")\n",
    "last_update = max(dt_list)\n",
    "for dt in dt_list:\n",
    "    try:\n",
    "        df5a[f\"Basis_{dt}\"] = df5a[f\"Mat_Matched_CDS_{dt}\"] - df5a[f\"Sprd_{dt}\"]\n",
    "    except:\n",
    "        hello = 1\n",
    "\n",
    "df5a = pd.merge(left=df5a, right=px, on=\"ISIN\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bdac9da-dc4a-481f-8364-39fefce2d561",
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df5a.copy()\n",
    "df5 = df5[[\"ISIN\",\"CUSIP\",\"Name\",\"Maturity\",\"Issuer Equity_red_tier_ccy_docclause\"] +\\\n",
    "    [col for col in df5.columns if last_update in col or \"Basis_\" in col]].copy()\n",
    "\n",
    "####################################### Zscore and 1Y High/Low Calc\n",
    "\n",
    "dfz = df5[[\"ISIN\"] + [item for item in df5.columns if \"Basis\" in item]]\n",
    "dfz = dfz.set_index(\"ISIN\").T\n",
    "dfz.index = [pd.to_datetime(item.split(\"_\")[1]).date() for item in dfz.index]\n",
    "dfz = dfz.sort_index()\n",
    "\n",
    "all_z_df = None\n",
    "for period in [3*22, 6*22, 12*22]:\n",
    "    x = ((dfz-dfz.rolling(period, min_periods = int(0.6*period)).mean())/dfz.rolling(period,\\\n",
    "                  min_periods = int(0.6*period)).std()).iloc[[-1],:].copy()\n",
    "    x.index = [f'ZScore_{int(period/22)}M']\n",
    "    all_z_df = pd.concat([all_z_df , x])\n",
    "\n",
    "max_1y = pd.DataFrame(dfz.iloc[-12*22:,:].max()).T\n",
    "max_1y.index = [f'Basis 1Y High']\n",
    "min_1y = pd.DataFrame(dfz.iloc[-12*22:,:].min()).T\n",
    "min_1y.index = [f'Basis 1Y Low']\n",
    "\n",
    "all_z_df = pd.concat([all_z_df , max_1y, min_1y])\n",
    "all_z_df = all_z_df.T\n",
    "all_z_df = all_z_df.reset_index()\n",
    "\n",
    "df6 = pd.merge(left=df5.drop([col for col in df5.columns if col.\\\n",
    "    startswith(\"Basis_\") and not last_update in col],axis=1),\\\n",
    "               right=all_z_df, on=\"ISIN\", how=\"inner\").drop([\"CUSIP\",\"Maturity\"],axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f8752c40-6c16-478d-920e-43ae34c6bc58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISIN</th>\n",
       "      <th>Name</th>\n",
       "      <th>Issuer Equity_red_tier_ccy_docclause</th>\n",
       "      <th>Mat_Matched_CDS_2025-08-28</th>\n",
       "      <th>Sprd_2025-08-28</th>\n",
       "      <th>Basis_2025-08-28</th>\n",
       "      <th>Price_2025-08-28</th>\n",
       "      <th>ZScore_3M</th>\n",
       "      <th>ZScore_6M</th>\n",
       "      <th>ZScore_12M</th>\n",
       "      <th>Basis 1Y High</th>\n",
       "      <th>Basis 1Y Low</th>\n",
       "      <th>Family</th>\n",
       "      <th>CDS RED Code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>US00108WAM29</td>\n",
       "      <td>AEP 2.1 07/01/30</td>\n",
       "      <td>AEP US_027A8A_SNRFOR_USD_XR14</td>\n",
       "      <td>32.159617</td>\n",
       "      <td>69.269</td>\n",
       "      <td>-37.109383</td>\n",
       "      <td>90.173</td>\n",
       "      <td>0.820925</td>\n",
       "      <td>1.257847</td>\n",
       "      <td>0.768501</td>\n",
       "      <td>-30.047945</td>\n",
       "      <td>-72.097946</td>\n",
       "      <td>IG</td>\n",
       "      <td>027A8A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>US00108WAP59</td>\n",
       "      <td>AEP 4.7 05/15/32</td>\n",
       "      <td>AEP US_027A8A_SNRFOR_USD_XR14</td>\n",
       "      <td>40.998147</td>\n",
       "      <td>88.334</td>\n",
       "      <td>-47.335853</td>\n",
       "      <td>99.606</td>\n",
       "      <td>0.348617</td>\n",
       "      <td>0.928011</td>\n",
       "      <td>0.355185</td>\n",
       "      <td>-29.837407</td>\n",
       "      <td>-78.951169</td>\n",
       "      <td>IG</td>\n",
       "      <td>027A8A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>US00108WAR16</td>\n",
       "      <td>AEP 5.4 06/01/33</td>\n",
       "      <td>AEP US_027A8A_SNRFOR_USD_XR14</td>\n",
       "      <td>45.342848</td>\n",
       "      <td>107.026</td>\n",
       "      <td>-61.683152</td>\n",
       "      <td>102.253</td>\n",
       "      <td>-0.832529</td>\n",
       "      <td>0.325452</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>-44.876745</td>\n",
       "      <td>-86.318869</td>\n",
       "      <td>IG</td>\n",
       "      <td>027A8A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>US00108WAT71</td>\n",
       "      <td>AEP 5.7 05/15/34</td>\n",
       "      <td>AEP US_027A8A_SNRFOR_USD_XR14</td>\n",
       "      <td>48.931880</td>\n",
       "      <td>117.371</td>\n",
       "      <td>-68.439120</td>\n",
       "      <td>103.164</td>\n",
       "      <td>-0.058889</td>\n",
       "      <td>0.609113</td>\n",
       "      <td>-0.150425</td>\n",
       "      <td>-45.108329</td>\n",
       "      <td>-94.395472</td>\n",
       "      <td>IG</td>\n",
       "      <td>027A8A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>US00130HCC79</td>\n",
       "      <td>AES 3.95 07/15/30</td>\n",
       "      <td>AES US_0A143H_SNRFOR_USD_XR14</td>\n",
       "      <td>101.538316</td>\n",
       "      <td>111.291</td>\n",
       "      <td>-9.752684</td>\n",
       "      <td>96.350</td>\n",
       "      <td>-0.708534</td>\n",
       "      <td>-0.101765</td>\n",
       "      <td>-0.325755</td>\n",
       "      <td>17.545906</td>\n",
       "      <td>-32.349106</td>\n",
       "      <td>IG</td>\n",
       "      <td>0A143H</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>US969457CL23</td>\n",
       "      <td>WMB 4.8 11/15/29</td>\n",
       "      <td>WMB US_9FFD9C_SNRFOR_USD_XR14</td>\n",
       "      <td>47.203524</td>\n",
       "      <td>68.571</td>\n",
       "      <td>-21.367476</td>\n",
       "      <td>101.746</td>\n",
       "      <td>-0.488983</td>\n",
       "      <td>0.224304</td>\n",
       "      <td>-0.380221</td>\n",
       "      <td>-5.345078</td>\n",
       "      <td>-34.607029</td>\n",
       "      <td>IG</td>\n",
       "      <td>9FFD9C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1103</th>\n",
       "      <td>US969457CP37</td>\n",
       "      <td>WMB 5.6 03/15/35</td>\n",
       "      <td>WMB US_9FFD9C_SNRFOR_USD_XR14</td>\n",
       "      <td>90.249625</td>\n",
       "      <td>104.755</td>\n",
       "      <td>-14.505375</td>\n",
       "      <td>103.023</td>\n",
       "      <td>-0.148177</td>\n",
       "      <td>-0.028139</td>\n",
       "      <td>-0.387038</td>\n",
       "      <td>2.305637</td>\n",
       "      <td>-29.315063</td>\n",
       "      <td>IG</td>\n",
       "      <td>9FFD9C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>US969457CR92</td>\n",
       "      <td>WMB 4 ⅝ 06/30/30</td>\n",
       "      <td>WMB US_9FFD9C_SNRFOR_USD_XR14</td>\n",
       "      <td>53.191224</td>\n",
       "      <td>79.037</td>\n",
       "      <td>-25.845776</td>\n",
       "      <td>100.660</td>\n",
       "      <td>-0.419737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.562432</td>\n",
       "      <td>-32.830373</td>\n",
       "      <td>IG</td>\n",
       "      <td>9FFD9C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1105</th>\n",
       "      <td>US983024AG50</td>\n",
       "      <td>PFE 6 ½ 02/01/34</td>\n",
       "      <td>PFE US_7I8789_SNRFOR_USD_XR14</td>\n",
       "      <td>53.339698</td>\n",
       "      <td>65.327</td>\n",
       "      <td>-11.987302</td>\n",
       "      <td>112.338</td>\n",
       "      <td>0.276324</td>\n",
       "      <td>0.917350</td>\n",
       "      <td>0.609999</td>\n",
       "      <td>-4.156601</td>\n",
       "      <td>-30.602879</td>\n",
       "      <td>IG</td>\n",
       "      <td>7I8789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1106</th>\n",
       "      <td>US983919AK78</td>\n",
       "      <td>AMD 2 ⅜ 06/01/30</td>\n",
       "      <td>AMD US_007G93_SNRFOR_USD_XR14</td>\n",
       "      <td>36.706092</td>\n",
       "      <td>42.622</td>\n",
       "      <td>-5.915908</td>\n",
       "      <td>92.595</td>\n",
       "      <td>0.042476</td>\n",
       "      <td>0.390731</td>\n",
       "      <td>0.404550</td>\n",
       "      <td>0.667001</td>\n",
       "      <td>-25.561408</td>\n",
       "      <td>IG</td>\n",
       "      <td>007G93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>752 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              ISIN               Name Issuer Equity_red_tier_ccy_docclause  \\\n",
       "187   US00108WAM29   AEP 2.1 07/01/30        AEP US_027A8A_SNRFOR_USD_XR14   \n",
       "188   US00108WAP59   AEP 4.7 05/15/32        AEP US_027A8A_SNRFOR_USD_XR14   \n",
       "189   US00108WAR16   AEP 5.4 06/01/33        AEP US_027A8A_SNRFOR_USD_XR14   \n",
       "190   US00108WAT71   AEP 5.7 05/15/34        AEP US_027A8A_SNRFOR_USD_XR14   \n",
       "191   US00130HCC79  AES 3.95 07/15/30        AES US_0A143H_SNRFOR_USD_XR14   \n",
       "...            ...                ...                                  ...   \n",
       "1102  US969457CL23   WMB 4.8 11/15/29        WMB US_9FFD9C_SNRFOR_USD_XR14   \n",
       "1103  US969457CP37   WMB 5.6 03/15/35        WMB US_9FFD9C_SNRFOR_USD_XR14   \n",
       "1104  US969457CR92   WMB 4 ⅝ 06/30/30        WMB US_9FFD9C_SNRFOR_USD_XR14   \n",
       "1105  US983024AG50   PFE 6 ½ 02/01/34        PFE US_7I8789_SNRFOR_USD_XR14   \n",
       "1106  US983919AK78   AMD 2 ⅜ 06/01/30        AMD US_007G93_SNRFOR_USD_XR14   \n",
       "\n",
       "      Mat_Matched_CDS_2025-08-28  Sprd_2025-08-28  Basis_2025-08-28  \\\n",
       "187                    32.159617           69.269        -37.109383   \n",
       "188                    40.998147           88.334        -47.335853   \n",
       "189                    45.342848          107.026        -61.683152   \n",
       "190                    48.931880          117.371        -68.439120   \n",
       "191                   101.538316          111.291         -9.752684   \n",
       "...                          ...              ...               ...   \n",
       "1102                   47.203524           68.571        -21.367476   \n",
       "1103                   90.249625          104.755        -14.505375   \n",
       "1104                   53.191224           79.037        -25.845776   \n",
       "1105                   53.339698           65.327        -11.987302   \n",
       "1106                   36.706092           42.622         -5.915908   \n",
       "\n",
       "      Price_2025-08-28  ZScore_3M  ZScore_6M  ZScore_12M  Basis 1Y High  \\\n",
       "187             90.173   0.820925   1.257847    0.768501     -30.047945   \n",
       "188             99.606   0.348617   0.928011    0.355185     -29.837407   \n",
       "189            102.253  -0.832529   0.325452    0.050654     -44.876745   \n",
       "190            103.164  -0.058889   0.609113   -0.150425     -45.108329   \n",
       "191             96.350  -0.708534  -0.101765   -0.325755      17.545906   \n",
       "...                ...        ...        ...         ...            ...   \n",
       "1102           101.746  -0.488983   0.224304   -0.380221      -5.345078   \n",
       "1103           103.023  -0.148177  -0.028139   -0.387038       2.305637   \n",
       "1104           100.660  -0.419737        NaN         NaN     -19.562432   \n",
       "1105           112.338   0.276324   0.917350    0.609999      -4.156601   \n",
       "1106            92.595   0.042476   0.390731    0.404550       0.667001   \n",
       "\n",
       "      Basis 1Y Low Family CDS RED Code  \n",
       "187     -72.097946     IG       027A8A  \n",
       "188     -78.951169     IG       027A8A  \n",
       "189     -86.318869     IG       027A8A  \n",
       "190     -94.395472     IG       027A8A  \n",
       "191     -32.349106     IG       0A143H  \n",
       "...            ...    ...          ...  \n",
       "1102    -34.607029     IG       9FFD9C  \n",
       "1103    -29.315063     IG       9FFD9C  \n",
       "1104    -32.830373     IG       9FFD9C  \n",
       "1105    -30.602879     IG       7I8789  \n",
       "1106    -25.561408     IG       007G93  \n",
       "\n",
       "[752 rows x 14 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df7 = df6.drop(f\"Dur_{last_update}\",axis=1).copy()\n",
    "df7[\"Family\"] = df7[\"Issuer Equity_red_tier_ccy_docclause\"].apply(lambda x: f_dict[x])\n",
    "df7[\"CDS RED Code\"] =  df7[\"Issuer Equity_red_tier_ccy_docclause\"].apply(lambda x: x.split(\"_\")[1])\n",
    "df7[df7[\"Family\"]==\"IG\"]#.drop("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "810b9e5b-6ccc-4821-bac2-c72f2c44c4e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ################################################## Adding IG/HY\n",
    "# blist = [f\"/isin/{item}@BGN\" for item in list(df6[\"ISIN\"])]\n",
    "# ig_hy = blp.bdp(tickers=blist, flds=\"BB_COMPSTE_RATING_IG_HY_INDCTR\")\n",
    "# ig_hy.to_parquet(\"Test3.parquet\")\n",
    "# ig_hy = pd.read_parquet(\"Test3.parquet\")\n",
    "\n",
    "# ig_hy[\"ISIN\"] = [item.replace(\"/isin/\",\"\").replace(\"@BGN\",\"\") for item in ig_hy.index]\n",
    "# ig_hy.columns = [\"IG_HY\",\"ISIN\"]\n",
    "# ig_hy = ig_hy.reset_index(drop=True).copy()\n",
    "# df6 = pd.merge(left=df6, right=ig_hy, how=\"outer\", on=\"ISIN\")\n",
    "# df6 = df6.sort_values(by=\"Eqty Name\").reset_index(drop=True).copy()\n",
    "\n",
    "################################################## \n",
    "\n",
    "df7 = df6.copy()\n",
    "df7[\"Time\"] = df7[\"Name\"].apply(lambda x: x.split(\"/\")[-1])\n",
    "df7 = df7.sort_values(by=[\"Eqty Name\",\"Time\"],ascending=True).\\\n",
    "    reset_index(drop=True).drop([\"Eqty Name\",\"Time\",\"ISIN\"],axis=1).copy()\n",
    "df7 = df7.set_index(\"Name\")\n",
    "df7.columns = df7.columns.str.replace(f'_{last_update}',\"\")\n",
    "df7.index.name = f'{pd.to_datetime(last_update).strftime(\"%d-%b\")}'\n",
    "df7 = round(df7,2)\n",
    "df7 = df7[[\"IG_HY\",\"CDS RED Code\",\"Price\",\"Sprd\",\"Mat_Matched_CDS\",\"Basis\",\n",
    "           \"Basis 1Y Low\",\"Basis 1Y High\",\"ZScore_3M\",\"ZScore_6M\",\"ZScore_12M\"]]\n",
    "\n",
    "df7[\"Name\"] = [item.split(\" \")[0] for item in df7.index]\n",
    "df7[\"Year\"] = [eval(item.split(\"/\")[-1]) for item in df7.index]\n",
    "df7 = df7.sort_values(by=[\"Name\",\"Year\"], ascending=True).drop([\"Name\",\"Year\"],axis=1).copy()\n",
    "\n",
    "px_new = blp.bdh(tickers=blist, flds=\"PX_LAST\", start_date = datetime.now()-timedelta(days=5*365))\n",
    "px_new.columns = [item.replace(\"/isin/\",\"\").replace(\"@BGN\",\"\") + \"_Price\" for item in blist]\n",
    "px_new.to_parquet(\"Test4.parquet\")\n",
    "px_new = pd.read_parquet(\"Test4.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22626355-4832-44e6-ad5b-57fec8147700",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "A = df4A[[\"ISIN\"]+[col for col in df4A.columns if col.startswith(\"Mat_Matched_CDS_\")]].set_index(\"ISIN\")\n",
    "A = A.T\n",
    "A.index = pd.to_datetime(A.index.str.replace(\"Mat_Matched_CDS_\",\"\"))\n",
    "A.columns = [f\"{item}_Mat_Matched_CDS_\" for item in A.columns]\n",
    "\n",
    "B = df5[[\"ISIN\"]+[col for col in df5.columns if col.startswith(\"Basis_\")]].set_index(\"ISIN\")\n",
    "B = B.T\n",
    "B.index = pd.to_datetime(B.index.str.replace(\"Basis_\",\"\"))\n",
    "B.columns = [f\"{item}_Basis\" for item in B.columns]\n",
    "\n",
    "C = bbg1[[\"ISIN\"]+[col for col in bbg1.columns if col.startswith(\"Sprd_\")]].set_index(\"ISIN\")\n",
    "C = C.T\n",
    "C.index = pd.to_datetime(C.index.str.replace(\"Sprd_\",\"\"))\n",
    "C.columns = [f\"{item}_G-Sprd\" for item in C.columns]\n",
    "\n",
    "D = px_new.copy()\n",
    "\n",
    "E = df1.copy()\n",
    "# E = E.set_index(\"close_date\")\n",
    "\n",
    "for item in [\"A\",\"B\",\"C\",\"D\",\"E\"]:\n",
    "    globals()[f\"{item}\"].index = pd.to_datetime(globals()[f\"{item}\"].index)\n",
    "\n",
    "F = pd.concat([A,B,C,D,E], axis=1).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9e9beb7-bc30-48b0-843e-fc36648386a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ######################### HY bonds TR data from BBG using BQL\n",
    "\n",
    "# import openpyxl\n",
    "# import subprocess\n",
    "# import time\n",
    "# import pyautogui\n",
    "# import pygetwindow as gw\n",
    "    \n",
    "# if True:\n",
    "#     bql_list = []\n",
    "    \n",
    "#     fl = [f'=BQL(\"', f\"\"\"ISIN\", \"return_series(calc_interval=range(-5y,0d,frq=d))\")\"\"\"]\n",
    "    \n",
    "#     issuers = df6[\"ISIN\"].to_list()\n",
    "    \n",
    "#     for item in issuers:\n",
    "#         bql_list += [(fl[0] + item + \" \" + fl[1])]\n",
    "        \n",
    "#     bql_list = [item.replace(\"\\\\\", \"\") for item in bql_list]\n",
    "    \n",
    "#     workbook = openpyxl.load_workbook(r\"J:\\\\55 BQL HY Bonds Rtn Data.xlsx\")\n",
    "#     sheet = workbook.active\n",
    "    \n",
    "#     for row in sheet.iter_rows():\n",
    "#         for cell in row:\n",
    "#             cell.value = None\n",
    "    \n",
    "#     start_col = 1\n",
    "#     for item in bql_list:\n",
    "#         cell = sheet.cell(row=2, column=start_col)\n",
    "#         cell.value = item\n",
    "#         start_col += 2\n",
    "#     workbook.save(r\"J:\\\\55 BQL HY Bonds Rtn Data.xlsx\")\n",
    "    \n",
    "#     file_path = r\"J:\\\\55 BQL HY Bonds Rtn Data.xlsx\"\n",
    "#     window_title = \"55 BQL HY Bonds Rtn Data - Excel\"\n",
    "    \n",
    "#     subprocess.Popen(['start', 'excel', file_path], shell=True)\n",
    "#     time.sleep(40)\n",
    "    \n",
    "#     excel_windows = [window for window in gw.getWindowsWithTitle('Excel')]\n",
    "    \n",
    "#     for check in range(2):\n",
    "#         for window in excel_windows:\n",
    "#             if window_title in window.title:\n",
    "#                 # time.sleep(0.25)\n",
    "#                 window.activate()\n",
    "#                 pyautogui.hotkey('ctrl', 's')\n",
    "#                 time.sleep(1)\n",
    "#                 pyautogui.hotkey('alt', 'f4')\n",
    "#                 # break\n",
    "    \n",
    "# time.sleep(0.5)\n",
    "\n",
    "# hy = pd.read_excel(r\"J:\\\\55 BQL HY Bonds Rtn Data.xlsx\",skiprows=1,parse_dates=True)\n",
    "# hy = hy.iloc[1:,:]\n",
    "# hy = hy[[hy.columns[0]] + [col for col in hy.columns if \"ISIN\" in col]]\n",
    "# hy.columns = [\"Date\"] + [item.replace(\" ISIN\",\"_Daily_Rtn\") for item in list(hy.columns)[1:]]\n",
    "# hy = hy.set_index(\"Date\")\n",
    "# hy.index = pd.to_datetime(hy.index)\n",
    "# hy = (1+hy).cumprod()\n",
    "# hy_col = hy.columns\n",
    "# for col in hy_col:\n",
    "#     hy[f'{col.split(\"_\")[0]} FWD_1M_Rtn'] = (hy[col].shift(-21) / hy[col] - 1) * 100\n",
    "#     hy[f'{col.split(\"_\")[0]} FWD_3M_Rtn'] = (hy[col].shift(-63) / hy[col] - 1) * 100\n",
    "#     hy[f'{col.split(\"_\")[0]} FWD_6M_Rtn'] = (hy[col].shift(-126) / hy[col] - 1) * 100\n",
    "# hy = hy[[col for col in hy.columns if \"FWD\" in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dae2dc39-d4d0-4c56-90f8-4a0f426fd117",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.concat([F, hy],axis=1).sort_index().copy()\n",
    "\n",
    "df = F.sort_index().copy()\n",
    "df.columns = df.columns.str.replace(\"_Mat_Matched_CDS_\",\" Mat. Matched CDS\").\\\n",
    "    str.replace(\"_Basis\",\" Basis\").str.replace(\"_Dur\",\" Duration\").\\\n",
    "    str.replace(\"_Price\",\" Price\").str.replace(\"_G-Sprd\",\" G-Sprd\")\n",
    "\n",
    "bond_dict = dict(zip(list(df2[\"ISIN\"]),list(df2[\"Name\"])))\n",
    "df.columns = [f\"{bond_dict[item.split(\" \",1)[0]]} {item.split(\" \",1)[1]}\"  for item in df.columns]\n",
    "df = df.dropna(how=\"all\").copy()\n",
    "df.columns = [f\"{item.split(\"/\",1)[0].rsplit(\" \",1)[0]}% due {item.\\\n",
    "    rsplit(\"/\",1)[1]}\" for item in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f519a4ae-33eb-4bd5-b2ec-603b6d9ec0c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickers_bbg = ['IBOXHY INDEX', 'IBOXIG INDEX']\n",
    "fields_bbg = ['PX_LAST', 'CONTRBTD_ZSPREAD', 'OAS_SOVEREIGN_CURVE', 'OPTION_ADJ_DURATION_SOV_CRV', 'YIELD_TO_MATURITY']\n",
    "start_date_bbg = \"2000-01-01\"\n",
    "end_date_bbg = datetime.now().strftime('%Y-%m-%d')\n",
    "df_bbg = blp.bdh(tickers=tickers_bbg, flds=fields_bbg, start_date=start_date_bbg, end_date=end_date_bbg)\n",
    "list1_bbg = ['TR', 'Z-Sprd', 'OAS', 'Dur', 'Yield']\n",
    "df_bbg.columns = ['BBG iBoxx HY ' + item for item in list1_bbg] + ['BBG iBoxx IG ' + item for item in list1_bbg] \n",
    "df_bbg.drop(['BBG iBoxx HY Dur', 'BBG iBoxx IG Yield'], axis=1, inplace=True) # First is wrong and second incomplete\n",
    "df_bbg = df_bbg.astype(float)\n",
    "\n",
    "tick = ['USGG5YR INDEX','USGG7YR INDEX','USGG10YR INDEX']\n",
    "all_x = None\n",
    "x = blp.bdh(tickers = tick, flds = 'PX_LAST', start_date = df_bbg.index[0])#, end_date = df_bbg.index[-1])\n",
    "for col in ['BBG']:# + list(set([item.split(' ',1)[0] for item in df_back.columns])):\n",
    "    x1 = x.copy()\n",
    "    x1.columns = [f'{col} US 5Y', f'{col} US 7Y', f'{col} US 10Y']\n",
    "    all_x = pd.concat([all_x,x1],axis=1)\n",
    "df_bbg = pd.concat([df_bbg,all_x],axis=1)\n",
    "\n",
    "tick = ['COA Comdty','VIX Index']\n",
    "x = blp.bdh(tickers = tick, flds='PX_LAST', start_date = df_bbg.index[0])#, end_date = df_bbg.index[-1])\n",
    "x.columns = ['BBG COA Comdty','BBG VIX Index']\n",
    "x = x.sort_index()\n",
    "df_bbg = pd.concat([df_bbg,x],axis=1)\n",
    "df_bbg.index = pd.to_datetime(df_bbg.index)\n",
    "\n",
    "backup = df.copy()\n",
    "df = pd.concat([backup, df_bbg], axis=1).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66854374-5e66-4e93-afdd-3158bda8952a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "options = sorted(backup.columns, key=lambda item: (item.split(' ', 1)[0], 2000 + \\\n",
    "            eval(item.split('due ', 1)[1].split(' ', 1)[0]) if eval(item.split('due ', 1)[1].split(' ', 1)[0])\\\n",
    "                    < 2000 else eval(item.split('due ', 1)[1].split(' ', 1)[0])))\n",
    "\n",
    "options += list(df_bbg.columns)\n",
    "fwd = [item for item in options if 'FWD_' in item]\n",
    "non_fwd = [item for item in options if not('FWD_' in item)]\n",
    "options = non_fwd + fwd\n",
    "\n",
    "time = ['All','2Y','1Y','6M','3M']\n",
    "\n",
    "#################################### Changing order of names\n",
    "o1 = [item for item in options if ((not 'FWD' in item) and ('%' in item))]\n",
    "o2 = [item for item in options if not item in o1]\n",
    "\n",
    "desired_order = [\"Price\", \"G-Sprd\", \"Basis\", \"Duration\", \"CDS\"]\n",
    "\n",
    "def reorder_items_in_chunks(items, order):\n",
    "    chunk_size = len(set([item.rsplit(' ',1)[1] for item in options if ((not 'FWD' in item) and ('%' in item))]))\n",
    "    reordered = []\n",
    "    for i in range(0, len(items), chunk_size):\n",
    "        chunk = items[i:i + chunk_size]\n",
    "        valid_items = [item for item in chunk if len(item.rsplit(' ', 1)) == 2]\n",
    "        reordered_chunk = sorted(valid_items, key=lambda x: order.index(x.rsplit(' ', 1)[1]))\n",
    "        reordered.extend(reordered_chunk)\n",
    "    return reordered\n",
    "\n",
    "o1_reordered = reorder_items_in_chunks(o1, desired_order)\n",
    "options = o1 + o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b06e1124-dd64-46be-8fef-f3fcd3eb8ea2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "############ Default bonds\n",
    "# x = df6[[\"Name\",\"ISIN\",\"Eqty Name\"]].copy()\n",
    "# issue = blp.bdp(tickers=[f\"/isin/{item}@BGN\" for item in x[\"ISIN\"]], flds=\"ISSUE_DT\")\n",
    "# issue1 = issue.copy()\n",
    "# issue1.index = issue1.index.str.replace(\"/isin/\",\"\").str.replace(\"@BGN\",\"\")\n",
    "# issue1.index.name = \"ISIN\"\n",
    "# issue1 = issue1.reset_index()\n",
    "# x = pd.merge(left=x, right=issue1, on=\"ISIN\", how=\"outer\")\n",
    "# x[\"Age\"] = round((datetime.now() - pd.to_datetime(x[\"issue_dt\"])).dt.days/365,2)\n",
    "# x = x[[\"Name\",\"Eqty Name\",\"Age\"]].copy()\n",
    "# x = x.sort_values(by=[\"Eqty Name\",\"Age\"], ascending=[True, False]).reset_index(drop=True).copy()\n",
    "# x = x.drop_duplicates(subset=\"Eqty Name\", keep=\"first\")[[\"Name\"]].copy()\n",
    "# x[\"Name\"] = x[\"Name\"].apply(lambda x: x.rsplit(\" \",1)[0] + \"% due \" + x.rsplit(\"/\",1)[-1])\n",
    "# x[\"MMC\"] = x[\"Name\"].apply(lambda x: [f\"{x.split(\" \",1)[1]} Mat. Matched CDS\", f\"{x.split(\" \",1)[1]} Basis\"])\n",
    "# x[\"Name\"] = x[\"Name\"].apply(lambda x: f\"{x.split(\" \",1)[0]}\")\n",
    "# dict(zip(x[\"Name\"], x[\"MMC\"]))\n",
    "\n",
    "\n",
    "\n",
    "default_values_dict = \\\n",
    "{'TOL': ['3.8% due 29 Mat. Matched CDS', '3.8% due 29 Basis'],\n",
    " 'ZIGGO': ['5 ⅛% due 30 Mat. Matched CDS', '5 ⅛% due 30 Basis'],\n",
    " 'CAR': ['8% due 31 Mat. Matched CDS', '8% due 31 Basis'],\n",
    " 'WFRD': ['8 ⅝% due 30 Mat. Matched CDS', '8 ⅝% due 30 Basis'],\n",
    " 'MPW': ['3 ½% due 31 Mat. Matched CDS', '3 ½% due 31 Basis'],\n",
    " 'OI': ['4 ¾% due 30 Mat. Matched CDS', '4 ¾% due 30 Basis'],\n",
    " 'CHTR': ['4 ¾% due 30 Mat. Matched CDS', '4 ¾% due 30 Basis'],\n",
    " 'HOUS': ['5 ¼% due 30 Mat. Matched CDS', '5 ¼% due 30 Basis'],\n",
    " 'SIRI': ['4 ⅛% due 30 Mat. Matched CDS', '4 ⅛% due 30 Basis'],\n",
    " 'TELEFO': ['8 ¼% due 30 Mat. Matched CDS', '8 ¼% due 30 Basis'],\n",
    " 'SIEGR': ['2.15% due 31 Mat. Matched CDS', '2.15% due 31 Basis'],\n",
    " 'CSCHLD': ['5 ¾% due 30 Mat. Matched CDS', '5 ¾% due 30 Basis'],\n",
    " 'SPG': ['2.45% due 29 Mat. Matched CDS', '2.45% due 29 Basis'],\n",
    " 'RGCARE': ['10% due 32 Mat. Matched CDS', '10% due 32 Basis'],\n",
    " 'TEVA': ['8 ⅛% due 31 Mat. Matched CDS', '8 ⅛% due 31 Basis'],\n",
    " 'HLT': ['4 ⅞% due 30 Mat. Matched CDS', '4 ⅞% due 30 Basis'],\n",
    " 'VST': ['7 ¾% due 31 Mat. Matched CDS', '7 ¾% due 31 Basis'],\n",
    " 'ALIANT': ['5 ⅞% due 29 Mat. Matched CDS', '5 ⅞% due 29 Basis'],\n",
    " 'AXL': ['5% due 29 Mat. Matched CDS', '5% due 29 Basis'],\n",
    " 'IMBLN': ['5 ½% due 30 Mat. Matched CDS', '5 ½% due 30 Basis'],\n",
    " 'DGELN': ['2 ⅜% due 29 Mat. Matched CDS', '2 ⅜% due 29 Basis'],\n",
    " 'TMUS': ['2 ⅞% due 31 Mat. Matched CDS', '2 ⅞% due 31 Basis'],\n",
    " 'URI': ['5 ¼% due 30 Mat. Matched CDS', '5 ¼% due 30 Basis'],\n",
    " 'DOW': ['7 ⅜% due 29 Mat. Matched CDS', '7 ⅜% due 29 Basis'],\n",
    " 'M': ['4 ½% due 34 Mat. Matched CDS', '4 ½% due 34 Basis'],\n",
    " 'JCI': ['1 ¾% due 30 Mat. Matched CDS', '1 ¾% due 30 Basis'],\n",
    " 'AALLN': ['2 ⅞% due 31 Mat. Matched CDS', '2 ⅞% due 31 Basis'],\n",
    " 'OGN': ['5 ⅛% due 31 Mat. Matched CDS', '5 ⅛% due 31 Basis'],\n",
    " 'MEDIND': ['5 ¼% due 29 Mat. Matched CDS', '5 ¼% due 29 Basis'],\n",
    " 'TTEFP': ['5.15% due 34 Mat. Matched CDS', '5.15% due 34 Basis'],\n",
    " 'PRUFIN': ['3 ⅛% due 30 Mat. Matched CDS', '3 ⅛% due 30 Basis'],\n",
    " 'NRUC': ['8% due 32 Mat. Matched CDS', '8% due 32 Basis'],\n",
    " 'LINTA': ['4% due 29 Mat. Matched CDS', '4% due 29 Basis'],\n",
    " 'RIG': ['7 ½% due 31 Mat. Matched CDS', '7 ½% due 31 Basis'],\n",
    " 'HILCRP': ['6% due 31 Mat. Matched CDS', '6% due 31 Basis'],\n",
    " 'CE': ['6.629% due 32 Mat. Matched CDS', '6.629% due 32 Basis'],\n",
    " 'HST': ['3 ⅜% due 29 Mat. Matched CDS', '3 ⅜% due 29 Basis'],\n",
    " 'TRPCN': ['5.6% due 34 Mat. Matched CDS', '5.6% due 34 Basis'],\n",
    " 'BRITEL': ['9 ⅝% due 30 Mat. Matched CDS', '9 ⅝% due 30 Basis'],\n",
    " 'RDSALN': ['2 ⅜% due 29 Mat. Matched CDS', '2 ⅜% due 29 Basis'],\n",
    " 'BMCAUS': ['4 ⅜% due 30 Mat. Matched CDS', '4 ⅜% due 30 Basis'],\n",
    " 'NEE': ['2 ¾% due 29 Mat. Matched CDS', '2 ¾% due 29 Basis'],\n",
    " 'HCA': ['3 ½% due 30 Mat. Matched CDS', '3 ½% due 30 Basis'],\n",
    " 'NESNVX': ['1 ¼% due 30 Mat. Matched CDS', '1 ¼% due 30 Basis'],\n",
    " 'AIFP': ['2 ¼% due 29 Mat. Matched CDS', '2 ¼% due 29 Basis'],\n",
    " 'AEP': ['2.3% due 30 Mat. Matched CDS', '2.3% due 30 Basis'],\n",
    " 'AES': ['3.95% due 30 Mat. Matched CDS', '3.95% due 30 Basis'],\n",
    " 'OMF': ['5 ⅜% due 29 Mat. Matched CDS', '5 ⅜% due 29 Basis'],\n",
    " 'AIG': ['3 ⅞% due 35 Mat. Matched CDS', '3 ⅞% due 35 Basis'],\n",
    " 'ALL': ['5.35% due 33 Mat. Matched CDS', '5.35% due 33 Basis'],\n",
    " 'ALLY': ['8% due 31 Mat. Matched CDS', '8% due 31 Basis'],\n",
    " 'AMGN': ['2.45% due 30 Mat. Matched CDS', '2.45% due 30 Basis'],\n",
    " 'AMZN': ['4.8% due 34 Mat. Matched CDS', '4.8% due 34 Basis'],\n",
    " 'APA': ['4 ¼% due 30 Mat. Matched CDS', '4 ¼% due 30 Basis'],\n",
    " 'ARW': ['2.95% due 32 Mat. Matched CDS', '2.95% due 32 Basis'],\n",
    " 'AVGO': ['5% due 30 Mat. Matched CDS', '5% due 30 Basis'],\n",
    " 'AVT': ['3% due 31 Mat. Matched CDS', '3% due 31 Basis'],\n",
    " 'AXP': ['4.42% due 33 Mat. Matched CDS', '4.42% due 33 Basis'],\n",
    " 'AZN': ['1 ⅜% due 30 Mat. Matched CDS', '1 ⅜% due 30 Basis'],\n",
    " 'AZO': ['4% due 30 Mat. Matched CDS', '4% due 30 Basis'],\n",
    " 'BA': ['6 ⅛% due 33 Mat. Matched CDS', '6 ⅛% due 33 Basis'],\n",
    " 'BALN': ['3.4% due 30 Mat. Matched CDS', '3.4% due 30 Basis'],\n",
    " 'BACR': ['2.645% due 31 Mat. Matched CDS', '2.645% due 31 Basis'],\n",
    " 'BAX': ['3.95% due 30 Mat. Matched CDS', '3.95% due 30 Basis'],\n",
    " 'BBY': ['1.95% due 30 Mat. Matched CDS', '1.95% due 30 Basis'],\n",
    " 'BMY': ['1.45% due 30 Mat. Matched CDS', '1.45% due 30 Basis'],\n",
    " 'BRK': ['6 ½% due 34 Mat. Matched CDS', '6 ½% due 34 Basis'],\n",
    " 'BSX': ['2.65% due 30 Mat. Matched CDS', '2.65% due 30 Basis'],\n",
    " 'CAG': ['8 ¼% due 30 Mat. Matched CDS', '8 ¼% due 30 Basis'],\n",
    " 'CAH': ['5.45% due 34 Mat. Matched CDS', '5.45% due 34 Basis'],\n",
    " 'CMCSA': ['7.05% due 33 Mat. Matched CDS', '7.05% due 33 Basis'],\n",
    " 'CNQCN': ['7.2% due 32 Mat. Matched CDS', '7.2% due 32 Basis'],\n",
    " 'COF': ['2.7% due 30 Mat. Matched CDS', '2.7% due 30 Basis'],\n",
    " 'COXENT': ['4.8% due 35 Mat. Matched CDS', '4.8% due 35 Basis'],\n",
    " 'CPB': ['2 ⅜% due 30 Mat. Matched CDS', '2 ⅜% due 30 Basis'],\n",
    " 'CSCO': ['4.95% due 31 Mat. Matched CDS', '4.95% due 31 Basis'],\n",
    " 'CSX': ['2.4% due 30 Mat. Matched CDS', '2.4% due 30 Basis'],\n",
    " 'CVS': ['4 ⅞% due 35 Mat. Matched CDS', '4 ⅞% due 35 Basis'],\n",
    " 'D': ['6.3% due 33 Mat. Matched CDS', '6.3% due 33 Basis'],\n",
    " 'DAL': ['3 ¾% due 29 Mat. Matched CDS', '3 ¾% due 29 Basis'],\n",
    " 'DE': ['7 ⅛% due 31 Mat. Matched CDS', '7 ⅛% due 31 Basis'],\n",
    " 'DGX': ['2.95% due 30 Mat. Matched CDS', '2.95% due 30 Basis'],\n",
    " 'DHI': ['5% due 34 Mat. Matched CDS', '5% due 34 Basis'],\n",
    " 'DHR': ['2.6% due 29 Mat. Matched CDS', '2.6% due 29 Basis'],\n",
    " 'DIS': ['7% due 32 Mat. Matched CDS', '7% due 32 Basis'],\n",
    " 'DRI': ['6.3% due 33 Mat. Matched CDS', '6.3% due 33 Basis'],\n",
    " 'DT': ['8 ¼% due 30 Mat. Matched CDS', '8 ¼% due 30 Basis'],\n",
    " 'DVN': ['7 ⅞% due 31 Mat. Matched CDS', '7 ⅞% due 31 Basis'],\n",
    " 'EDF': ['6 ¼% due 33 Mat. Matched CDS', '6 ¼% due 33 Basis'],\n",
    " 'EMN': ['5 ¾% due 33 Mat. Matched CDS', '5 ¾% due 33 Basis'],\n",
    " 'ENBCN': ['3 ⅛% due 29 Mat. Matched CDS', '3 ⅛% due 29 Basis'],\n",
    " 'ENGIFP': ['5 ⅝% due 34 Mat. Matched CDS', '5 ⅝% due 34 Basis'],\n",
    " 'ENIIM': ['5 ½% due 34 Mat. Matched CDS', '5 ½% due 34 Basis'],\n",
    " 'EQNR': ['3 ⅛% due 30 Mat. Matched CDS', '3 ⅛% due 30 Basis'],\n",
    " 'ET': ['4.9% due 35 Mat. Matched CDS', '4.9% due 35 Basis'],\n",
    " 'EXC': ['5 ⅝% due 35 Mat. Matched CDS', '5 ⅝% due 35 Basis'],\n",
    " 'EXPE': ['3 ¼% due 30 Mat. Matched CDS', '3 ¼% due 30 Basis'],\n",
    " 'F': ['7.45% due 31 Mat. Matched CDS', '7.45% due 31 Basis'],\n",
    " 'FCX': ['5.4% due 34 Mat. Matched CDS', '5.4% due 34 Basis'],\n",
    " 'FDX': ['4 ¼% due 30 Mat. Matched CDS', '4 ¼% due 30 Basis'],\n",
    " 'FE': ['4.55% due 30 Mat. Matched CDS', '4.55% due 30 Basis'],\n",
    " 'GE': ['6 ¾% due 32 Mat. Matched CDS', '6 ¾% due 32 Basis'],\n",
    " 'GIS': ['2 ⅞% due 30 Mat. Matched CDS', '2 ⅞% due 30 Basis'],\n",
    " 'GM': ['5% due 35 Mat. Matched CDS', '5% due 35 Basis'],\n",
    " 'HAL': ['2.92% due 30 Mat. Matched CDS', '2.92% due 30 Basis'],\n",
    " 'HD': ['2.7% due 30 Mat. Matched CDS', '2.7% due 30 Basis'],\n",
    " 'HES': ['7 ⅞% due 29 Mat. Matched CDS', '7 ⅞% due 29 Basis'],\n",
    " 'KHC': ['6 ¾% due 32 Mat. Matched CDS', '6 ¾% due 32 Basis'],\n",
    " 'HON': ['1.95% due 30 Mat. Matched CDS', '1.95% due 30 Basis'],\n",
    " 'HPQ': ['3.4% due 30 Mat. Matched CDS', '3.4% due 30 Basis'],\n",
    " 'HSBC': ['3.973% due 30 Mat. Matched CDS', '3.973% due 30 Basis'],\n",
    " 'IBM': ['5 ⅞% due 32 Mat. Matched CDS', '5 ⅞% due 32 Basis'],\n",
    " 'INTNED': ['2.727% due 32 Mat. Matched CDS', '2.727% due 32 Basis'],\n",
    " 'INTC': ['4% due 32 Mat. Matched CDS', '4% due 32 Basis'],\n",
    " 'JNJ': ['6.95% due 29 Mat. Matched CDS', '6.95% due 29 Basis'],\n",
    " 'KMI': ['7.4% due 31 Mat. Matched CDS', '7.4% due 31 Basis'],\n",
    " 'KPN': ['8 ⅜% due 30 Mat. Matched CDS', '8 ⅜% due 30 Basis'],\n",
    " 'KR': ['7 ½% due 31 Mat. Matched CDS', '7 ½% due 31 Basis'],\n",
    " 'L': ['6% due 35 Mat. Matched CDS', '6% due 35 Basis'],\n",
    " 'LEN': ['5.2% due 30 Mat. Matched CDS', '5.2% due 30 Basis'],\n",
    " 'LLOYDS': ['0% due 32 Mat. Matched CDS', '0% due 32 Basis'],\n",
    " 'LMT': ['3.6% due 35 Mat. Matched CDS', '3.6% due 35 Basis'],\n",
    " 'LNC': ['3.05% due 30 Mat. Matched CDS', '3.05% due 30 Basis'],\n",
    " 'LOW': ['4 ½% due 30 Mat. Matched CDS', '4 ½% due 30 Basis'],\n",
    " 'LUV': ['2 ⅝% due 30 Mat. Matched CDS', '2 ⅝% due 30 Basis'],\n",
    " 'MCD': ['2 ⅝% due 29 Mat. Matched CDS', '2 ⅝% due 29 Basis'],\n",
    " 'MCK': ['5.1% due 33 Mat. Matched CDS', '5.1% due 33 Basis'],\n",
    " 'MDC': ['3.85% due 30 Mat. Matched CDS', '3.85% due 30 Basis'],\n",
    " 'MDLZ': ['2 ¾% due 30 Mat. Matched CDS', '2 ¾% due 30 Basis'],\n",
    " 'MET': ['6 ½% due 32 Mat. Matched CDS', '6 ½% due 32 Basis'],\n",
    " 'MO': ['3.4% due 30 Mat. Matched CDS', '3.4% due 30 Basis'],\n",
    " 'MPC': ['5.15% due 30 Mat. Matched CDS', '5.15% due 30 Basis'],\n",
    " 'MSI': ['2.3% due 30 Mat. Matched CDS', '2.3% due 30 Basis'],\n",
    " 'MTNA': ['6.8% due 32 Mat. Matched CDS', '6.8% due 32 Basis'],\n",
    " 'NEM': ['5 ⅞% due 35 Mat. Matched CDS', '5 ⅞% due 35 Basis'],\n",
    " 'NFLX': ['5 ⅜% due 29 Mat. Matched CDS', '5 ⅜% due 29 Basis'],\n",
    " 'NGGLN': ['5.809% due 33 Mat. Matched CDS', '5.809% due 33 Basis'],\n",
    " 'NOC': ['4.4% due 30 Mat. Matched CDS', '4.4% due 30 Basis'],\n",
    " 'NSC': ['2.55% due 29 Mat. Matched CDS', '2.55% due 29 Basis'],\n",
    " 'NWG': ['5.076% due 30 Mat. Matched CDS', '5.076% due 30 Basis'],\n",
    " 'OMC': ['2.45% due 30 Mat. Matched CDS', '2.45% due 30 Basis'],\n",
    " 'ORAFP': ['8 ½% due 31 Mat. Matched CDS', '8 ½% due 31 Basis'],\n",
    " 'ORCL': ['4.3% due 34 Mat. Matched CDS', '4.3% due 34 Basis'],\n",
    " 'OVV': ['8 ⅛% due 30 Mat. Matched CDS', '8 ⅛% due 30 Basis'],\n",
    " 'OXY': ['7 ½% due 31 Mat. Matched CDS', '7 ½% due 31 Basis'],\n",
    " 'PARA': ['7 ⅞% due 30 Mat. Matched CDS', '7 ⅞% due 30 Basis'],\n",
    " 'PFE': ['6 ½% due 34 Mat. Matched CDS', '6 ½% due 34 Basis'],\n",
    " 'PG': ['5.8% due 34 Mat. Matched CDS', '5.8% due 34 Basis'],\n",
    " 'PHM': ['7 ⅞% due 32 Mat. Matched CDS', '7 ⅞% due 32 Basis'],\n",
    " 'PKG': ['3% due 29 Mat. Matched CDS', '3% due 29 Basis'],\n",
    " 'PRU': ['5 ¾% due 33 Mat. Matched CDS', '5 ¾% due 33 Basis'],\n",
    " 'R': ['6.6% due 33 Mat. Matched CDS', '6.6% due 33 Basis'],\n",
    " 'RIFP': ['1 ⅝% due 31 Mat. Matched CDS', '1 ⅝% due 31 Basis'],\n",
    " 'RTX': ['7 ½% due 29 Mat. Matched CDS', '7 ½% due 29 Basis'],\n",
    " 'SHW': ['2.3% due 30 Mat. Matched CDS', '2.3% due 30 Basis'],\n",
    " 'SO': ['2.65% due 29 Mat. Matched CDS', '2.65% due 29 Basis'],\n",
    " 'SRE': ['5 ½% due 33 Mat. Matched CDS', '5 ½% due 33 Basis'],\n",
    " 'STANLN': ['4.305% due 30 Mat. Matched CDS', '4.305% due 30 Basis'],\n",
    " 'T': ['4 ½% due 35 Mat. Matched CDS', '4 ½% due 35 Basis'],\n",
    " 'TGT': ['6.35% due 32 Mat. Matched CDS', '6.35% due 32 Basis'],\n",
    " 'TSN': ['4 ⅞% due 34 Mat. Matched CDS', '4 ⅞% due 34 Basis'],\n",
    " 'UBS': ['3.126% due 30 Mat. Matched CDS', '3.126% due 30 Basis'],\n",
    " 'UNH': ['4 ⅝% due 35 Mat. Matched CDS', '4 ⅝% due 35 Basis'],\n",
    " 'UNP': ['3 ⅜% due 35 Mat. Matched CDS', '3 ⅜% due 35 Basis'],\n",
    " 'VLO': ['7 ½% due 32 Mat. Matched CDS', '7 ½% due 32 Basis'],\n",
    " 'VZ': ['7 ¾% due 30 Mat. Matched CDS', '7 ¾% due 30 Basis'],\n",
    " 'WHR': ['2.4% due 31 Mat. Matched CDS', '2.4% due 31 Basis'],\n",
    " 'WMB': ['7 ½% due 31 Mat. Matched CDS', '7 ½% due 31 Basis'],\n",
    " 'WMT': ['7.55% due 30 Mat. Matched CDS', '7.55% due 30 Basis'],\n",
    " 'WY': ['7 ⅜% due 32 Mat. Matched CDS', '7 ⅜% due 32 Basis']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f93c4554-4e53-41a1-a886-ee07442f18fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b148f500634710b4f0c8c66c0956d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Issuer', options=('All', 'AALLN', 'AEP', 'AES', 'AIFP', 'A…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca33eba6c294e36a177e6bf7708867c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='a', description='Horizontal Axis:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "694ae7ab9a9444dfb6ea36539d0f38f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='b', description='Vertical Axis:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b04ffea7254ac4ac2c0701d2142d92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46cf93dc29d4d4c88f8e234bd4b759a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################### Changing order of names\n",
    "\n",
    "issuer = ['All'] + list(sorted(set([item.split(' ',1)[0] for item in options])))\n",
    "options1 = list(set([item.split(' ',1)[1] for item in options])) + ['US 5Y','US 7Y','US 10Y']\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "dropdown1 = Dropdown(options=issuer, description='Issuer')\n",
    "dropdown2 = Dropdown(options=options1, description='A:')\n",
    "dropdown3 = Dropdown(options=options1, description='B:')\n",
    "dropdown4 = Dropdown(options=options1, description='C:')\n",
    "dropdown5 = Dropdown(options=options1, description='D:')\n",
    "dropdown6 = Dropdown(options=options1, description='E:')\n",
    "dropdown7 = Dropdown(options=options1, description='F:')\n",
    "dropdown8 = Dropdown(options=options1, description='G:')\n",
    "dropdown9 = Dropdown(options=options1, description='H:')\n",
    "dropdown10 = Dropdown(options=options1, description='I:')\n",
    "dropdown11 = Dropdown(options=options1, description='J:')\n",
    "dropdown12 = Dropdown(options=options1, description='K:')\n",
    "dropdown13 = Dropdown(options=options1, description='L:')\n",
    "# dropdown14 = Dropdown(options=time, description='Time:')\n",
    "\n",
    "dropdown14 = widgets.FloatText(\n",
    "    value=5,\n",
    "    description='Years:',\n",
    "    step=0.01\n",
    ")\n",
    "\n",
    "row1 = HBox([dropdown1])\n",
    "row2 = HBox([dropdown2, dropdown3, dropdown4])\n",
    "row3 = HBox([dropdown5, dropdown6, dropdown7])\n",
    "row4 = HBox([dropdown8, dropdown9, dropdown10])\n",
    "row5 = HBox([dropdown11, dropdown12, dropdown13])\n",
    "row6 = HBox([dropdown14])\n",
    "\n",
    "dropdown_box = VBox([row1, row2, row3, row4, row5, row6])\n",
    "\n",
    "display(dropdown_box)\n",
    "\n",
    "expression_input1 = Text(description='Horizontal Axis:',value='a')\n",
    "expression_input2 = Text(description='Vertical Axis:',value='b')\n",
    "display(expression_input1)\n",
    "display(expression_input2)\n",
    "\n",
    "def get_values():\n",
    "    return dropdown1.value, dropdown2.value, dropdown3.value, \\\n",
    "    dropdown4.value, dropdown5.value, dropdown6.value, \\\n",
    "    dropdown7.value, dropdown8.value, dropdown9.value, \\\n",
    "    dropdown10.value, dropdown11.value, dropdown12.value, \\\n",
    "    dropdown13.value, dropdown14.value\n",
    "\n",
    "submit_button = Button(description=\"Submit\")\n",
    "display(submit_button)\n",
    "\n",
    "output = Output()\n",
    "display(output)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        global df\n",
    "        clear_output()\n",
    "        selected_values = get_values()\n",
    "        x = list(selected_values)\n",
    "        if x[0] != 'All':\n",
    "            x = [x[0]] + [f\"{x[0]} {item}\" for item in x[1:-1]] + [x[-1]]\n",
    "            selected_values = [x[0]] + \\\n",
    "            ['BBG ' + item.split(' ',1)[1] if (len(item.split(' '))>2 and item.split(' ')[1]=='US') else item for item in x[1:-1]]\\\n",
    "            +[x[-1]]\n",
    "            selected_values = tuple(selected_values)\n",
    "        \n",
    "        expression1 = expression_input1.value.upper()\n",
    "        expression2 = expression_input2.value.upper()\n",
    "        \n",
    "        col_map = {'A': selected_values[1], 'B': selected_values[2], 'C': selected_values[3], \n",
    "                   'D': selected_values[4], 'E': selected_values[5], 'F': selected_values[6],\n",
    "                   'G': selected_values[7], 'H': selected_values[8], 'I': selected_values[9], \n",
    "                   'J': selected_values[10], 'K': selected_values[11], 'L': selected_values[12]}\n",
    "        \n",
    "        for key, value in col_map.items():\n",
    "            expression1 = expression1.replace(key, key.lower())\n",
    "            expression2 = expression2.replace(key, key.lower())\n",
    "        \n",
    "        a, b, c, d, e, f, g, h, i, j, k, l = sp.symbols('a b c d e f g h i j k l')\n",
    "        expr1 = sp.sympify(expression1)\n",
    "        expr11 = sp.sympify(expression1)\n",
    "        expr2 = sp.sympify(expression2) if expression2 else None\n",
    "        expr21 = sp.sympify(expression2) if expression2 else None\n",
    "\n",
    "        cols_to_check = [col_map['A'], col_map['B'], col_map['C'], \\\n",
    "                         col_map['D'], col_map['E'], col_map['F'], \\\n",
    "                         col_map['G'], col_map['H'], col_map['I'], \\\n",
    "                         col_map['J'], col_map['K'], col_map['L'] ]\n",
    "        \n",
    "        df1 = df.copy()\n",
    "        df2 = df.copy()\n",
    "        \n",
    "        replacements = {\n",
    "            'A': selected_values[1], 'a': selected_values[1],\n",
    "            'B': selected_values[2], 'b': selected_values[2],\n",
    "            'C': selected_values[3], 'c': selected_values[3],\n",
    "            'D': selected_values[4], 'd': selected_values[4],\n",
    "            'E': selected_values[5], 'e': selected_values[5],\n",
    "            'F': selected_values[6], 'f': selected_values[6],\n",
    "            'G': selected_values[7], 'g': selected_values[7],\n",
    "            'H': selected_values[8], 'h': selected_values[8],\n",
    "            'I': selected_values[9], 'i': selected_values[9],\n",
    "            'J': selected_values[10], 'j': selected_values[10],\n",
    "            'K': selected_values[11], 'k': selected_values[11],\n",
    "            'L': selected_values[12], 'l': selected_values[12]\n",
    "        }\n",
    "\n",
    "        regex = re.compile(\"|\".join(re.escape(key) for key in replacements.keys()))\n",
    "        used_keys = set()\n",
    "        def substitution(match):\n",
    "            key = match.group(0)\n",
    "            used_keys.add(key)\n",
    "            return replacements[key]\n",
    "        \n",
    "        expr111 = regex.sub(substitution, str(expr11))\n",
    "        expr211 = regex.sub(substitution, str(expr21))\n",
    "        used_substitutions = list(used_keys)\n",
    "\n",
    "        used_substitutions = [replacements[item.upper()] for item in used_substitutions]\n",
    "\n",
    "        df1['Expression 1'] = df1.apply(lambda row: expr1.evalf(subs={\\\n",
    "            a: row[col_map['A']], b: row[col_map['B']], \n",
    "            c: row[col_map['C']], d: row[col_map['D']], \n",
    "            e: row[col_map['E']], f: row[col_map['F']],\n",
    "            g: row[col_map['G']], h: row[col_map['H']],\n",
    "            i: row[col_map['I']], j: row[col_map['J']], \n",
    "            k: row[col_map['K']], l: row[col_map['L']] }), axis=1).astype(float)       \n",
    "        df1['Expression 2'] = df1.apply(lambda row: expr2.evalf(subs={\\\n",
    "            a: row[col_map['A']], b: row[col_map['B']], \n",
    "            c: row[col_map['C']], d: row[col_map['D']], \n",
    "            e: row[col_map['E']], f: row[col_map['F']],\n",
    "            g: row[col_map['G']], h: row[col_map['H']],\n",
    "            i: row[col_map['I']], j: row[col_map['J']], \n",
    "            k: row[col_map['K']], l: row[col_map['L']] }) if expr2 else np.nan, axis=1).astype(float)\n",
    "\n",
    "        plot_exp1 = np.nan\n",
    "        plot_exp2 = np.nan\n",
    "        \n",
    "        if ('FWD' in expr111) and not ('FWD' in expr211) and expression2:\n",
    "            df2['Expression 2'] = df2.apply(lambda row: expr2.evalf(subs={\\\n",
    "            a: row[col_map['A']], b: row[col_map['B']], \n",
    "            c: row[col_map['C']], d: row[col_map['D']], \n",
    "            e: row[col_map['E']], f: row[col_map['F']],\n",
    "            g: row[col_map['G']], h: row[col_map['H']],\n",
    "            i: row[col_map['I']], j: row[col_map['J']], \n",
    "            k: row[col_map['K']], l: row[col_map['L']] }), axis=1).astype(float)\n",
    "            plot_exp2 = df2.iloc[-1]['Expression 2'].astype(float)\n",
    "        if ('FWD' in expr211) and not ('FWD' in expr111):\n",
    "            df2['Expression 1'] = df2.apply(lambda row: expr1.evalf(subs={\\\n",
    "            a: row[col_map['A']], b: row[col_map['B']], \n",
    "            c: row[col_map['C']], d: row[col_map['D']], \n",
    "            e: row[col_map['E']], f: row[col_map['F']],\n",
    "            g: row[col_map['G']], h: row[col_map['H']],\n",
    "            i: row[col_map['I']], j: row[col_map['J']], \n",
    "            k: row[col_map['K']], l: row[col_map['L']] }), axis=1).astype(float)\n",
    "            plot_exp1 = df2.iloc[-1]['Expression 1'].astype(float)\n",
    "\n",
    "        \n",
    "        def filter_df(dfx1, time_period):\n",
    "            dfx = dfx1.copy()\n",
    "            dfx.index=pd.to_datetime(dfx.index)\n",
    "            if time_period == 'All':\n",
    "                return dfx\n",
    "            else:\n",
    "                now = datetime.now()\n",
    "                # if time_period == '2Y':\n",
    "                #     start_date = now - timedelta(days=2*365)\n",
    "                # elif time_period == '1Y':\n",
    "                #     start_date = now - timedelta(days=365)\n",
    "                # elif time_period == '6M':\n",
    "                #     start_date = now - timedelta(days=6*30)\n",
    "                # elif time_period == '3M':\n",
    "                #     start_date = now - timedelta(days=3*30)\n",
    "                # return dfx[dfx.index.date >= start_date.date()]   \n",
    "                \n",
    "                start_date = now - timedelta(days=int(time_period*365))\n",
    "                return dfx[dfx.index.date >= start_date.date()] \n",
    "\n",
    "        def update_plot(plot_exp1,plot_exp2,df1,df2):\n",
    "            df1 = df1[used_substitutions + ['Expression 1','Expression 2']].dropna().copy()\n",
    "            # display(df1)\n",
    "            if expression2:\n",
    "                fig = make_subplots(rows=2, cols=1, shared_xaxes=False, \\\n",
    "                                    vertical_spacing=0.1, specs=[ [{\"secondary_y\":False}], [{\"secondary_y\":True}] ],\\\n",
    "                                   subplot_titles=(f'Scatter Plot from {df1.index[0].date()} to {df1.index[-1].date()}',\\\n",
    "                                                  f'{expr111}: {df1[df1.columns[-2]][-1]:.4f}   &   {expr211}: {df1[df1.columns[-1]][-1]:.4f}'))\n",
    "                \n",
    "                x_scatter = df1[df1.columns[-2]]\n",
    "                y_scatter = df1[df1.columns[-1]]\n",
    "\n",
    "                coeffs = np.polyfit(x_scatter,y_scatter,2)\n",
    "                polynomial = np.poly1d(coeffs)\n",
    "                x_poly=np.linspace(min(x_scatter),max(x_scatter),500)\n",
    "                y_poly=polynomial(x_poly)\n",
    "                y_pred = polynomial(x_scatter)\n",
    "                r2=r2_score(y_scatter,y_pred)\n",
    "                equation_text = f\"y = {coeffs[0]:.4f}*x² + {coeffs[1]:.4f}*x + {coeffs[2]:.4f}\"\n",
    "    \n",
    "                residuals = y_scatter-y_pred\n",
    "                res_sum=np.sum(residuals**2)\n",
    "                dof=len(x_scatter)-len(coeffs)\n",
    "                res_var = res_sum / dof\n",
    "                se = np.sqrt(res_var)\n",
    "                conf_upper = y_poly + 2 * se\n",
    "                conf_lower = y_poly - 2 * se\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=df1[df1.columns[-2]][-63:-1], y=df1[df1.columns[-1]][-63:-1], \\\n",
    "                                         name='< 3 months', mode='markers',marker=dict(color='green')), \\\n",
    "                              row=1,col=1,secondary_y=False)\n",
    "                fig.add_trace(go.Scatter(x=df1[df1.columns[-2]][-252:-63], y=df1[df1.columns[-1]][-252:-63], \\\n",
    "                                         name='> 3 months & < 1 year', mode='markers',marker=dict(color='blue')), \\\n",
    "                              row=1,col=1,secondary_y=False)\n",
    "                fig.add_trace(go.Scatter(x=df1[df1.columns[-2]][:-252], y=df1[df1.columns[-1]][:-252], \\\n",
    "                                         name='> 1 year', mode='markers',marker=dict(color='gray')), \\\n",
    "                              row=1,col=1,secondary_y=False)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=[df1[df1.columns[-2]].iloc[-1]], y=[df1[df1.columns[-1]].iloc[-1]], \\\n",
    "                                         name=f'Value as of {df1.index[-1].date()}', mode='markers',marker=dict(color='red',size=10),\\\n",
    "                                         showlegend=True), row=1,col=1,secondary_y=False)      \n",
    "                fig.add_trace(go.Scatter(x=x_poly, y=y_poly, \\\n",
    "                                         name=f'Polynomial Fit<br>R² = {r2:.3f}<br>{equation_text}', \\\n",
    "                                         mode='lines', line=dict(color='orange'),\n",
    "                                         showlegend=True), row=1,col=1,secondary_y=False) \n",
    "               \n",
    "                fig.add_trace(go.Scatter(x=x_poly, y=conf_upper, \\\n",
    "                                         name='Upper Confidence Band', \\\n",
    "                                         mode='lines', line=dict(color='orange',dash='dash'),\n",
    "                                         showlegend=True), row=1,col=1,secondary_y=False) \n",
    "                fig.add_trace(go.Scatter(x=x_poly, y=conf_lower, \\\n",
    "                                         name='Lower Confidence Band', fill='tonexty',\\\n",
    "                                         fillcolor='rgba(255,165,0,0.15)',\n",
    "                                         mode='lines', line=dict(color='orange',dash='dash'),\n",
    "                                         showlegend=True), row=1,col=1,secondary_y=False) \n",
    "                \n",
    "                if ('FWD' in expr111) and not ('FWD' in expr211):\n",
    "                    # display(f\"Condition1\")\n",
    "                    plot_exp2 = [plot_exp2] * len(df1[df1.columns[-2]])\n",
    "                    fig.add_trace(go.Scatter(x=df1[df1.columns[-2]], y=plot_exp2, mode='lines',\\\n",
    "                     line=dict(color='red',width=1),name = f'{expr211} on {df2.index[-1]} was {plot_exp2[0]}'), \\\n",
    "                      row=1,col=1,secondary_y=False)\n",
    "\n",
    "                if ('FWD' in expr211) and not ('FWD' in expr111):\n",
    "                    # display(f\"Condition2\")\n",
    "                    plot_exp1 = [plot_exp1] * len(df1[df1.columns[-1]])\n",
    "                    fig.add_trace(go.Scatter(x=plot_exp1, y=df1[df1.columns[-1]], mode='lines',\\\n",
    "                     line=dict(color='red',width=1), name = f'{expr111} on {df2.index[-1]} was {plot_exp1[0]}'), \\\n",
    "                      row=1,col=1,secondary_y=False)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=df1.index, y=df1[df1.columns[-2]], name=expr111,\\\n",
    "                         line=dict(color='blue')), row=2,col=1,secondary_y=False)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=[df1.index[0], df1.index[-1]], \\\n",
    "                 y=[df1[df1.columns[-2]][-1], df1[df1.columns[-2]][-1]], \\\n",
    "                 mode='lines', line=dict(dash='dash', color='blue'), \\\n",
    "                 name=f'Recent value of {expr111} is {df1[df1.columns[-2]][-1]}'),row=2,col=1,secondary_y=False)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=df1.index, y=df1[df1.columns[-1]], \\\n",
    "                                     name=expr211, line=dict(color='green')),\\\n",
    "                                      row=2,col=1, secondary_y=True)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=[df1.index[0], df1.index[-1]], \\\n",
    "                 y=[df1[df1.columns[-1]][-1], df1[df1.columns[-1]][-1]], \\\n",
    "                 mode='lines', line=dict(dash='dash', color='green'), \\\n",
    "                 name=f'Recent value of {expr211} is {df1[df1.columns[-1]][-1]}'),row=2,col=1, secondary_y=True)\n",
    "                \n",
    "                fig.update_layout(\n",
    "                hovermode='x unified',\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white',\n",
    "                legend=dict(orientation=\"h\",yanchor=\"bottom\",xanchor=\"center\",x=0.5,y=1.05),\n",
    "                height=1900,\n",
    "                width=1100)\n",
    "\n",
    "            else:\n",
    "                fig = make_subplots(rows=1, cols=1, shared_xaxes=False, \\\n",
    "                                    vertical_spacing=0.1, subplot_titles=(f'{expr111}: {df1[df1.columns[-2]][-1]:.4f}'))\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=df1.index, y=df1[df1.columns[-2]], name=expr111,\\\n",
    "                         line=dict(color='blue')), row=1,col=1)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=[df1.index[0], df1.index[-1]], \\\n",
    "                 y=[df1[df1.columns[-2]][-1], df1[df1.columns[-2]][-1]], \\\n",
    "                 mode='lines', line=dict(dash='dash', color='blue'), \\\n",
    "                 name=f'Recent value of {expr111} is {df1[df1.columns[-2]][-1]}'))\n",
    "\n",
    "                fig.update_layout(\n",
    "                yaxis=dict(zeroline=True, zerolinecolor='black'),\n",
    "                hovermode='x unified',\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white',\n",
    "                legend=dict(orientation=\"h\",yanchor=\"bottom\",xanchor=\"center\",x=0.5,y=1.05),\n",
    "                height=800,\n",
    "                width=1100)\n",
    "\n",
    "            def split_label(label,n):\n",
    "                return '<br>'.join([label[i:i+n] for i in range(0,len(label),n)])\n",
    "\n",
    "            label1 = split_label(expr111,38)\n",
    "            label2 = split_label(expr211,38)\n",
    "          \n",
    "            if expression2:\n",
    "                fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True,\\\n",
    "                                 row=1,col=1,title=label1, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "                fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True,\\\n",
    "                                 row=1,col=1, title=label2, secondary_y=False, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "                fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title='Date', row=2, col=1, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "                fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title=label1, side='left', row=2,col=1, secondary_y=False, \\\n",
    "                                 showgrid=True, gridcolor='LightGrey',gridwidth=1, title_font = dict(color='blue'))\n",
    "                fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title=label2, side='right', row=2,col=1, secondary_y=True, title_font = dict(color='green'))\n",
    "            else:\n",
    "                fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title='Date', row=1, col=1, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "                fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title=label1, side='left', row=1,col=1, secondary_y=False, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "            fig.show()\n",
    "        \n",
    "        df1 = filter_df(df1, selected_values[-1]).copy() #Time goes here\n",
    "        interact(update_plot(plot_exp1,plot_exp2,df1,df2))\n",
    "\n",
    "submit_button.on_click(on_button_clicked)\n",
    "\n",
    "def update_dropdowns(*args):\n",
    "    selected_issuer = dropdown1.value\n",
    "    if selected_issuer:\n",
    "        for i in range(2, 14):\n",
    "            dropdown = globals().get(f'dropdown{i}')\n",
    "            if dropdown:\n",
    "                if selected_issuer != 'All':\n",
    "                    x = list([item.split(' ', 1)[1] for item in options if item.startswith(selected_issuer)]) + ['US 5Y','US 7Y','US 10Y']\n",
    "                else:\n",
    "                    x = options\n",
    "                dropdown.options = x\n",
    "        if selected_issuer in list(default_values_dict.keys()):\n",
    "            globals().get(f'dropdown2').value = default_values_dict[selected_issuer][0]\n",
    "            globals().get(f'dropdown3').value = default_values_dict[selected_issuer][1]\n",
    "\n",
    "dropdown1.observe(update_dropdowns, names='value')\n",
    "update_dropdowns()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

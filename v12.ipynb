{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06c55c96-14f7-47ba-b243-74810b410cf4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from pydataquery import DataQuery\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from xbbg import blp\n",
    "import numpy as np\n",
    "import pytz\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "import statsmodels.api as sm\n",
    "from ipywidgets import interact, Dropdown, HBox, VBox, Button, Output, Text, widgets\n",
    "from IPython.display import display, clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import re\n",
    "import scipy.stats as stats\n",
    "from adjustText import adjust_text\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import sympy as sp\n",
    "import itertools\n",
    "import warnings\n",
    "import openpyxl\n",
    "import subprocess\n",
    "import time\n",
    "import pyautogui\n",
    "import pygetwindow as gw\n",
    "import pyodbc\n",
    "import ast\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec475d55-89fc-490f-9f7e-11205368f40f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    df_original = pd.read_parquet(\"Markit CDS.parquet\")\n",
    "    \n",
    "    to_date = datetime.today().date()\n",
    "    from_date = df_original[\"close_date\"].iloc[-1].date()\n",
    "    \n",
    "    from_date_str = from_date.strftime('%m/%d/%Y')\n",
    "    to_date_str = to_date.strftime('%m/%d/%Y')\n",
    "    \n",
    "    conn_str = (\n",
    "        f'DRIVER={{SQL Server}};'\n",
    "        f'SERVER=BC-ODS-P1;'\n",
    "        f'DATABASE=MarkitDB;'\n",
    "        f'ApplicationIntent=ReadOnly;'\n",
    "        f'Trusted_Connection=Yes;'\n",
    "        f'Authentication=ActiveDirectoryIntegrated;'\n",
    "    )\n",
    "    \n",
    "    conn = pyodbc.connect(conn_str)\n",
    "    \n",
    "    query1 = f\"\"\"\n",
    "        DECLARE @FromDate DATE = '{from_date_str}';\n",
    "        DECLARE @ToDate DATE = '{to_date_str}';\n",
    "        \n",
    "        SELECT sc.close_date, r.ticker, c.red, c.tier, c.docclause, c.ccy, sc.tenor, sc.spread\n",
    "        FROM dbo.RedEntities r\n",
    "        INNER JOIN dbo.MarkitCurves c ON r.red = c.red\n",
    "        INNER JOIN dbo.MarkitSpreadCurve sc ON c.curve_id = sc.curve_id\n",
    "        WHERE sc.close_date >= @FromDate AND sc.close_date <= @ToDate;\n",
    "    \"\"\"\n",
    "    \n",
    "    df_new = pd.read_sql(query1, conn)\n",
    "    conn.close()\n",
    "\n",
    "    df_old = df_original[df_original[\"close_date\"]<pd.to_datetime(df_original[\"close_date\"].iloc[-1])]\n",
    "\n",
    "    df1 = pd.concat([df_old, df_new])\n",
    "    df1 = df1.drop_duplicates()\n",
    "    df1.to_parquet(\"Markit CDS.parquet\")\n",
    "except:\n",
    "    df1 = pd.read_parquet(\"Markit CDS.parquet\")\n",
    "    hello = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88addd8-9cd9-4db2-8b2a-d790d057d6f3",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "markit_cds = list(set(df1[\"red\"]))\n",
    "markit_df1 = df1.copy()\n",
    "\n",
    "res_codes = { \"Full Restructuring\": \"CR14\", \"Modified Restructuring\": \"MR14\",\n",
    "          \"Modified-Modified Restructurin\": \"MM14\", \"No Restructuring\": \"XR14\"}\n",
    "\n",
    "excel_df = None\n",
    "all_dq = None\n",
    "all_temp_cds = None\n",
    "\n",
    "for rating_col in[\"IG\",\"HY\",\"EUR_IG\",\"EUR_HY\",\"SNRFIN\",\"SUBFIN\",\"Extras\"]:\n",
    "    dq = pd.read_excel(\"CDX Members.xlsx\", sheet_name=rating_col)\n",
    "    dq[\"Restructuring\"] = dq[\"Restructuring\"].apply(lambda x: res_codes[x])\n",
    "    dq = dq[dq[\"Actual RED Code\"].isin(markit_cds)].reset_index(drop=True).copy()\n",
    "    dq.rename(columns={\"Actual RED Code\": \"red\"}, inplace=True)\n",
    "    \n",
    "    if not \"Family\" in dq.columns:\n",
    "        dq[\"Family\"] = [rating_col]*len(dq)\n",
    "        \n",
    "    if not \"tier\" in dq.columns:\n",
    "        dq[\"tier\"] = \"SNRFOR\" if rating_col != \"SUBFIN\" else \"SUBLT2\"\n",
    "    \n",
    "    dq[\"ccy\"] = dq[\"Family\"].apply(lambda x: \"USD\" if x in [\"IG\",\"HY\"] else \"EUR\")\n",
    "    dq = dq.drop([\"5Y CDS Ticker\",\"ISIN\",\"RED Code\",\"Company Name\",\"Corp Ticker\"],axis=1)\n",
    "    \n",
    "    all_dq = pd.concat([all_dq, dq]).drop_duplicates(keep=\"first\").reset_index(drop=True).copy()\n",
    "\n",
    "unique_all_dq = all_dq.drop(\"Family\",axis=1).drop_duplicates().reset_index(drop=True).copy()\n",
    "unique_all_dq.columns = unique_all_dq.columns.str.replace(\"Restructuring\",\"docclause\")\n",
    "\n",
    "cds_df = pd.merge(left=df1, right = unique_all_dq, on=[\"red\",\"docclause\",\"tier\",\"ccy\"], how=\"inner\")\n",
    "cds_df[\"close_date\"] = pd.to_datetime(cds_df[\"close_date\"])\n",
    "cds_df = cds_df[cds_df[\"tenor\"]!=\"Spot\"]\n",
    "cds_df[\"tenor\"] = cds_df[\"tenor\"].apply(lambda x: eval(x.replace(\"y\",\"*1\").replace(\"m\",\"*(1/12)\")))\n",
    "\n",
    "cds_df[\"ticker_red_tier_ccy_docclause\"] = (cds_df[\"ticker\"].astype(str) + \"_\" + cds_df[\"red\"].astype(str) +\\\n",
    "     \"_\" + cds_df[\"tier\"].astype(str) + \"_\" + cds_df[\"ccy\"].astype(str) + \"_\" + cds_df[\"docclause\"].astype(str))\n",
    "cds_df = cds_df.drop([\"ticker\",\"red\",\"tier\",\"ccy\",\"docclause\"],axis=1)\n",
    "\n",
    "########################### Creating map for family\n",
    "f = all_dq.drop_duplicates().reset_index(drop=True).copy()\n",
    "f1 = f[\"Issuer Equity\"].astype(str) + \"_\" + f[\"red\"].astype(str) + \"_\" +\\\n",
    "f[\"tier\"].astype(str) + \"_\" + f[\"ccy\"].astype(str)  + \"_\" + f[\"Restructuring\"].astype(str)\n",
    "f2 = f[\"Family\"]\n",
    "f_dict = dict(zip(f1,f2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf68035-cdde-498d-8ad9-7322fb3a7b76",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "##############################################################################################################\n",
    "\n",
    "issuers = list(sorted(set(cds_df[\"ticker_red_tier_ccy_docclause\"])))\n",
    "last_dt = max(cds_df[\"close_date\"])\n",
    "\n",
    "all_curves = None\n",
    "\n",
    "try:\n",
    "    # all_curves = pd.read_excel(\"All CDS Curves.xlsx/\") ############## made to fail\n",
    "    for issuer in issuers:\n",
    "        df = cds_df[cds_df[\"ticker_red_tier_ccy_docclause\"]==issuer]\n",
    "        df = pd.pivot_table(df, values=\"spread\", index=\"close_date\", columns =\"tenor\")\n",
    "        \n",
    "        if not last_dt in df.index:\n",
    "            df.loc[last_dt] = [np.nan] * len(df.columns)\n",
    "        df = df.sort_index().ffill().copy()\n",
    "        df[f\"{issuer}_curve\"] = [np.nan] * len(df)\n",
    "    \n",
    "        for idx in df.index:\n",
    "            curve = df.loc[[idx],:].dropna(axis=1)\n",
    "            curve = curve.iloc[:,:-1].copy()\n",
    "            x = list((curve.columns))\n",
    "            x2 = [item**2 for item in x]\n",
    "            X = np.column_stack([x, x2])\n",
    "            Y = list(curve.iloc[0])\n",
    "    \n",
    "            if len(X) > 2:\n",
    "                model = sm.OLS(Y, sm.add_constant(X)).fit()\n",
    "                df.loc[idx,f\"{issuer}_curve\"] = str([model.params[0], model.params[1], model.params[2]])\n",
    "                \n",
    "                # x_pred = list(np.linspace(min(x), max(x),100))\n",
    "                # x_pred2 = [item**2 for item in x_pred]\n",
    "                # X_pred = np.column_stack([x_pred, x_pred2])\n",
    "                # y_pred = model.predict(sm.add_constant(X_pred))\n",
    "                # plt.plot(x, Y)\n",
    "                # plt.plot(x_pred, y_pred)\n",
    "                # title = f\"{issuer} on {str(idx.date())}\"\n",
    "                # plt.title(title)\n",
    "                # # plt.savefig(f\"Curve Plots v2/{title}.png\")\n",
    "                # plt.show()\n",
    "                # plt.close()\n",
    "                \n",
    "            else:\n",
    "                df.loc[idx,f\"{issuer}_curve\"] = str([np.nan, np.nan, np.nan])\n",
    "    \n",
    "        all_curves = pd.concat([all_curves,df.iloc[:,[-1]]],axis=1)\n",
    "    all_curves.to_excel(\"All CDS Curves.xlsx\")\n",
    "except:\n",
    "    all_curves = pd.read_excel(\"All CDS Curves.xlsx\",index_col=0, parse_dates=True)\n",
    "    hello=1\n",
    "\n",
    "all_curves1 = all_curves.copy()\n",
    "all_curves = all_curves.T.copy()\n",
    "all_curves.index.name = \"ticker_red_tier_ccy_docclause\"\n",
    "all_curves.columns = [f'CDS_{item.date()}' for item in all_curves.columns]\n",
    "all_curves = all_curves.reset_index(drop=False).copy()\n",
    "all_temp_cds = all_curves.copy()\n",
    "all_temp_cds[\"Temp\"] = (all_temp_cds[\"ticker_red_tier_ccy_docclause\"].astype(str).\\\n",
    "    str.split(\"_\", n=1).str[1].str.replace(\"_curve\", \"\", regex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0ac30843-b275-4f60-b8ed-89788d9c8cdf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "unique_all_dq[\"Issuer Equity_red_tier_ccy_docclause\"] = (unique_all_dq[\"Issuer Equity\"].astype(str) + \"_\" + unique_all_dq[\"red\"].astype(str) +\\\n",
    "     \"_\" + unique_all_dq[\"tier\"].astype(str) + \"_\" + unique_all_dq[\"ccy\"].astype(str) + \"_\" + unique_all_dq[\"docclause\"].astype(str))\n",
    "unique_all_dq = unique_all_dq.drop([\"Issuer Equity\",\"red\",\"tier\",\"ccy\",\"docclause\"],axis=1)\n",
    "unique_all_dq[\"Temp\"] = unique_all_dq[\"Issuer Equity_red_tier_ccy_docclause\"].astype(str).str.split(\"_\", n=1).str[1]\n",
    "\n",
    "df2 = pd.merge(left=unique_all_dq, right=all_temp_cds, on=\"Temp\", how=\"inner\").drop([\"Temp\",\"ticker_red_tier_ccy_docclause\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8f4cb6-1908-474c-93bb-a6e57a366b48",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "markit_to_bbg_tier_map = {\"SNRFOR\": \"Sr Unsecured\", \"SUBLT2\": \"Subordinated\"}\n",
    "\n",
    "l1 = [item.split(\"_\")[0] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "l2 = [markit_to_bbg_tier_map[item.split(\"_\")[2]] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "l3 = [item.split(\"_\")[3] for item in df2[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "l4 = [item.split(\" \")[0] for item in df2[\"Bond Name\"]]\n",
    "bbg_bonds_dict = {}\n",
    "\n",
    "for i in range(len(l1)):\n",
    "    bbg_bonds_dict[f\"{l1[i]} Equity_{l2[i]}_{l3[i]}\"] = l4[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4309eab9-0be2-4c88-a272-4099e34a50b2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ##########################################################################This Data was copied to All Bonds sheet\n",
    "# bql_list = []\n",
    "\n",
    "# fl = [f\"\"\"=BQL(\"filter(bonds(['\"\"\",\n",
    "#       f\"\"\"']), payment_rank=='\"\"\",\n",
    "#       f\"\"\"' AND crncy=='\"\"\",\n",
    "#       f\"\"\"')\", \"id_isin, id_cusip, name, maturity, amt_outstanding\")\"\"\"]\n",
    "\n",
    "# for item, key in bbg_bonds_dict.items():\n",
    "#     bql_list += [fl[0] + item.split(\"_\")[0] + fl[1] + item.split(\"_\")[1] + fl[2] + item.split(\"_\")[2] + fl[3]]\n",
    "\n",
    "    \n",
    "# bql_list = [item.replace(\"\\\\\", \"\") for item in bql_list]\n",
    "\n",
    "# workbook = openpyxl.load_workbook(r\"J:\\\\HY Basis Data.xlsx\")\n",
    "# sheet = workbook.active\n",
    "\n",
    "# for row in sheet.iter_rows():\n",
    "#     for cell in row:\n",
    "#         cell.value = None\n",
    "\n",
    "# start_col = 1\n",
    "# for item in bql_list:\n",
    "#     cell = sheet.cell(row=2, column=start_col)\n",
    "#     cell.value = item\n",
    "#     start_col += 6\n",
    "# workbook.save(r\"J:\\\\HY Basis Data.xlsx\")\n",
    "\n",
    "# file_path = r\"J:\\\\HY Basis Data.xlsx\"\n",
    "# window_title = \"HY Basis Data - Excel\"\n",
    "\n",
    "# subprocess.Popen(['start', 'excel', file_path], shell=True)\n",
    "# time.sleep(5)\n",
    "\n",
    "# excel_windows = [window for window in gw.getWindowsWithTitle('Excel')]\n",
    "\n",
    "# for window in excel_windows:\n",
    "#     if window_title in window.title:\n",
    "#         # time.sleep(0.5)\n",
    "#         window.activate()\n",
    "#         break\n",
    "\n",
    "# time.sleep(45)\n",
    "# pyautogui.hotkey('ctrl', 's')\n",
    "# time.sleep(1)\n",
    "# # pyautogui.hotkey('alt', 'f4')\n",
    "\n",
    "# time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54affce-efdf-47c5-bfd4-f9eb3af6b60a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "bonds_map = []\n",
    "markit_to_bbg_tier_map_reverse = dict(zip(list(markit_to_bbg_tier_map.values()), list(markit_to_bbg_tier_map.keys())))\n",
    "\n",
    "for i in range(len(l1)):\n",
    "    bonds_map += [f\"{l1[i]}_{markit_to_bbg_tier_map_reverse[l2[i]]}_{l3[i]}\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "037cb256-d1d8-4b81-b084-65c8d09d5624",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"All Bonds.xlsx\", sheet_name=\"All Bonds\")\n",
    "l5 = [item.split(\"_\")[0].replace(\" Equity\",\"\") + \"_\" + markit_to_bbg_tier_map_reverse[item.split(\"_\")[1]] +\\\n",
    "      \"_\" + item.split(\"_\")[2] for item in list(bbg_bonds_dict.keys())]\n",
    "l6 = list(bbg_bonds_dict.values())\n",
    "\n",
    "all_df = None\n",
    "\n",
    "for i in range(len(df.columns))[::6]:\n",
    "    x = df.iloc[:,i:i+6].dropna().copy()\n",
    "    # display(l6[int(i/6)].split(\"_\")[0])\n",
    "    # display(df.iloc[:,i:i+6].dropna(how=\"all\"))\n",
    "    if len(x) > 0:\n",
    "        x.columns = ['ID','ISIN', \"CUSIP\", 'Name', 'Maturity','Amt']\n",
    "        x[\"Issuer Equity_tier_ccy\"] = [l5[int(i/6)]] * len(x)\n",
    "        x[\"Bond Name\"] = [l6[int(i/6)]] * len(x)\n",
    "        x[\"Check Col\"] = x.apply(lambda row: row[\"Name\"].split(\" \")[0]==row[\"Bond Name\"],axis=1)\n",
    "        x = x[x[\"Check Col\"]].drop([\"Check Col\",\"Bond Name\"],axis=1)\n",
    "        all_df = pd.concat([all_df, x])\n",
    "\n",
    "all_df['Time'] = round(((pd.to_datetime(all_df['Maturity'])-datetime.now()).dt.days/365),2)\n",
    "all_df = all_df[all_df[\"Time\"]>=0]\n",
    "all_df = all_df[(all_df['Time']>=4) & (all_df['Time']<=10)]\n",
    "all_df = all_df[all_df['Amt']>=300*10**6]\n",
    "all_df = all_df.reset_index(drop=True)\n",
    "excel_df = pd.concat([excel_df, all_df])\n",
    "all_df = excel_df.copy()\n",
    "\n",
    "all_df = all_df.drop_duplicates(keep=\"first\").reset_index(drop=True).copy()\n",
    "\n",
    "########################################################################################### 144A and REGS\n",
    "\n",
    "blist = [f'/isin/{item}@BGN' for item in list(all_df[\"ISIN\"])]\n",
    "blist = blp.bdp(tickers=blist, flds=[\"144A_FLAG\",\"IS_REG_S\"])\n",
    "blist.to_parquet(\"144A.parquet\")\n",
    "blist = pd.read_parquet(\"144A.parquet\")\n",
    "blist.index = [item.rsplit(\"/\",1)[1].split(\"@\")[0] for item in blist.index]\n",
    "\n",
    "blist.columns = [\"144A\",\"REGS\"]\n",
    "blist.index.name = \"ISIN\"\n",
    "blist = blist.reset_index()\n",
    "blist[\"REGS_144A\"] = blist.apply(lambda row: f'{row[\"REGS\"]}_{row[\"144A\"]}',axis=1)\n",
    "order = [\"N_N\", \"Y_N\", \"Y_Y\", \"N_Y\"]\n",
    "\n",
    "all_df = pd.merge(left=all_df, right=blist, on=\"ISIN\", how=\"outer\")\n",
    "all_df = all_df[[item for item in all_df.columns if not item in [\"144A\",\"REGS\"]]]\n",
    "\n",
    "all_df[\"REGS_144A\"] = pd.Categorical(all_df[\"REGS_144A\"], categories=order, ordered=True)\n",
    "all_df = all_df.sort_values(by=\"REGS_144A\")\n",
    "all_df = all_df[~all_df[\"Name\"].duplicated(keep='first')].drop([\"REGS_144A\",\"Time\"],axis=1).reset_index(drop=True).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96f17b33-0b0e-43d9-adb5-789fcd742d1c",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "t = [f\"/isin/{item}@BGN\" for item in list(all_df[\"ISIN\"])]\n",
    "bbg = blp.bdh(tickers=t, flds=\"BLOOMBERG_MID_G_SPREAD\", start_date=datetime.now()-timedelta(days=365*5))\n",
    "bbg.to_parquet(\"Test1.parquet\")\n",
    "bbg = pd.read_parquet(\"Test1.parquet\")\n",
    "\n",
    "bbg1 = bbg.copy()\n",
    "new = []\n",
    "for item in bbg1.columns:\n",
    "    new += [\"BBG_\" + item[0].replace(\"/isin/\",\"\").replace(\"@BGN\",\"\")]\n",
    "bbg1.columns = new\n",
    "bbg1.index = pd.to_datetime(bbg1.index)\n",
    "\n",
    "############################################################ choose bbg or dq sprds\n",
    "\n",
    "bbg1.columns = [item.split(\"_\")[1] for item in bbg1.columns]\n",
    "bbg1.index = [f\"Sprd_{str(item.date())}\" for item in bbg1.index]\n",
    "bbg1 = bbg1.T.copy()\n",
    "bbg1.index.name = \"ISIN\"\n",
    "bbg1 = bbg1.reset_index(drop=False).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32854e01-4e9d-4968-8aaf-2f12013de97b",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df2a = df2.drop([\"Primary ISIN\",\"Bond Name\"],axis=1).copy()\n",
    "df2a[\"Issuer Equity_tier_ccy\"] = [item.split(\"_\")[0] + \"_\" + item.split(\"_\")[2] +\\\n",
    "               \"_\" + item.split(\"_\")[3] for item in df2a[\"Issuer Equity_red_tier_ccy_docclause\"]]\n",
    "\n",
    "df3 = pd.merge(left=all_df, right=df2a, on=\"Issuer Equity_tier_ccy\",\\\n",
    "               how=\"inner\").drop([\"ID\",\"Amt\",\"Issuer Equity_tier_ccy\"],axis=1).copy()\n",
    "\n",
    "for dt in pd.to_datetime(bbg.index):\n",
    "    df3[f'Mat_Time_{dt.date()}'] = [((pd.to_datetime(item) - dt).days/365) for item in df3[\"Maturity\"]]\n",
    "\n",
    "df4A = df3.copy()\n",
    "dt_list = [item.replace(\"CDS_\",\"\") for item in df4A.columns if item.startswith(\"CDS_\")]\n",
    "\n",
    "# for dt in dt_list:\n",
    "#     if f\"Mat_Time_{dt}\" in df4A.columns and f\"CDS_{dt}\" in df4A.columns:\n",
    "#         df4A[f'Mat_Matched_CDS_{dt}'] = df4A[f'CDS_{dt}'].apply(lambda x: ast.\\\n",
    "#             literal_eval(x)[0] if isinstance(x,str) else np.nan) +\\\n",
    "#         df4A[f'Mat_Time_{dt}'].apply(lambda x: x) *\\\n",
    "#         df4A[f'CDS_{dt}'].apply(lambda x: ast.literal_eval(x)[1] if isinstance(x,str) else np.nan) +\\\n",
    "#         df4A[f'Mat_Time_{dt}'].apply(lambda x: x**2) *\\\n",
    "#         df4A[f'CDS_{dt}'].apply(lambda x: ast.literal_eval(x)[2] if isinstance(x,str) else np.nan)\n",
    "\n",
    "def safe_literal_eval(x):\n",
    "    try:\n",
    "        return ast.literal_eval(x) if isinstance(x, str) else [np.nan, np.nan, np.nan]\n",
    "    except (ValueError, SyntaxError):\n",
    "        return [np.nan, np.nan, np.nan]\n",
    "\n",
    "for dt in dt_list:\n",
    "    if f\"Mat_Time_{dt}\" in df4A.columns and f\"CDS_{dt}\" in df4A.columns:\n",
    "        cds_values = df4A[f'CDS_{dt}'].apply(safe_literal_eval)\n",
    "        mat_time = df4A[f'Mat_Time_{dt}']\n",
    "\n",
    "        df4A[f'Mat_Matched_CDS_{dt}'] = (\n",
    "            cds_values.apply(lambda x: x[0]) +\n",
    "            mat_time * cds_values.apply(lambda x: x[1]) +\n",
    "            mat_time**2 * cds_values.apply(lambda x: x[2]))\n",
    "\n",
    "df4 = df4A[[\"ISIN\",\"CUSIP\",\"Name\",\"Maturity\",\"Issuer Equity_red_tier_ccy_docclause\"] +\\\n",
    "    [col for col in df4A.columns if col.startswith(\"Mat_Matched_CDS\")]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73e39702-b143-44c1-8a89-847a2e625c59",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#################################################### Duration Data\n",
    "\n",
    "dq_bonds = ['US50077LBF22','US49456BAG68','US49456BAR24','US49456BAV36','US49456BAX91','US500255AX28','US50077LAL09','US50077LAV80','US50077LBN55','US526057CY87','US530715AJ01','US501044DV05','US48666KAY55','US48666KAZ21','US48666KBA60','US620076BT59','US626717AP72','US63938CAN83','US63938CAP32','US63938CAQ15','US651229BD74','US549271AF19','US55262CAJ99','US552676AT59','US552676AU23','US552953CJ87','US552953CK50','US55342UAM62','US55616XAM92','US58013MFQ24','US382550BJ95','US382550BK68','US382550BR12','US382550BS94','US404119CA57','US404119CC14','US404119CK30','US404119CQ00','US404119CT49','US337932AL12','US337932AP26','US345370CA64','US345370CX67','US345370DA55','US345370DB39','US35671DBJ37','US35671DCD57','US35671DCF06','US35671DCH61','US36186CBY84','US36962GXZ26','US370334CL64','US370334CT90','US37045VAH33','US37045VAY65','US37045VAZ31','US404119DB22','US404121AK12','US458140BR09','US651229BE57','US44107TBC99','US40434LAN55','US42307TAG31','US432833AF84','US437076CB65','US44106MAY84','US44106MBB72','US44107TAY29','US44107TAZ93','US651229BF23','US89352HBA68','US893830AF64','US902494AZ66','US911363AM11','US911365BL76','US911365BP80','US91324PEJ75','US911365BN33','US88947EAU47','US85172FAR01','US87264ABF12','US87264ABT16','US87264ABW45','US87264ABX28','US87264ACB98','US87264ACQ67','US87264ACV52','US87264ADT97','US87901JAH86','US88033GAV23','US88167AAR23','US88167AAS06','US88167AAT88','US962166BR41','US963320AY28','US963320AZ92','US963320BA33','US963320BC98','US963320BD71','US963320BE54','US969457BB59','US969457BM15','US969457BZ28','US969457CJ76','US988498AN16','US988498AP63','US988498AR20','XS0161100515','US931142FC22','US92343VEU44','US92343VFX73','US92343VGN82','US92343VGY48','US92343VGZ13','US925524AH30','US925524AV24','US92556HAB33','US92556HAD98','US680665AK27','US682691AA80','US682691AE03','US682691AF77','US682691AG50','US682691AJ99','US682691AK62','US682691AL46','US68389XBV64','US68389XCE31','US68389XCH61','US68389XCJ28','US69047QAC69','US674599EL59','US674599EK76','US65339KCU25','US65339KDJ60','US65339KDK34','US65339KDL17',\n",
    "'US674599DD43','US674599DE26','US674599EA94','US674599ED34','US674599EF81','US698900AG20','US75513ECR09','US78355HLC15','US78442FAZ18','US81761LAE20','US828807DT11','US716973AD41','US716973AE24','US717081EW90','US745867AM30','US745867AP60','US745867AT82','US74834LBC37','US30212PBH73','US1248EPCN14','US012873AK13','US012873AH83','US11135FAS02','US11135FBD24','US136385AE19','US134429BJ73','US126650DJ69','US00206RMM15','US126650DU15','US126650ED80','US031162DQ06','US026874DC84','US02406PBB58','US023551AM66','US023551AJ38','US097023CN34','US097023CP81','US097023CY98','US097023DC69','US097023DR39','US097023CJ22','US097023DS12','US023135AP19','US097023AU94','US023551AF16','US058498AW66','US058498AX40','US058498BA38','US07556QBT13','US08652BAB53','US071813BY49','US254709AS70','US244199BJ37','US247361ZT81','US251799AA02','US25179MBF95','US25179SAD27','US247361A329','US23331ABT51','US29273VAU44','US29273VBA70','US29278NAQ60','US30161NAX93','US30212PAR64','US29273VAT70','US29273RBE80','US28368EAD85','US28368EAE68','US292480AM22','US29273VAQ32','US292505AD65','US20030NEE76','US20030NDG34','US20030NBH35','US15089QAZ72','US15089QBA13','US15089QAY08','US00206RCP55','US15089QAP90','US00130HCG83','US15089QAX25','US205887AX04','XS2774392638','XS2655993033','XS3037720227','XS3023963534','XS3126635039','XS3106096178','XS3105513769','XS3091660194','XS2872799734','XS2870878456','XS2864439158','XS2811097075','XS2802883731','XS2826718087','XS2929387996','XS2922654418','XS2914769299','XS2904791774','XS2385393587','XS2116386132','XS2432162654','XS2247549731','XS2189766970','XS2300293003','XS2290544068','XS2056491587','XS2488809612','XS2010039894','FR001400WJR8','FR001400PAJ8','DE000A383HC1','CH0494734418','CH0591979627','DE000A4DFLQ6','US46284VAQ41','US501797AW48','US513272AD65','US513272AE49','US53219LAX73','US46284VAN10','US55617LAR33','US55617LAS16','US62482BAB80','US46284VAL53','US44332PAJ03','US46284VAF85','US37441QAA94','US428040DB25','US431318AV64','US431318AY04','US431318AZ78','US431318BC74','US431318BE31','US431318BG88','US432833AL52','US432833AN19','US432833AQ40','US432833AR23','US432833AS06','US44332PAG63','US62886HBP55','US46284VAJ08','US62886HBR12','US629377CS98','US629377CR16','US780153BV38','US780153BW11','US81211KAK60','US812127AB45','US812127AC28','US82967NBG25','US82967NBM92','US853496AG21','US853496AH04','US893830BZ10','US911365BR47','US92840VAP76','US92840VAR33','US947075AU14','US988498AL59','US780153BU54','US75606DAQ43','US737446AV69','US629377CW01','US629377CX83','US62957HAP01','US62957HAQ83','US63861CAF68','US64110LAU08','US64110LAV80','US677347CH71','US680665AN65','US68622FAB76','US68622TAB70','US737446AP91','US737446AQ74','US737446AR57','US737446AX26','US364760AQ18','US11135FBF71','US11135FBH38','US11135FBK66''US11135FBL40','US11135FBT75','US1248EPCD32','US1248EPCE15','US1248EPCK74','US1248EPCL57','US1248EPCP61','US1248EPCQ45''US1248EPCS01','US1248EPCT83','US126307BA42','US126307BB25','US103304BV23','US126307BD80','US097751CD18','US097751CB51','US00130HCC79','US01883LAD55','US01883LAH69','US03743QAQ10','US04433LAA08','US05368VAA44','US05368VAB27','US053773BH95','US053773BJ51','US053773BK25','US071734AJ60','US071734AL17','US097751AL51','US097751CA78','US097751CC35','US126307BF39','US126307BH94','US126307BK24','US224044CS42','US226373AT56','US23918KAS78','US23918KAT51','US23918KAW80','US23918KAY47','US185899AS01','US185899AR28','US12769GAA85','US12769GAD25','US131347CQ78','US143658BX94','US143658BY77','US364760AP35','US143658BZ43','US17888HAB96','US17888HAC79','US17888HAD52','US185899AL57','US185899AN14','US185899AP61','US185899AQ45','US143658CA82']\n",
    "\n",
    "dq_bonds = list(df4[\"ISIN\"])\n",
    "all_labels = dict(zip(df4[\"ISIN\"],[f\"DB(CREDIT,HY,BOND,{item},MDUR)\" for item in df4[\"CUSIP\"]]))\n",
    "\n",
    "labels = {}\n",
    "for item in dq_bonds:\n",
    "    labels[f\"{item}_Dur\"] = all_labels[item]\n",
    "\n",
    "try:\n",
    "    df1 = pd.read_excel(\"DQ HY Duration Data.xlsx/\",index_col=0, parse_dates=True)\n",
    "    dq = DataQuery(\n",
    "        client_id='jbAIMF2Tkp0JO3sc',\n",
    "        client_secret='d7qfzgt55pddjs352sgxosFyI4t2eja07k7opbi6wg9oqjc1OjkdAksn1btmnugeMjchcx2vwTsJupw',\n",
    "        calendar = 'CAL_USBANK',\n",
    "    )\n",
    "    \n",
    "    job = dq.create_job(expressions = list(labels.values()))\n",
    "    dq.start_date = str((datetime.now()-timedelta(days=5*365)).date())\n",
    "    job.execute(alert_long_requests='ignore')\n",
    "    df = job.to_pivot_table()\n",
    "    df = df.T\n",
    "    df.index.name = 'Date'\n",
    "    df.index = pd.to_datetime(df.index, format='%Y%m%d').date\n",
    "    df.columns.name = None\n",
    "    \n",
    "    df1 = pd.DataFrame()\n",
    "    for key in labels:\n",
    "        df1[key] = df[labels[key]]\n",
    "    \n",
    "    df1 = df1[list(labels.keys())].copy()\n",
    "    clear_output(wait=False)\n",
    "    df1.dropna(axis=1, how='all', inplace=True)\n",
    "    df1.to_excel(\"DQ HY Duration Data.xlsx\")\n",
    "except:\n",
    "    df1 = pd.read_excel(\"DQ HY Duration Data.xlsx\",index_col=0, parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0f99d405-a8e4-42ed-87f2-7eaf2e6e29d2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df1a = df1.copy()\n",
    "df1a = df1a.T\n",
    "df1a.index = df1a.index.str.replace(\"_Dur\",\"\")\n",
    "df1a.columns = [\"Dur_\" + str(item.date()) for item in df1a.columns]\n",
    "df1a.index.name=\"ISIN\"\n",
    "df1a = df1a.reset_index()\n",
    "\n",
    "df4B = pd.merge(left=df4, right=df1a, on=\"ISIN\", how=\"outer\")\n",
    "\n",
    "####################################################################\n",
    "\n",
    "t = [f\"/isin/{item}@BGN\" for item in list(all_df[\"ISIN\"])]\n",
    "px = blp.bdh(tickers=t, flds=\"PX_LAST\", start_date=datetime.now()-timedelta(days=365*5))\n",
    "px.to_parquet(\"Test2.parquet\")\n",
    "px = pd.read_parquet(\"Test2.parquet\")\n",
    "\n",
    "new = []\n",
    "for item in px.columns:\n",
    "    new += [item[0].replace(\"/isin/\",\"\").replace(\"@BGN\",\"\")]\n",
    "px.columns = new\n",
    "px = px.T\n",
    "px.columns = [\"Price_\" + str(item) for item in px.columns]\n",
    "px.index.name= \"ISIN\"\n",
    "px = px.reset_index()\n",
    "\n",
    "####################################################\n",
    "df5a = pd.merge(left=df4B, right=bbg1, on=\"ISIN\", how=\"inner\")\n",
    "last_update = max(dt_list)\n",
    "for dt in dt_list:\n",
    "    try:\n",
    "        df5a[f\"Basis_{dt}\"] = df5a[f\"Mat_Matched_CDS_{dt}\"] - df5a[f\"Sprd_{dt}\"]\n",
    "    except:\n",
    "        hello = 1\n",
    "\n",
    "df5a = pd.merge(left=df5a, right=px, on=\"ISIN\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2bdac9da-dc4a-481f-8364-39fefce2d561",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df5 = df5a.copy()\n",
    "df5 = df5[[\"ISIN\",\"CUSIP\",\"Name\",\"Maturity\",\"Issuer Equity_red_tier_ccy_docclause\"] +\\\n",
    "    [col for col in df5.columns if last_update in col or \"Basis_\" in col]].copy()\n",
    "\n",
    "####################################### Zscore and 1Y High/Low Calc\n",
    "\n",
    "dfz = df5[[\"ISIN\"] + [item for item in df5.columns if \"Basis\" in item]]\n",
    "dfz = dfz.set_index(\"ISIN\").T\n",
    "dfz.index = [pd.to_datetime(item.split(\"_\")[1]).date() for item in dfz.index]\n",
    "dfz = dfz.sort_index()\n",
    "\n",
    "all_z_df = None\n",
    "for period in [3*22, 6*22, 12*22]:\n",
    "    x = ((dfz-dfz.rolling(period, min_periods = int(0.6*period)).mean())/dfz.rolling(period,\\\n",
    "                  min_periods = int(0.6*period)).std()).iloc[[-1],:].copy()\n",
    "    x.index = [f'ZScore_{int(period/22)}M']\n",
    "    all_z_df = pd.concat([all_z_df , x])\n",
    "\n",
    "max_1y = pd.DataFrame(dfz.iloc[-12*22:,:].max()).T\n",
    "max_1y.index = [f'Basis 1Y High']\n",
    "min_1y = pd.DataFrame(dfz.iloc[-12*22:,:].min()).T\n",
    "min_1y.index = [f'Basis 1Y Low']\n",
    "\n",
    "all_z_df = pd.concat([all_z_df , max_1y, min_1y])\n",
    "all_z_df = all_z_df.T\n",
    "all_z_df = all_z_df.reset_index()\n",
    "\n",
    "df6 = pd.merge(left=df5.drop([col for col in df5.columns if col.\\\n",
    "    startswith(\"Basis_\") and not last_update in col],axis=1),\\\n",
    "               right=all_z_df, on=\"ISIN\", how=\"inner\").drop([\"CUSIP\",\"Maturity\"],axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8752c40-6c16-478d-920e-43ae34c6bc58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df7 = df6.drop(f\"Dur_{last_update}\",axis=1).copy()\n",
    "df7[\"Family\"] = df7[\"Issuer Equity_red_tier_ccy_docclause\"].apply(lambda x: f_dict[x])\n",
    "df7[\"CDS RED Code\"] =  df7[\"Issuer Equity_red_tier_ccy_docclause\"].apply(lambda x: x.split(\"_\")[1])\n",
    "df7.columns = df7.columns.str.replace(f\"_{last_update}\",\"\").str.replace(\"Mat_Matched_CDS\",\"Mat. Matched CDS\")\n",
    "df7[\"First Sort\"] = df7[\"Name\"].apply(lambda x: x.split(\" \")[0])\n",
    "df7[\"Second Sort\"] = df7[\"Name\"].apply(lambda x: x.rsplit(\"/\")[-1])\n",
    "\n",
    "df7 = df7.sort_values(by=[\"First Sort\",\"Second Sort\"],ascending=[True, True])\n",
    "df7 = df7.drop([\"ISIN\",\"Issuer Equity_red_tier_ccy_docclause\",\"First Sort\",\"Second Sort\"], axis=1).set_index(\"Name\").copy()\n",
    "\n",
    "df7 = df7[[\"Family\",\"CDS RED Code\",\"Price\",\"Sprd\",\"Mat. Matched CDS\",\"Basis\",\"Basis 1Y Low\",\"Basis 1Y High\",\\\n",
    "           \"ZScore_3M\",\"ZScore_6M\",\"ZScore_12M\"]].copy()\n",
    "df7 = round(df7,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22626355-4832-44e6-ad5b-57fec8147700",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "A = df5a[[\"ISIN\"]+[col for col in df5a.columns if col.startswith(\"Mat_Matched_CDS_\")]].set_index(\"ISIN\")\n",
    "A = A.T\n",
    "A.index = pd.to_datetime(A.index.str.replace(\"Mat_Matched_CDS_\",\"\"))\n",
    "A.columns = [f\"{item}_Mat_Matched_CDS_\" for item in A.columns]\n",
    "\n",
    "B = df5a[[\"ISIN\"]+[col for col in df5a.columns if col.startswith(\"Basis_\")]].set_index(\"ISIN\")\n",
    "B = B.T\n",
    "B.index = pd.to_datetime(B.index.str.replace(\"Basis_\",\"\"))\n",
    "B.columns = [f\"{item}_Basis\" for item in B.columns]\n",
    "\n",
    "C = df5a[[\"ISIN\"]+[col for col in df5a.columns if col.startswith(\"Sprd_\")]].set_index(\"ISIN\")\n",
    "C = C.T\n",
    "C.index = pd.to_datetime(C.index.str.replace(\"Sprd_\",\"\"))\n",
    "C.columns = [f\"{item}_G-Sprd\" for item in C.columns]\n",
    "\n",
    "D = df5a[[\"ISIN\"]+[col for col in df5a.columns if col.startswith(\"Price_\")]].set_index(\"ISIN\")\n",
    "D = D.T\n",
    "D.index = pd.to_datetime(D.index.str.replace(\"Price_\",\"\"))\n",
    "D.columns = [f\"{item}_Price\" for item in D.columns]\n",
    "\n",
    "E = df5a[[\"ISIN\"]+[col for col in df5a.columns if col.startswith(\"Dur_\")]].set_index(\"ISIN\")\n",
    "E = E.T\n",
    "E.index = pd.to_datetime(E.index.str.replace(\"Dur_\",\"\"))\n",
    "E.columns = [f\"{item}_Dur\" for item in E.columns]\n",
    "E = E.dropna(how='all',axis=1)\n",
    "\n",
    "for item in [\"A\",\"B\",\"C\",\"D\",\"E\"]:\n",
    "    globals()[f\"{item}\"].index = pd.to_datetime(globals()[f\"{item}\"].index)\n",
    "\n",
    "F = pd.concat([A,B,C,D,E], axis=1).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d9e9beb7-bc30-48b0-843e-fc36648386a1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# ######################### HY bonds TR data from BBG using BQL\n",
    "\n",
    "# import openpyxl\n",
    "# import subprocess\n",
    "# import time\n",
    "# import pyautogui\n",
    "# import pygetwindow as gw\n",
    "    \n",
    "# if True:\n",
    "#     bql_list = []\n",
    "    \n",
    "#     fl = [f'=BQL(\"', f\"\"\"ISIN\", \"return_series(calc_interval=range(-5y,0d,frq=d))\")\"\"\"]\n",
    "    \n",
    "#     issuers = df6[\"ISIN\"].to_list()\n",
    "    \n",
    "#     for item in issuers:\n",
    "#         bql_list += [(fl[0] + item + \" \" + fl[1])]\n",
    "        \n",
    "#     bql_list = [item.replace(\"\\\\\", \"\") for item in bql_list]\n",
    "    \n",
    "#     workbook = openpyxl.load_workbook(r\"J:\\\\55 BQL HY Bonds Rtn Data.xlsx\")\n",
    "#     sheet = workbook.active\n",
    "    \n",
    "#     for row in sheet.iter_rows():\n",
    "#         for cell in row:\n",
    "#             cell.value = None\n",
    "    \n",
    "#     start_col = 1\n",
    "#     for item in bql_list:\n",
    "#         cell = sheet.cell(row=2, column=start_col)\n",
    "#         cell.value = item\n",
    "#         start_col += 2\n",
    "#     workbook.save(r\"J:\\\\55 BQL HY Bonds Rtn Data.xlsx\")\n",
    "    \n",
    "#     file_path = r\"J:\\\\55 BQL HY Bonds Rtn Data.xlsx\"\n",
    "#     window_title = \"55 BQL HY Bonds Rtn Data - Excel\"\n",
    "    \n",
    "#     subprocess.Popen(['start', 'excel', file_path], shell=True)\n",
    "#     time.sleep(40)\n",
    "    \n",
    "#     excel_windows = [window for window in gw.getWindowsWithTitle('Excel')]\n",
    "    \n",
    "#     for check in range(2):\n",
    "#         for window in excel_windows:\n",
    "#             if window_title in window.title:\n",
    "#                 # time.sleep(0.25)\n",
    "#                 window.activate()\n",
    "#                 pyautogui.hotkey('ctrl', 's')\n",
    "#                 time.sleep(1)\n",
    "#                 pyautogui.hotkey('alt', 'f4')\n",
    "#                 # break\n",
    "    \n",
    "# time.sleep(0.5)\n",
    "\n",
    "# hy = pd.read_excel(r\"J:\\\\55 BQL HY Bonds Rtn Data.xlsx\",skiprows=1,parse_dates=True)\n",
    "# hy = hy.iloc[1:,:]\n",
    "# hy = hy[[hy.columns[0]] + [col for col in hy.columns if \"ISIN\" in col]]\n",
    "# hy.columns = [\"Date\"] + [item.replace(\" ISIN\",\"_Daily_Rtn\") for item in list(hy.columns)[1:]]\n",
    "# hy = hy.set_index(\"Date\")\n",
    "# hy.index = pd.to_datetime(hy.index)\n",
    "# hy = (1+hy).cumprod()\n",
    "# hy_col = hy.columns\n",
    "# for col in hy_col:\n",
    "#     hy[f'{col.split(\"_\")[0]} FWD_1M_Rtn'] = (hy[col].shift(-21) / hy[col] - 1) * 100\n",
    "#     hy[f'{col.split(\"_\")[0]} FWD_3M_Rtn'] = (hy[col].shift(-63) / hy[col] - 1) * 100\n",
    "#     hy[f'{col.split(\"_\")[0]} FWD_6M_Rtn'] = (hy[col].shift(-126) / hy[col] - 1) * 100\n",
    "# hy = hy[[col for col in hy.columns if \"FWD\" in col]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dae2dc39-d4d0-4c56-90f8-4a0f426fd117",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# df = pd.concat([F, hy],axis=1).sort_index().copy()\n",
    "\n",
    "df = F.sort_index().copy()\n",
    "df.columns = df.columns.str.replace(\"_Mat_Matched_CDS_\",\" Mat. Matched CDS\").\\\n",
    "    str.replace(\"_Basis\",\" Basis\").str.replace(\"_Dur\",\" Duration\").\\\n",
    "    str.replace(\"_Price\",\" Price\").str.replace(\"_G-Sprd\",\" G-Sprd\")\n",
    "\n",
    "bond_dict = dict(zip(list(df5a[\"ISIN\"]),list(df5a[\"Name\"])))\n",
    "df.columns = [f\"{bond_dict[item.split(\" \",1)[0]]} {item.split(\" \",1)[1]}\"  for item in df.columns]\n",
    "df = df.dropna(how=\"all\").copy()\n",
    "df.columns = [f\"{item.split(\"/\",1)[0].rsplit(\" \",1)[0]}% due {item.\\\n",
    "    rsplit(\"/\",1)[1]}\" for item in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f519a4ae-33eb-4bd5-b2ec-603b6d9ec0c8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tickers_bbg = ['IBOXHY INDEX', 'IBOXIG INDEX']\n",
    "fields_bbg = ['PX_LAST', 'CONTRBTD_ZSPREAD', 'OAS_SOVEREIGN_CURVE', 'OPTION_ADJ_DURATION_SOV_CRV', 'YIELD_TO_MATURITY']\n",
    "start_date_bbg = \"2000-01-01\"\n",
    "end_date_bbg = datetime.now().strftime('%Y-%m-%d')\n",
    "df_bbg = blp.bdh(tickers=tickers_bbg, flds=fields_bbg, start_date=start_date_bbg, end_date=end_date_bbg)\n",
    "list1_bbg = ['TR', 'Z-Sprd', 'OAS', 'Dur', 'Yield']\n",
    "df_bbg.columns = ['BBG iBoxx HY ' + item for item in list1_bbg] + ['BBG iBoxx IG ' + item for item in list1_bbg] \n",
    "df_bbg.drop(['BBG iBoxx HY Dur', 'BBG iBoxx IG Yield'], axis=1, inplace=True) # First is wrong and second incomplete\n",
    "df_bbg = df_bbg.astype(float)\n",
    "\n",
    "tick = ['USGG5YR INDEX','USGG7YR INDEX','USGG10YR INDEX']\n",
    "all_x = None\n",
    "x = blp.bdh(tickers = tick, flds = 'PX_LAST', start_date = df_bbg.index[0])#, end_date = df_bbg.index[-1])\n",
    "for col in ['BBG']:# + list(set([item.split(' ',1)[0] for item in df_back.columns])):\n",
    "    x1 = x.copy()\n",
    "    x1.columns = [f'{col} US 5Y', f'{col} US 7Y', f'{col} US 10Y']\n",
    "    all_x = pd.concat([all_x,x1],axis=1)\n",
    "df_bbg = pd.concat([df_bbg,all_x],axis=1)\n",
    "\n",
    "tick = ['COA Comdty','VIX Index']\n",
    "x = blp.bdh(tickers = tick, flds='PX_LAST', start_date = df_bbg.index[0])#, end_date = df_bbg.index[-1])\n",
    "x.columns = ['BBG COA Comdty','BBG VIX Index']\n",
    "x = x.sort_index()\n",
    "df_bbg = pd.concat([df_bbg,x],axis=1)\n",
    "df_bbg.index = pd.to_datetime(df_bbg.index)\n",
    "\n",
    "backup = df.copy()\n",
    "df = pd.concat([backup, df_bbg], axis=1).sort_index().copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66854374-5e66-4e93-afdd-3158bda8952a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "options = sorted(backup.columns, key=lambda item: (item.split(' ', 1)[0], 2000 + \\\n",
    "            eval(item.split('due ', 1)[1].split(' ', 1)[0]) if eval(item.split('due ', 1)[1].split(' ', 1)[0])\\\n",
    "                    < 2000 else eval(item.split('due ', 1)[1].split(' ', 1)[0])))\n",
    "\n",
    "options += list(df_bbg.columns)\n",
    "fwd = [item for item in options if 'FWD_' in item]\n",
    "non_fwd = [item for item in options if not('FWD_' in item)]\n",
    "options = non_fwd + fwd\n",
    "\n",
    "time = ['All','2Y','1Y','6M','3M']\n",
    "\n",
    "#################################### Changing order of names\n",
    "o1 = [item for item in options if ((not 'FWD' in item) and ('%' in item))]\n",
    "o2 = [item for item in options if not item in o1]\n",
    "\n",
    "desired_order = [\"Price\", \"G-Sprd\", \"Basis\", \"Duration\", \"CDS\"]\n",
    "\n",
    "def reorder_items_in_chunks(items, order):\n",
    "    chunk_size = len(set([item.rsplit(' ',1)[1] for item in options if ((not 'FWD' in item) and ('%' in item))]))\n",
    "    reordered = []\n",
    "    for i in range(0, len(items), chunk_size):\n",
    "        chunk = items[i:i + chunk_size]\n",
    "        valid_items = [item for item in chunk if len(item.rsplit(' ', 1)) == 2]\n",
    "        reordered_chunk = sorted(valid_items, key=lambda x: order.index(x.rsplit(' ', 1)[1]))\n",
    "        reordered.extend(reordered_chunk)\n",
    "    return reordered\n",
    "\n",
    "o1_reordered = reorder_items_in_chunks(o1, desired_order)\n",
    "options = o1 + o2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b06e1124-dd64-46be-8fef-f3fcd3eb8ea2",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "############ Default bonds\n",
    "# x = df5a[[\"Name\",\"ISIN\"]].copy()\n",
    "# x[\"Eqty Name\"] = df5a[\"Issuer Equity_red_tier_ccy_docclause\"].apply(lambda x: x.split(\"_\")[0])\n",
    "# issue = blp.bdp(tickers=[f\"/isin/{item}@BGN\" for item in x[\"ISIN\"]], flds=\"ISSUE_DT\")\n",
    "# issue1 = issue.copy()\n",
    "# issue1.index = issue1.index.str.replace(\"/isin/\",\"\").str.replace(\"@BGN\",\"\")\n",
    "# issue1.index.name = \"ISIN\"\n",
    "# issue1 = issue1.reset_index()\n",
    "# x = pd.merge(left=x, right=issue1, on=\"ISIN\", how=\"outer\")\n",
    "# x[\"Age\"] = round((datetime.now() - pd.to_datetime(x[\"issue_dt\"])).dt.days/365,2)\n",
    "# x = x[[\"Name\",\"Eqty Name\",\"Age\"]].copy()\n",
    "# x = x.sort_values(by=[\"Eqty Name\",\"Age\"], ascending=[True, False]).reset_index(drop=True).copy()\n",
    "# x = x.drop_duplicates(subset=\"Eqty Name\", keep=\"first\")[[\"Name\"]].copy()\n",
    "# x[\"Name\"] = x[\"Name\"].apply(lambda x: x.rsplit(\" \",1)[0] + \"% due \" + x.rsplit(\"/\",1)[-1])\n",
    "# x[\"MMC\"] = x[\"Name\"].apply(lambda x: [f\"{x.split(\" \",1)[1]} Mat. Matched CDS\", f\"{x.split(\" \",1)[1]} Basis\"])\n",
    "# x[\"Name\"] = x[\"Name\"].apply(lambda x: f\"{x.split(\" \",1)[0]}\")\n",
    "# dict(zip(x[\"Name\"], x[\"MMC\"]))\n",
    "\n",
    "\n",
    "\n",
    "default_values_dict = \\\n",
    "{'TOL': ['3.8% due 29 Mat. Matched CDS', '3.8% due 29 Basis'],\n",
    " 'PUBFP': ['1 ¾% due 31 Mat. Matched CDS', '1 ¾% due 31 Basis'],\n",
    " 'ZIGGO': ['3 ⅜% due 30 Mat. Matched CDS', '3 ⅜% due 30 Basis'],\n",
    " 'CAR': ['8% due 31 Mat. Matched CDS', '8% due 31 Basis'],\n",
    " 'WFRD': ['8 ⅝% due 30 Mat. Matched CDS', '8 ⅝% due 30 Basis'],\n",
    " 'MPW': ['3 ½% due 31 Mat. Matched CDS', '3 ½% due 31 Basis'],\n",
    " 'CHTR': ['4 ¾% due 30 Mat. Matched CDS', '4 ¾% due 30 Basis'],\n",
    " 'TSCOLN': ['4 ¼% due 31 Mat. Matched CDS', '4 ¼% due 31 Basis'],\n",
    " 'HOUS': ['5 ¼% due 30 Mat. Matched CDS', '5 ¼% due 30 Basis'],\n",
    " 'SIRI': ['4 ⅛% due 30 Mat. Matched CDS', '4 ⅛% due 30 Basis'],\n",
    " 'TELEFO': ['5 ⅞% due 33 Mat. Matched CDS', '5 ⅞% due 33 Basis'],\n",
    " 'BMW': ['0 ⅞% due 32 Mat. Matched CDS', '0 ⅞% due 32 Basis'],\n",
    " 'SIEGR': ['1 ⅜% due 30 Mat. Matched CDS', '1 ⅜% due 30 Basis'],\n",
    " 'CSCHLD': ['5 ¾% due 30 Mat. Matched CDS', '5 ¾% due 30 Basis'],\n",
    " 'SPG': ['2.45% due 29 Mat. Matched CDS', '2.45% due 29 Basis'],\n",
    " 'ALVGR': ['1 ⅜% due 31 Mat. Matched CDS', '1 ⅜% due 31 Basis'],\n",
    " 'RGCARE': ['10% due 32 Mat. Matched CDS', '10% due 32 Basis'],\n",
    " 'SZUGR': ['4 ⅛% due 32 Mat. Matched CDS', '4 ⅛% due 32 Basis'],\n",
    " 'VW': ['3.3% due 33 Mat. Matched CDS', '3.3% due 33 Basis'],\n",
    " 'SPMIM': ['4 ⅞% due 30 Mat. Matched CDS', '4 ⅞% due 30 Basis'],\n",
    " 'GSK': ['1 ⅜% due 29 Mat. Matched CDS', '1 ⅜% due 29 Basis'],\n",
    " 'TEVA': ['8 ⅛% due 31 Mat. Matched CDS', '8 ⅛% due 31 Basis'],\n",
    " 'HLT': ['4 ⅞% due 30 Mat. Matched CDS', '4 ⅞% due 30 Basis'],\n",
    " 'VST': ['7 ¾% due 31 Mat. Matched CDS', '7 ¾% due 31 Basis'],\n",
    " 'CMACG': ['5% due 31 Mat. Matched CDS', '5% due 31 Basis'],\n",
    " 'ALIANT': ['5 ⅞% due 29 Mat. Matched CDS', '5 ⅞% due 29 Basis'],\n",
    " 'DUFNSW': ['4 ¾% due 31 Mat. Matched CDS', '4 ¾% due 31 Basis'],\n",
    " 'AXL': ['5% due 29 Mat. Matched CDS', '5% due 29 Basis'],\n",
    " 'IMBLN': ['3 ⅞% due 34 Mat. Matched CDS', '3 ⅞% due 34 Basis'],\n",
    " 'ZFFNGR': ['3% due 29 Mat. Matched CDS', '3% due 29 Basis'],\n",
    " 'TMUS': ['2 ⅞% due 31 Mat. Matched CDS', '2 ⅞% due 31 Basis'],\n",
    " 'URI': ['5 ¼% due 30 Mat. Matched CDS', '5 ¼% due 30 Basis'],\n",
    " 'DOW': ['7 ⅜% due 29 Mat. Matched CDS', '7 ⅜% due 29 Basis'],\n",
    " 'NCLH': ['6 ¼% due 30 Mat. Matched CDS', '6 ¼% due 30 Basis'],\n",
    " 'M': ['4 ½% due 34 Mat. Matched CDS', '4 ½% due 34 Basis'],\n",
    " 'BPLN': ['1.231% due 31 Mat. Matched CDS', '1.231% due 31 Basis'],\n",
    " 'JCI': ['1 ¾% due 30 Mat. Matched CDS', '1 ¾% due 30 Basis'],\n",
    " 'AALLN': ['4 ¾% due 32 Mat. Matched CDS', '4 ¾% due 32 Basis'],\n",
    " 'OGN': ['5 ⅛% due 31 Mat. Matched CDS', '5 ⅛% due 31 Basis'],\n",
    " 'LOUDRE': ['3 ½% due 31 Mat. Matched CDS', '3 ½% due 31 Basis'],\n",
    " 'MEDIND': ['5 ¼% due 29 Mat. Matched CDS', '5 ¼% due 29 Basis'],\n",
    " 'HOLNSW': ['1 ¾% due 29 Mat. Matched CDS', '1 ¾% due 29 Basis'],\n",
    " 'GLENLN': ['1 ¼% due 33 Mat. Matched CDS', '1 ¼% due 33 Basis'],\n",
    " 'NRUC': ['8% due 32 Mat. Matched CDS', '8% due 32 Basis'],\n",
    " 'LINTA': ['4% due 29 Mat. Matched CDS', '4% due 29 Basis'],\n",
    " 'CARLB': ['0 ⅝% due 30 Mat. Matched CDS', '0 ⅝% due 30 Basis'],\n",
    " 'RIG': ['7 ½% due 31 Mat. Matched CDS', '7 ½% due 31 Basis'],\n",
    " 'REPSM': ['2 ⅝% due 30 Mat. Matched CDS', '2 ⅝% due 30 Basis'],\n",
    " 'NBR': ['9 ⅛% due 30 Mat. Matched CDS', '9 ⅛% due 30 Basis'],\n",
    " 'HILCRP': ['6% due 31 Mat. Matched CDS', '6% due 31 Basis'],\n",
    " 'CE': ['6.629% due 32 Mat. Matched CDS', '6.629% due 32 Basis'],\n",
    " 'HST': ['3 ⅜% due 29 Mat. Matched CDS', '3 ⅜% due 29 Basis'],\n",
    " 'HRB': ['3 ⅞% due 30 Mat. Matched CDS', '3 ⅞% due 30 Basis'],\n",
    " 'BATSLN': ['2 ¼% due 30 Mat. Matched CDS', '2 ¼% due 30 Basis'],\n",
    " 'TRPCN': ['5.6% due 34 Mat. Matched CDS', '5.6% due 34 Basis'],\n",
    " 'BRITEL': ['1 ⅛% due 29 Mat. Matched CDS', '1 ⅛% due 29 Basis'],\n",
    " 'RDSALN': ['0 ½% due 31 Mat. Matched CDS', '0 ½% due 31 Basis'],\n",
    " 'BMCAUS': ['4 ⅜% due 30 Mat. Matched CDS', '4 ⅜% due 30 Basis'],\n",
    " 'NEE': ['2 ¾% due 29 Mat. Matched CDS', '2 ¾% due 29 Basis'],\n",
    " 'HTZ': ['5% due 29 Mat. Matched CDS', '5% due 29 Basis'],\n",
    " 'VMED': ['3 ¾% due 30 Mat. Matched CDS', '3 ¾% due 30 Basis'],\n",
    " 'VLVY': ['3% due 30 Mat. Matched CDS', '3% due 30 Basis'],\n",
    " 'HCA': ['3 ½% due 30 Mat. Matched CDS', '3 ½% due 30 Basis'],\n",
    " 'AIFP': ['0 ⅝% due 30 Mat. Matched CDS', '0 ⅝% due 30 Basis'],\n",
    " 'NTGYSM': ['1 ⅞% due 29 Mat. Matched CDS', '1 ⅞% due 29 Basis'],\n",
    " 'ABIBB': ['3 ¼% due 33 Mat. Matched CDS', '3 ¼% due 33 Basis'],\n",
    " 'ACFP': ['3 ⅞% due 31 Mat. Matched CDS', '3 ⅞% due 31 Basis'],\n",
    " 'ACAFP': ['2% due 30 Mat. Matched CDS', '2% due 30 Basis'],\n",
    " 'AEP': ['2.3% due 30 Mat. Matched CDS', '2.3% due 30 Basis'],\n",
    " 'AES': ['3.95% due 30 Mat. Matched CDS', '3.95% due 30 Basis'],\n",
    " 'AFFP': ['3 ¾% due 30 Mat. Matched CDS', '3 ¾% due 30 Basis'],\n",
    " 'OMF': ['5 ⅜% due 29 Mat. Matched CDS', '5 ⅜% due 29 Basis'],\n",
    " 'AIG': ['3 ⅞% due 35 Mat. Matched CDS', '3 ⅞% due 35 Basis'],\n",
    " 'AIRFP': ['2 ⅛% due 29 Mat. Matched CDS', '2 ⅛% due 29 Basis'],\n",
    " 'AKZANA': ['1 ⅝% due 30 Mat. Matched CDS', '1 ⅝% due 30 Basis'],\n",
    " 'ALL': ['5.35% due 33 Mat. Matched CDS', '5.35% due 33 Basis'],\n",
    " 'ALLY': ['8% due 31 Mat. Matched CDS', '8% due 31 Basis'],\n",
    " 'ALOFP': ['0 ½% due 30 Mat. Matched CDS', '0 ½% due 30 Basis'],\n",
    " 'AMD': ['2 ⅜% due 30 Mat. Matched CDS', '2 ⅜% due 30 Basis'],\n",
    " 'AMGN': ['2.45% due 30 Mat. Matched CDS', '2.45% due 30 Basis'],\n",
    " 'AMZN': ['4.8% due 34 Mat. Matched CDS', '4.8% due 34 Basis'],\n",
    " 'APA': ['4 ¼% due 30 Mat. Matched CDS', '4 ¼% due 30 Basis'],\n",
    " 'ARW': ['2.95% due 32 Mat. Matched CDS', '2.95% due 32 Basis'],\n",
    " 'ASH': ['3 ⅜% due 31 Mat. Matched CDS', '3 ⅜% due 31 Basis'],\n",
    " 'ATLIM': ['4 ½% due 30 Mat. Matched CDS', '4 ½% due 30 Basis'],\n",
    " 'AVGO': ['4.15% due 30 Mat. Matched CDS', '4.15% due 30 Basis'],\n",
    " 'AVNT': ['7 ⅛% due 30 Mat. Matched CDS', '7 ⅛% due 30 Basis'],\n",
    " 'AVT': ['3% due 31 Mat. Matched CDS', '3% due 31 Basis'],\n",
    " 'AXP': ['4.42% due 33 Mat. Matched CDS', '4.42% due 33 Basis'],\n",
    " 'AZN': ['3 ¾% due 32 Mat. Matched CDS', '3 ¾% due 32 Basis'],\n",
    " 'AZO': ['4% due 30 Mat. Matched CDS', '4% due 30 Basis'],\n",
    " 'BA': ['6 ⅛% due 33 Mat. Matched CDS', '6 ⅛% due 33 Basis'],\n",
    " 'BALL': ['2 ⅞% due 30 Mat. Matched CDS', '2 ⅞% due 30 Basis'],\n",
    " 'BACR': ['1 ⅛% due 31 Mat. Matched CDS', '1 ⅛% due 31 Basis'],\n",
    " 'BASGR': ['3% due 33 Mat. Matched CDS', '3% due 33 Basis'],\n",
    " 'BAX': ['3.95% due 30 Mat. Matched CDS', '3.95% due 30 Basis'],\n",
    " 'BAYNGR': ['2 ⅛% due 29 Mat. Matched CDS', '2 ⅛% due 29 Basis'],\n",
    " 'BBDBCN': ['7.45% due 34 Mat. Matched CDS', '7.45% due 34 Basis'],\n",
    " 'BBVASM': ['5 ¾% due 33 Mat. Matched CDS', '5 ¾% due 33 Basis'],\n",
    " 'BBWI': ['6 ⅝% due 30 Mat. Matched CDS', '6 ⅝% due 30 Basis'],\n",
    " 'BBY': ['1.95% due 30 Mat. Matched CDS', '1.95% due 30 Basis'],\n",
    " 'BHCCN': ['5 ¼% due 30 Mat. Matched CDS', '5 ¼% due 30 Basis'],\n",
    " 'BMY': ['1.45% due 30 Mat. Matched CDS', '1.45% due 30 Basis'],\n",
    " 'BNFP': ['0.52% due 30 Mat. Matched CDS', '0.52% due 30 Basis'],\n",
    " 'BNP': ['2 ⅜% due 30 Mat. Matched CDS', '2 ⅜% due 30 Basis'],\n",
    " 'BRK': ['6 ½% due 34 Mat. Matched CDS', '6 ½% due 34 Basis'],\n",
    " 'BSX': ['2.65% due 30 Mat. Matched CDS', '2.65% due 30 Basis'],\n",
    " 'BERTEL': ['1 ½% due 30 Mat. Matched CDS', '1 ½% due 30 Basis'],\n",
    " 'BWA': ['5.4% due 34 Mat. Matched CDS', '5.4% due 34 Basis'],\n",
    " 'BYD': ['4 ¾% due 31 Mat. Matched CDS', '4 ¾% due 31 Basis'],\n",
    " 'BZH': ['7 ¼% due 29 Mat. Matched CDS', '7 ¼% due 29 Basis'],\n",
    " 'CAFP': ['2 ⅜% due 29 Mat. Matched CDS', '2 ⅜% due 29 Basis'],\n",
    " 'CAG': ['8 ¼% due 30 Mat. Matched CDS', '8 ¼% due 30 Basis'],\n",
    " 'CAH': ['5.45% due 34 Mat. Matched CDS', '5.45% due 34 Basis'],\n",
    " 'CMZB': ['4% due 30 Mat. Matched CDS', '4% due 30 Basis'],\n",
    " 'CCL': ['6 ⅛% due 33 Mat. Matched CDS', '6 ⅛% due 33 Basis'],\n",
    " 'CIVI': ['8 ¾% due 31 Mat. Matched CDS', '8 ¾% due 31 Basis'],\n",
    " 'CLF': ['4 ⅞% due 31 Mat. Matched CDS', '4 ⅞% due 31 Basis'],\n",
    " 'CLNXSM': ['1 ¾% due 30 Mat. Matched CDS', '1 ¾% due 30 Basis'],\n",
    " 'CMCSA': ['7.05% due 33 Mat. Matched CDS', '7.05% due 33 Basis'],\n",
    " 'CNQCN': ['7.2% due 32 Mat. Matched CDS', '7.2% due 32 Basis'],\n",
    " 'COF': ['2.7% due 30 Mat. Matched CDS', '2.7% due 30 Basis'],\n",
    " 'CONGR': ['3 ½% due 29 Mat. Matched CDS', '3 ½% due 29 Basis'],\n",
    " 'COXENT': ['4.8% due 35 Mat. Matched CDS', '4.8% due 35 Basis'],\n",
    " 'CPB': ['2 ⅜% due 30 Mat. Matched CDS', '2 ⅜% due 30 Basis'],\n",
    " 'CPGLN': ['3 ¼% due 31 Mat. Matched CDS', '3 ¼% due 31 Basis'],\n",
    " 'CPN': ['5% due 31 Mat. Matched CDS', '5% due 31 Basis'],\n",
    " 'AXASA': ['3 ¾% due 30 Mat. Matched CDS', '3 ¾% due 30 Basis'],\n",
    " 'CSCO': ['4.95% due 31 Mat. Matched CDS', '4.95% due 31 Basis'],\n",
    " 'CSTM': ['5 ⅜% due 32 Mat. Matched CDS', '5 ⅜% due 32 Basis'],\n",
    " 'CSX': ['2.4% due 30 Mat. Matched CDS', '2.4% due 30 Basis'],\n",
    " 'CVS': ['4 ⅞% due 35 Mat. Matched CDS', '4 ⅞% due 35 Basis'],\n",
    " 'CZR': ['4 ⅝% due 29 Mat. Matched CDS', '4 ⅝% due 29 Basis'],\n",
    " 'D': ['6.3% due 33 Mat. Matched CDS', '6.3% due 33 Basis'],\n",
    " 'DAL': ['3 ¾% due 29 Mat. Matched CDS', '3 ¾% due 29 Basis'],\n",
    " 'DANBNK': ['1 ½% due 30 Mat. Matched CDS', '1 ½% due 30 Basis'],\n",
    " 'DB': ['5 ⅝% due 31 Mat. Matched CDS', '5 ⅝% due 31 Basis'],\n",
    " 'DE': ['7 ⅛% due 31 Mat. Matched CDS', '7 ⅛% due 31 Basis'],\n",
    " 'DGFP': ['1 ¾% due 30 Mat. Matched CDS', '1 ¾% due 30 Basis'],\n",
    " 'DGX': ['2.95% due 30 Mat. Matched CDS', '2.95% due 30 Basis'],\n",
    " 'DHI': ['5% due 34 Mat. Matched CDS', '5% due 34 Basis'],\n",
    " 'DHR': ['2.6% due 29 Mat. Matched CDS', '2.6% due 29 Basis'],\n",
    " 'DIS': ['7% due 32 Mat. Matched CDS', '7% due 32 Basis'],\n",
    " 'DRI': ['6.3% due 33 Mat. Matched CDS', '6.3% due 33 Basis'],\n",
    " 'DT': ['7 ½% due 33 Mat. Matched CDS', '7 ½% due 33 Basis'],\n",
    " 'DVA': ['4 ⅝% due 30 Mat. Matched CDS', '4 ⅝% due 30 Basis'],\n",
    " 'DVN': ['7 ⅞% due 31 Mat. Matched CDS', '7 ⅞% due 31 Basis'],\n",
    " 'EDF': ['5 ⅝% due 33 Mat. Matched CDS', '5 ⅝% due 33 Basis'],\n",
    " 'EDPPL': ['1 ⅞% due 29 Mat. Matched CDS', '1 ⅞% due 29 Basis'],\n",
    " 'ELTLX': ['2 ½% due 30 Mat. Matched CDS', '2 ½% due 30 Basis'],\n",
    " 'EMN': ['5 ¾% due 33 Mat. Matched CDS', '5 ¾% due 33 Basis'],\n",
    " 'ENFP': ['0 ½% due 30 Mat. Matched CDS', '0 ½% due 30 Basis'],\n",
    " 'ENBCN': ['3 ⅛% due 29 Mat. Matched CDS', '3 ⅛% due 29 Basis'],\n",
    " 'ENGIFP': ['1 ½% due 35 Mat. Matched CDS', '1 ½% due 35 Basis'],\n",
    " 'ENIIM': ['1% due 34 Mat. Matched CDS', '1% due 34 Basis'],\n",
    " 'EOANGR': ['5 ¾% due 33 Mat. Matched CDS', '5 ¾% due 33 Basis'],\n",
    " 'EQNR': ['1 ⅝% due 35 Mat. Matched CDS', '1 ⅝% due 35 Basis'],\n",
    " 'ET': ['4.9% due 35 Mat. Matched CDS', '4.9% due 35 Basis'],\n",
    " 'EXC': ['5 ⅝% due 35 Mat. Matched CDS', '5 ⅝% due 35 Basis'],\n",
    " 'EXPE': ['3 ¼% due 30 Mat. Matched CDS', '3 ¼% due 30 Basis'],\n",
    " 'F': ['7.45% due 31 Mat. Matched CDS', '7.45% due 31 Basis'],\n",
    " 'FCX': ['5.4% due 34 Mat. Matched CDS', '5.4% due 34 Basis'],\n",
    " 'FDX': ['4 ¼% due 30 Mat. Matched CDS', '4 ¼% due 30 Basis'],\n",
    " 'FE': ['4.55% due 30 Mat. Matched CDS', '4.55% due 30 Basis'],\n",
    " 'FUMVFH': ['4 ½% due 33 Mat. Matched CDS', '4 ½% due 33 Basis'],\n",
    " 'FRFP': ['4 ½% due 30 Mat. Matched CDS', '4 ½% due 30 Basis'],\n",
    " 'EOFP': ['5 ½% due 31 Mat. Matched CDS', '5 ½% due 31 Basis'],\n",
    " 'ASSGEN': ['2.124% due 30 Mat. Matched CDS', '2.124% due 30 Basis'],\n",
    " 'GAP': ['3 ⅝% due 29 Mat. Matched CDS', '3 ⅝% due 29 Basis'],\n",
    " 'GE': ['6 ¾% due 32 Mat. Matched CDS', '6 ¾% due 32 Basis'],\n",
    " 'GFLCN': ['6 ⅝% due 32 Mat. Matched CDS', '6 ⅝% due 32 Basis'],\n",
    " 'GIS': ['2 ⅞% due 30 Mat. Matched CDS', '2 ⅞% due 30 Basis'],\n",
    " 'SOCGEN': ['1% due 30 Mat. Matched CDS', '1% due 30 Basis'],\n",
    " 'GM': ['5% due 35 Mat. Matched CDS', '5% due 35 Basis'],\n",
    " 'GS': ['6 ⅛% due 33 Mat. Matched CDS', '6 ⅛% due 33 Basis'],\n",
    " 'GT': ['5 ¼% due 31 Mat. Matched CDS', '5 ¼% due 31 Basis'],\n",
    " 'HAL': ['2.92% due 30 Mat. Matched CDS', '2.92% due 30 Basis'],\n",
    " 'HBGCN': ['5 ⅝% due 29 Mat. Matched CDS', '5 ⅝% due 29 Basis'],\n",
    " 'HD': ['2.7% due 30 Mat. Matched CDS', '2.7% due 30 Basis'],\n",
    " 'HEIGR': ['3 ¾% due 32 Mat. Matched CDS', '3 ¾% due 32 Basis'],\n",
    " 'HEIANA': ['2.02% due 32 Mat. Matched CDS', '2.02% due 32 Basis'],\n",
    " 'HENKEL': ['0 ½% due 32 Mat. Matched CDS', '0 ½% due 32 Basis'],\n",
    " 'HES': ['7 ⅞% due 29 Mat. Matched CDS', '7 ⅞% due 29 Basis'],\n",
    " 'KHC': ['6 ¾% due 32 Mat. Matched CDS', '6 ¾% due 32 Basis'],\n",
    " 'HON': ['1.95% due 30 Mat. Matched CDS', '1.95% due 30 Basis'],\n",
    " 'HOTGR': ['4 ¼% due 30 Mat. Matched CDS', '4 ¼% due 30 Basis'],\n",
    " 'HPQ': ['3.4% due 30 Mat. Matched CDS', '3.4% due 30 Basis'],\n",
    " 'HSBC': ['0.77% due 31 Mat. Matched CDS', '0.77% due 31 Basis'],\n",
    " 'IBM': ['5 ⅞% due 32 Mat. Matched CDS', '5 ⅞% due 32 Basis'],\n",
    " 'INTNED': ['2 ½% due 30 Mat. Matched CDS', '2 ½% due 30 Basis'],\n",
    " 'INTC': ['4% due 32 Mat. Matched CDS', '4% due 32 Basis'],\n",
    " 'IRM': ['4 ⅞% due 29 Mat. Matched CDS', '4 ⅞% due 29 Basis'],\n",
    " 'ISPIM': ['6.184% due 34 Mat. Matched CDS', '6.184% due 34 Basis'],\n",
    " 'ITVLN': ['4 ¼% due 32 Mat. Matched CDS', '4 ¼% due 32 Basis'],\n",
    " 'CCK': ['4 ½% due 30 Mat. Matched CDS', '4 ½% due 30 Basis'],\n",
    " 'JNJ': ['6.95% due 29 Mat. Matched CDS', '6.95% due 29 Basis'],\n",
    " 'JPM': ['4.452% due 29 Mat. Matched CDS', '4.452% due 29 Basis'],\n",
    " 'KBH': ['4.8% due 29 Mat. Matched CDS', '4.8% due 29 Basis'],\n",
    " 'KERFP': ['1 ⅞% due 30 Mat. Matched CDS', '1 ⅞% due 30 Basis'],\n",
    " 'KMI': ['7.4% due 31 Mat. Matched CDS', '7.4% due 31 Basis'],\n",
    " 'KPN': ['0 ⅞% due 32 Mat. Matched CDS', '0 ⅞% due 32 Basis'],\n",
    " 'KR': ['7 ½% due 31 Mat. Matched CDS', '7 ½% due 31 Basis'],\n",
    " 'KSS': ['4 ⅝% due 31 Mat. Matched CDS', '4 ⅝% due 31 Basis'],\n",
    " 'L': ['6% due 35 Mat. Matched CDS', '6% due 35 Basis'],\n",
    " 'LEN': ['5.2% due 30 Mat. Matched CDS', '5.2% due 30 Basis'],\n",
    " 'LHAGR': ['4% due 30 Mat. Matched CDS', '4% due 30 Basis'],\n",
    " 'LLOYDS': ['3 ⅛% due 30 Mat. Matched CDS', '3 ⅛% due 30 Basis'],\n",
    " 'LMT': ['3.6% due 35 Mat. Matched CDS', '3.6% due 35 Basis'],\n",
    " 'LNC': ['3.05% due 30 Mat. Matched CDS', '3.05% due 30 Basis'],\n",
    " 'LOW': ['4 ½% due 30 Mat. Matched CDS', '4 ½% due 30 Basis'],\n",
    " 'LUV': ['2 ⅝% due 30 Mat. Matched CDS', '2 ⅝% due 30 Basis'],\n",
    " 'LW': ['4 ⅛% due 30 Mat. Matched CDS', '4 ⅛% due 30 Basis'],\n",
    " 'LXSGR': ['0 ⅝% due 29 Mat. Matched CDS', '0 ⅝% due 29 Basis'],\n",
    " 'BACRED': ['6 ½% due 33 Mat. Matched CDS', '6 ½% due 33 Basis'],\n",
    " 'MBGGR': ['2% due 31 Mat. Matched CDS', '2% due 31 Basis'],\n",
    " 'MBI': ['5.7% due 34 Mat. Matched CDS', '5.7% due 34 Basis'],\n",
    " 'MCFP': ['0 ⅜% due 31 Mat. Matched CDS', '0 ⅜% due 31 Basis'],\n",
    " 'MCD': ['2 ⅝% due 29 Mat. Matched CDS', '2 ⅝% due 29 Basis'],\n",
    " 'MCK': ['5.1% due 33 Mat. Matched CDS', '5.1% due 33 Basis'],\n",
    " 'MDC': ['3.85% due 30 Mat. Matched CDS', '3.85% due 30 Basis'],\n",
    " 'MDLZ': ['2 ¾% due 30 Mat. Matched CDS', '2 ¾% due 30 Basis'],\n",
    " 'MET': ['6 ½% due 32 Mat. Matched CDS', '6 ½% due 32 Basis'],\n",
    " 'MWDP': ['1% due 31 Mat. Matched CDS', '1% due 31 Basis'],\n",
    " 'MGM': ['6 ½% due 32 Mat. Matched CDS', '6 ½% due 32 Basis'],\n",
    " 'MO': ['3.4% due 30 Mat. Matched CDS', '3.4% due 30 Basis'],\n",
    " 'MPC': ['5.15% due 30 Mat. Matched CDS', '5.15% due 30 Basis'],\n",
    " 'MSI': ['2.3% due 30 Mat. Matched CDS', '2.3% due 30 Basis'],\n",
    " 'MTNA': ['3 ½% due 31 Mat. Matched CDS', '3 ½% due 31 Basis'],\n",
    " 'MUR': ['6% due 32 Mat. Matched CDS', '6% due 32 Basis'],\n",
    " 'NAVI': ['5 ⅝% due 33 Mat. Matched CDS', '5 ⅝% due 33 Basis'],\n",
    " 'NEM': ['5 ⅞% due 35 Mat. Matched CDS', '5 ⅞% due 35 Basis'],\n",
    " 'NEXIIM': ['3 ⅞% due 31 Mat. Matched CDS', '3 ⅞% due 31 Basis'],\n",
    " 'NFLX': ['5 ⅜% due 29 Mat. Matched CDS', '5 ⅜% due 29 Basis'],\n",
    " 'NGGLN': ['0.553% due 29 Mat. Matched CDS', '0.553% due 29 Basis'],\n",
    " 'NOC': ['4.4% due 30 Mat. Matched CDS', '4.4% due 30 Basis'],\n",
    " 'NOKIA': ['4 ⅜% due 31 Mat. Matched CDS', '4 ⅜% due 31 Basis'],\n",
    " 'NRG': ['3 ⅝% due 31 Mat. Matched CDS', '3 ⅝% due 31 Basis'],\n",
    " 'NSC': ['2.55% due 29 Mat. Matched CDS', '2.55% due 29 Basis'],\n",
    " 'COOP': ['7 ⅛% due 32 Mat. Matched CDS', '7 ⅛% due 32 Basis'],\n",
    " 'NWG': ['0.78% due 30 Mat. Matched CDS', '0.78% due 30 Basis'],\n",
    " 'NWL': ['6 ⅝% due 29 Mat. Matched CDS', '6 ⅝% due 29 Basis'],\n",
    " 'CPIPGR': ['1 ½% due 31 Mat. Matched CDS', '1 ½% due 31 Basis'],\n",
    " 'OLN': ['5% due 30 Mat. Matched CDS', '5% due 30 Basis'],\n",
    " 'OMC': ['2.45% due 30 Mat. Matched CDS', '2.45% due 30 Basis'],\n",
    " 'ORAFP': ['8 ⅛% due 33 Mat. Matched CDS', '8 ⅛% due 33 Basis'],\n",
    " 'ORCL': ['4.3% due 34 Mat. Matched CDS', '4.3% due 34 Basis'],\n",
    " 'OVV': ['8 ⅛% due 30 Mat. Matched CDS', '8 ⅛% due 30 Basis'],\n",
    " 'OXY': ['7 ½% due 31 Mat. Matched CDS', '7 ½% due 31 Basis'],\n",
    " 'PARA': ['7 ⅞% due 30 Mat. Matched CDS', '7 ⅞% due 30 Basis'],\n",
    " 'PFE': ['6 ½% due 34 Mat. Matched CDS', '6 ½% due 34 Basis'],\n",
    " 'PG': ['5.8% due 34 Mat. Matched CDS', '5.8% due 34 Basis'],\n",
    " 'PHIANA': ['2% due 30 Mat. Matched CDS', '2% due 30 Basis'],\n",
    " 'PHM': ['7 ⅞% due 32 Mat. Matched CDS', '7 ⅞% due 32 Basis'],\n",
    " 'PKG': ['3% due 29 Mat. Matched CDS', '3% due 29 Basis'],\n",
    " 'PNLNA': ['4 ¾% due 31 Mat. Matched CDS', '4 ¾% due 31 Basis'],\n",
    " 'POST': ['5 ½% due 29 Mat. Matched CDS', '5 ½% due 29 Basis'],\n",
    " 'PPCGA': ['4 ⅝% due 31 Mat. Matched CDS', '4 ⅝% due 31 Basis'],\n",
    " 'PRU': ['5 ¾% due 33 Mat. Matched CDS', '5 ¾% due 33 Basis'],\n",
    " 'R': ['6.6% due 33 Mat. Matched CDS', '6.6% due 33 Basis'],\n",
    " 'RABOBK': ['3 ⅞% due 32 Mat. Matched CDS', '3 ⅞% due 32 Basis'],\n",
    " 'RCL': ['6 ¼% due 32 Mat. Matched CDS', '6 ¼% due 32 Basis'],\n",
    " 'RIFP': ['0 ⅞% due 31 Mat. Matched CDS', '0 ⅞% due 31 Basis'],\n",
    " 'RTX': ['7 ½% due 29 Mat. Matched CDS', '7 ½% due 29 Basis'],\n",
    " 'RXLFP': ['5 ¼% due 30 Mat. Matched CDS', '5 ¼% due 30 Basis'],\n",
    " 'SEE': ['6 ⅞% due 33 Mat. Matched CDS', '6 ⅞% due 33 Basis'],\n",
    " 'SESGFP': ['4 ⅛% due 30 Mat. Matched CDS', '4 ⅛% due 30 Basis'],\n",
    " 'SGOFP': ['1 ⅞% due 31 Mat. Matched CDS', '1 ⅞% due 31 Basis'],\n",
    " 'SHAEFF': ['4 ½% due 30 Mat. Matched CDS', '4 ½% due 30 Basis'],\n",
    " 'SHBASS': ['3 ¼% due 33 Mat. Matched CDS', '3 ¼% due 33 Basis'],\n",
    " 'SHW': ['2.3% due 30 Mat. Matched CDS', '2.3% due 30 Basis'],\n",
    " 'SO': ['2.65% due 29 Mat. Matched CDS', '2.65% due 29 Basis'],\n",
    " 'SOLBBB': ['4 ¼% due 31 Mat. Matched CDS', '4 ¼% due 31 Basis'],\n",
    " 'SRE': ['5 ½% due 33 Mat. Matched CDS', '5 ½% due 33 Basis'],\n",
    " 'STANLN': ['1.2% due 31 Mat. Matched CDS', '1.2% due 31 Basis'],\n",
    " 'STERV': ['0 ⅝% due 30 Mat. Matched CDS', '0 ⅝% due 30 Basis'],\n",
    " 'STLA': ['1 ⅛% due 29 Mat. Matched CDS', '1 ⅛% due 29 Basis'],\n",
    " 'SVC': ['4 ⅜% due 30 Mat. Matched CDS', '4 ⅜% due 30 Basis'],\n",
    " 'SWEDA': ['3 ⅝% due 32 Mat. Matched CDS', '3 ⅝% due 32 Basis'],\n",
    " 'T': ['4 ½% due 35 Mat. Matched CDS', '4 ½% due 35 Basis'],\n",
    " 'TELNO': ['1 ¾% due 34 Mat. Matched CDS', '1 ¾% due 34 Basis'],\n",
    " 'TELIAS': ['3 ½% due 33 Mat. Matched CDS', '3 ½% due 33 Basis'],\n",
    " 'TGNA': ['5% due 29 Mat. Matched CDS', '5% due 29 Basis'],\n",
    " 'TGT': ['6.35% due 32 Mat. Matched CDS', '6.35% due 32 Basis'],\n",
    " 'THC': ['6 ⅞% due 31 Mat. Matched CDS', '6 ⅞% due 31 Basis'],\n",
    " 'TITIM': ['7 ¾% due 33 Mat. Matched CDS', '7 ¾% due 33 Basis'],\n",
    " 'TSN': ['4 ⅞% due 34 Mat. Matched CDS', '4 ⅞% due 34 Basis'],\n",
    " 'TUIGR': ['1.95% due 31 Mat. Matched CDS', '1.95% due 31 Basis'],\n",
    " 'UBS': ['0.65% due 29 Mat. Matched CDS', '0.65% due 29 Basis'],\n",
    " 'UCGIM': ['2.731% due 32 Mat. Matched CDS', '2.731% due 32 Basis'],\n",
    " 'URWFP': ['1 ⅜% due 30 Mat. Matched CDS', '1 ⅜% due 30 Basis'],\n",
    " 'UNANA': ['1 ⅝% due 33 Mat. Matched CDS', '1 ⅝% due 33 Basis'],\n",
    " 'UNH': ['4 ⅝% due 35 Mat. Matched CDS', '4 ⅝% due 35 Basis'],\n",
    " 'UNP': ['3 ⅜% due 35 Mat. Matched CDS', '3 ⅜% due 35 Basis'],\n",
    " 'VIEFP': ['6 ⅛% due 33 Mat. Matched CDS', '6 ⅛% due 33 Basis'],\n",
    " 'VLO': ['7 ½% due 32 Mat. Matched CDS', '7 ½% due 32 Basis'],\n",
    " 'VOD': ['2 ¾% due 34 Mat. Matched CDS', '2 ¾% due 34 Basis'],\n",
    " 'VOVCAB': ['4 ¾% due 30 Mat. Matched CDS', '4 ¾% due 30 Basis'],\n",
    " 'VZ': ['7 ¾% due 30 Mat. Matched CDS', '7 ¾% due 30 Basis'],\n",
    " 'IPGIM': ['4 ⅞% due 30 Mat. Matched CDS', '4 ⅞% due 30 Basis'],\n",
    " 'WHR': ['2.4% due 31 Mat. Matched CDS', '2.4% due 31 Basis'],\n",
    " 'WMB': ['7 ½% due 31 Mat. Matched CDS', '7 ½% due 31 Basis'],\n",
    " 'WMT': ['7.55% due 30 Mat. Matched CDS', '7.55% due 30 Basis'],\n",
    " 'WY': ['7 ⅜% due 32 Mat. Matched CDS', '7 ⅜% due 32 Basis'],\n",
    " 'YUM': ['4 ¾% due 30 Mat. Matched CDS', '4 ¾% due 30 Basis']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f93c4554-4e53-41a1-a886-ee07442f18fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67cbba4d92a74022b9353ad4b8ef788b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Issuer', options=('All', 'AALLN', 'ABIBB', 'ACAFP', 'ACFP'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "decc96f8bf224bdbb99014a01d61a313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='a', description='Horizontal Axis:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b9f8a96feeb450387740fc84afdcb35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='b', description='Vertical Axis:')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dafd2e1cfab46d4a098f7463c51880e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Submit', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454c160141d24954a3876533ffa81637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#################################### Changing order of names\n",
    "\n",
    "issuer = ['All'] + list(sorted(set([item.split(' ',1)[0] for item in options])))\n",
    "options1 = list(set([item.split(' ',1)[1] for item in options])) + ['US 5Y','US 7Y','US 10Y']\n",
    "\n",
    "df1 = pd.DataFrame()\n",
    "\n",
    "dropdown1 = Dropdown(options=issuer, description='Issuer')\n",
    "dropdown2 = Dropdown(options=options1, description='A:')\n",
    "dropdown3 = Dropdown(options=options1, description='B:')\n",
    "dropdown4 = Dropdown(options=options1, description='C:')\n",
    "dropdown5 = Dropdown(options=options1, description='D:')\n",
    "dropdown6 = Dropdown(options=options1, description='E:')\n",
    "dropdown7 = Dropdown(options=options1, description='F:')\n",
    "dropdown8 = Dropdown(options=options1, description='G:')\n",
    "dropdown9 = Dropdown(options=options1, description='H:')\n",
    "dropdown10 = Dropdown(options=options1, description='I:')\n",
    "dropdown11 = Dropdown(options=options1, description='J:')\n",
    "dropdown12 = Dropdown(options=options1, description='K:')\n",
    "dropdown13 = Dropdown(options=options1, description='L:')\n",
    "# dropdown14 = Dropdown(options=time, description='Time:')\n",
    "\n",
    "dropdown14 = widgets.FloatText(\n",
    "    value=5,\n",
    "    description='Years:',\n",
    "    step=0.01\n",
    ")\n",
    "\n",
    "row1 = HBox([dropdown1])\n",
    "row2 = HBox([dropdown2, dropdown3, dropdown4])\n",
    "row3 = HBox([dropdown5, dropdown6, dropdown7])\n",
    "row4 = HBox([dropdown8, dropdown9, dropdown10])\n",
    "row5 = HBox([dropdown11, dropdown12, dropdown13])\n",
    "row6 = HBox([dropdown14])\n",
    "\n",
    "dropdown_box = VBox([row1, row2, row3, row4, row5, row6])\n",
    "\n",
    "display(dropdown_box)\n",
    "\n",
    "expression_input1 = Text(description='Horizontal Axis:',value='a')\n",
    "expression_input2 = Text(description='Vertical Axis:',value='b')\n",
    "display(expression_input1)\n",
    "display(expression_input2)\n",
    "\n",
    "def get_values():\n",
    "    return dropdown1.value, dropdown2.value, dropdown3.value, \\\n",
    "    dropdown4.value, dropdown5.value, dropdown6.value, \\\n",
    "    dropdown7.value, dropdown8.value, dropdown9.value, \\\n",
    "    dropdown10.value, dropdown11.value, dropdown12.value, \\\n",
    "    dropdown13.value, dropdown14.value\n",
    "\n",
    "submit_button = Button(description=\"Submit\")\n",
    "display(submit_button)\n",
    "\n",
    "output = Output()\n",
    "display(output)\n",
    "\n",
    "def on_button_clicked(b):\n",
    "    with output:\n",
    "        global df\n",
    "        clear_output()\n",
    "        selected_values = get_values()\n",
    "        x = list(selected_values)\n",
    "        if x[0] != 'All':\n",
    "            x = [x[0]] + [f\"{x[0]} {item}\" for item in x[1:-1]] + [x[-1]]\n",
    "            selected_values = [x[0]] + \\\n",
    "            ['BBG ' + item.split(' ',1)[1] if (len(item.split(' '))>2 and item.split(' ')[1]=='US') else item for item in x[1:-1]]\\\n",
    "            +[x[-1]]\n",
    "            selected_values = tuple(selected_values)\n",
    "        \n",
    "        expression1 = expression_input1.value.upper()\n",
    "        expression2 = expression_input2.value.upper()\n",
    "        \n",
    "        col_map = {'A': selected_values[1], 'B': selected_values[2], 'C': selected_values[3], \n",
    "                   'D': selected_values[4], 'E': selected_values[5], 'F': selected_values[6],\n",
    "                   'G': selected_values[7], 'H': selected_values[8], 'I': selected_values[9], \n",
    "                   'J': selected_values[10], 'K': selected_values[11], 'L': selected_values[12]}\n",
    "        \n",
    "        for key, value in col_map.items():\n",
    "            expression1 = expression1.replace(key, key.lower())\n",
    "            expression2 = expression2.replace(key, key.lower())\n",
    "        \n",
    "        a, b, c, d, e, f, g, h, i, j, k, l = sp.symbols('a b c d e f g h i j k l')\n",
    "        expr1 = sp.sympify(expression1)\n",
    "        expr11 = sp.sympify(expression1)\n",
    "        expr2 = sp.sympify(expression2) if expression2 else None\n",
    "        expr21 = sp.sympify(expression2) if expression2 else None\n",
    "\n",
    "        cols_to_check = [col_map['A'], col_map['B'], col_map['C'], \\\n",
    "                         col_map['D'], col_map['E'], col_map['F'], \\\n",
    "                         col_map['G'], col_map['H'], col_map['I'], \\\n",
    "                         col_map['J'], col_map['K'], col_map['L'] ]\n",
    "        \n",
    "        df1 = df.copy()\n",
    "        df2 = df.copy()\n",
    "        \n",
    "        replacements = {\n",
    "            'A': selected_values[1], 'a': selected_values[1],\n",
    "            'B': selected_values[2], 'b': selected_values[2],\n",
    "            'C': selected_values[3], 'c': selected_values[3],\n",
    "            'D': selected_values[4], 'd': selected_values[4],\n",
    "            'E': selected_values[5], 'e': selected_values[5],\n",
    "            'F': selected_values[6], 'f': selected_values[6],\n",
    "            'G': selected_values[7], 'g': selected_values[7],\n",
    "            'H': selected_values[8], 'h': selected_values[8],\n",
    "            'I': selected_values[9], 'i': selected_values[9],\n",
    "            'J': selected_values[10], 'j': selected_values[10],\n",
    "            'K': selected_values[11], 'k': selected_values[11],\n",
    "            'L': selected_values[12], 'l': selected_values[12]\n",
    "        }\n",
    "\n",
    "        regex = re.compile(\"|\".join(re.escape(key) for key in replacements.keys()))\n",
    "        used_keys = set()\n",
    "        def substitution(match):\n",
    "            key = match.group(0)\n",
    "            used_keys.add(key)\n",
    "            return replacements[key]\n",
    "        \n",
    "        expr111 = regex.sub(substitution, str(expr11))\n",
    "        expr211 = regex.sub(substitution, str(expr21))\n",
    "        used_substitutions = list(used_keys)\n",
    "\n",
    "        used_substitutions = [replacements[item.upper()] for item in used_substitutions]\n",
    "\n",
    "        df1['Expression 1'] = df1.apply(lambda row: expr1.evalf(subs={\\\n",
    "            a: row[col_map['A']], b: row[col_map['B']], \n",
    "            c: row[col_map['C']], d: row[col_map['D']], \n",
    "            e: row[col_map['E']], f: row[col_map['F']],\n",
    "            g: row[col_map['G']], h: row[col_map['H']],\n",
    "            i: row[col_map['I']], j: row[col_map['J']], \n",
    "            k: row[col_map['K']], l: row[col_map['L']] }), axis=1).astype(float)       \n",
    "        df1['Expression 2'] = df1.apply(lambda row: expr2.evalf(subs={\\\n",
    "            a: row[col_map['A']], b: row[col_map['B']], \n",
    "            c: row[col_map['C']], d: row[col_map['D']], \n",
    "            e: row[col_map['E']], f: row[col_map['F']],\n",
    "            g: row[col_map['G']], h: row[col_map['H']],\n",
    "            i: row[col_map['I']], j: row[col_map['J']], \n",
    "            k: row[col_map['K']], l: row[col_map['L']] }) if expr2 else np.nan, axis=1).astype(float)\n",
    "\n",
    "        plot_exp1 = np.nan\n",
    "        plot_exp2 = np.nan\n",
    "        \n",
    "        if ('FWD' in expr111) and not ('FWD' in expr211) and expression2:\n",
    "            df2['Expression 2'] = df2.apply(lambda row: expr2.evalf(subs={\\\n",
    "            a: row[col_map['A']], b: row[col_map['B']], \n",
    "            c: row[col_map['C']], d: row[col_map['D']], \n",
    "            e: row[col_map['E']], f: row[col_map['F']],\n",
    "            g: row[col_map['G']], h: row[col_map['H']],\n",
    "            i: row[col_map['I']], j: row[col_map['J']], \n",
    "            k: row[col_map['K']], l: row[col_map['L']] }), axis=1).astype(float)\n",
    "            plot_exp2 = df2.iloc[-1]['Expression 2'].astype(float)\n",
    "        if ('FWD' in expr211) and not ('FWD' in expr111):\n",
    "            df2['Expression 1'] = df2.apply(lambda row: expr1.evalf(subs={\\\n",
    "            a: row[col_map['A']], b: row[col_map['B']], \n",
    "            c: row[col_map['C']], d: row[col_map['D']], \n",
    "            e: row[col_map['E']], f: row[col_map['F']],\n",
    "            g: row[col_map['G']], h: row[col_map['H']],\n",
    "            i: row[col_map['I']], j: row[col_map['J']], \n",
    "            k: row[col_map['K']], l: row[col_map['L']] }), axis=1).astype(float)\n",
    "            plot_exp1 = df2.iloc[-1]['Expression 1'].astype(float)\n",
    "\n",
    "        \n",
    "        def filter_df(dfx1, time_period):\n",
    "            dfx = dfx1.copy()\n",
    "            dfx.index=pd.to_datetime(dfx.index)\n",
    "            if time_period == 'All':\n",
    "                return dfx\n",
    "            else:\n",
    "                now = datetime.now()\n",
    "                # if time_period == '2Y':\n",
    "                #     start_date = now - timedelta(days=2*365)\n",
    "                # elif time_period == '1Y':\n",
    "                #     start_date = now - timedelta(days=365)\n",
    "                # elif time_period == '6M':\n",
    "                #     start_date = now - timedelta(days=6*30)\n",
    "                # elif time_period == '3M':\n",
    "                #     start_date = now - timedelta(days=3*30)\n",
    "                # return dfx[dfx.index.date >= start_date.date()]   \n",
    "                \n",
    "                start_date = now - timedelta(days=int(time_period*365))\n",
    "                return dfx[dfx.index.date >= start_date.date()] \n",
    "\n",
    "        def update_plot(plot_exp1,plot_exp2,df1,df2):\n",
    "            df1 = df1[used_substitutions + ['Expression 1','Expression 2']].dropna().copy()\n",
    "            # display(df1)\n",
    "            if expression2:\n",
    "                fig = make_subplots(rows=2, cols=1, shared_xaxes=False, \\\n",
    "                                    vertical_spacing=0.1, specs=[ [{\"secondary_y\":False}], [{\"secondary_y\":True}] ],\\\n",
    "                                   subplot_titles=(f'Scatter Plot from {df1.index[0].date()} to {df1.index[-1].date()}',\\\n",
    "                                                  f'{expr111}: {df1[df1.columns[-2]][-1]:.4f}   &   {expr211}: {df1[df1.columns[-1]][-1]:.4f}'))\n",
    "                \n",
    "                x_scatter = df1[df1.columns[-2]]\n",
    "                y_scatter = df1[df1.columns[-1]]\n",
    "\n",
    "                coeffs = np.polyfit(x_scatter,y_scatter,2)\n",
    "                polynomial = np.poly1d(coeffs)\n",
    "                x_poly=np.linspace(min(x_scatter),max(x_scatter),500)\n",
    "                y_poly=polynomial(x_poly)\n",
    "                y_pred = polynomial(x_scatter)\n",
    "                r2=r2_score(y_scatter,y_pred)\n",
    "                equation_text = f\"y = {coeffs[0]:.4f}*x² + {coeffs[1]:.4f}*x + {coeffs[2]:.4f}\"\n",
    "    \n",
    "                residuals = y_scatter-y_pred\n",
    "                res_sum=np.sum(residuals**2)\n",
    "                dof=len(x_scatter)-len(coeffs)\n",
    "                res_var = res_sum / dof\n",
    "                se = np.sqrt(res_var)\n",
    "                conf_upper = y_poly + 2 * se\n",
    "                conf_lower = y_poly - 2 * se\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=df1[df1.columns[-2]][-63:-1], y=df1[df1.columns[-1]][-63:-1], \\\n",
    "                                         name='< 3 months', mode='markers',marker=dict(color='green')), \\\n",
    "                              row=1,col=1,secondary_y=False)\n",
    "                fig.add_trace(go.Scatter(x=df1[df1.columns[-2]][-252:-63], y=df1[df1.columns[-1]][-252:-63], \\\n",
    "                                         name='> 3 months & < 1 year', mode='markers',marker=dict(color='blue')), \\\n",
    "                              row=1,col=1,secondary_y=False)\n",
    "                fig.add_trace(go.Scatter(x=df1[df1.columns[-2]][:-252], y=df1[df1.columns[-1]][:-252], \\\n",
    "                                         name='> 1 year', mode='markers',marker=dict(color='gray')), \\\n",
    "                              row=1,col=1,secondary_y=False)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=[df1[df1.columns[-2]].iloc[-1]], y=[df1[df1.columns[-1]].iloc[-1]], \\\n",
    "                                         name=f'Value as of {df1.index[-1].date()}', mode='markers',marker=dict(color='red',size=10),\\\n",
    "                                         showlegend=True), row=1,col=1,secondary_y=False)      \n",
    "                fig.add_trace(go.Scatter(x=x_poly, y=y_poly, \\\n",
    "                                         name=f'Polynomial Fit<br>R² = {r2:.3f}<br>{equation_text}', \\\n",
    "                                         mode='lines', line=dict(color='orange'),\n",
    "                                         showlegend=True), row=1,col=1,secondary_y=False) \n",
    "               \n",
    "                fig.add_trace(go.Scatter(x=x_poly, y=conf_upper, \\\n",
    "                                         name='Upper Confidence Band', \\\n",
    "                                         mode='lines', line=dict(color='orange',dash='dash'),\n",
    "                                         showlegend=True), row=1,col=1,secondary_y=False) \n",
    "                fig.add_trace(go.Scatter(x=x_poly, y=conf_lower, \\\n",
    "                                         name='Lower Confidence Band', fill='tonexty',\\\n",
    "                                         fillcolor='rgba(255,165,0,0.15)',\n",
    "                                         mode='lines', line=dict(color='orange',dash='dash'),\n",
    "                                         showlegend=True), row=1,col=1,secondary_y=False) \n",
    "                \n",
    "                if ('FWD' in expr111) and not ('FWD' in expr211):\n",
    "                    # display(f\"Condition1\")\n",
    "                    plot_exp2 = [plot_exp2] * len(df1[df1.columns[-2]])\n",
    "                    fig.add_trace(go.Scatter(x=df1[df1.columns[-2]], y=plot_exp2, mode='lines',\\\n",
    "                     line=dict(color='red',width=1),name = f'{expr211} on {df2.index[-1]} was {plot_exp2[0]}'), \\\n",
    "                      row=1,col=1,secondary_y=False)\n",
    "\n",
    "                if ('FWD' in expr211) and not ('FWD' in expr111):\n",
    "                    # display(f\"Condition2\")\n",
    "                    plot_exp1 = [plot_exp1] * len(df1[df1.columns[-1]])\n",
    "                    fig.add_trace(go.Scatter(x=plot_exp1, y=df1[df1.columns[-1]], mode='lines',\\\n",
    "                     line=dict(color='red',width=1), name = f'{expr111} on {df2.index[-1]} was {plot_exp1[0]}'), \\\n",
    "                      row=1,col=1,secondary_y=False)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=df1.index, y=df1[df1.columns[-2]], name=expr111,\\\n",
    "                         line=dict(color='blue')), row=2,col=1,secondary_y=False)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=[df1.index[0], df1.index[-1]], \\\n",
    "                 y=[df1[df1.columns[-2]][-1], df1[df1.columns[-2]][-1]], \\\n",
    "                 mode='lines', line=dict(dash='dash', color='blue'), \\\n",
    "                 name=f'Recent value of {expr111} is {df1[df1.columns[-2]][-1]}'),row=2,col=1,secondary_y=False)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=df1.index, y=df1[df1.columns[-1]], \\\n",
    "                                     name=expr211, line=dict(color='green')),\\\n",
    "                                      row=2,col=1, secondary_y=True)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=[df1.index[0], df1.index[-1]], \\\n",
    "                 y=[df1[df1.columns[-1]][-1], df1[df1.columns[-1]][-1]], \\\n",
    "                 mode='lines', line=dict(dash='dash', color='green'), \\\n",
    "                 name=f'Recent value of {expr211} is {df1[df1.columns[-1]][-1]}'),row=2,col=1, secondary_y=True)\n",
    "                \n",
    "                fig.update_layout(\n",
    "                hovermode='x unified',\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white',\n",
    "                legend=dict(orientation=\"h\",yanchor=\"bottom\",xanchor=\"center\",x=0.5,y=1.05),\n",
    "                height=1900,\n",
    "                width=1100)\n",
    "\n",
    "            else:\n",
    "                fig = make_subplots(rows=1, cols=1, shared_xaxes=False, \\\n",
    "                                    vertical_spacing=0.1, subplot_titles=(f'{expr111}: {df1[df1.columns[-2]][-1]:.4f}'))\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=df1.index, y=df1[df1.columns[-2]], name=expr111,\\\n",
    "                         line=dict(color='blue')), row=1,col=1)\n",
    "                \n",
    "                fig.add_trace(go.Scatter(x=[df1.index[0], df1.index[-1]], \\\n",
    "                 y=[df1[df1.columns[-2]][-1], df1[df1.columns[-2]][-1]], \\\n",
    "                 mode='lines', line=dict(dash='dash', color='blue'), \\\n",
    "                 name=f'Recent value of {expr111} is {df1[df1.columns[-2]][-1]}'))\n",
    "\n",
    "                fig.update_layout(\n",
    "                yaxis=dict(zeroline=True, zerolinecolor='black'),\n",
    "                hovermode='x unified',\n",
    "                plot_bgcolor='white',\n",
    "                paper_bgcolor='white',\n",
    "                legend=dict(orientation=\"h\",yanchor=\"bottom\",xanchor=\"center\",x=0.5,y=1.05),\n",
    "                height=800,\n",
    "                width=1100)\n",
    "\n",
    "            def split_label(label,n):\n",
    "                return '<br>'.join([label[i:i+n] for i in range(0,len(label),n)])\n",
    "\n",
    "            label1 = split_label(expr111,38)\n",
    "            label2 = split_label(expr211,38)\n",
    "          \n",
    "            if expression2:\n",
    "                fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True,\\\n",
    "                                 row=1,col=1,title=label1, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "                fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True,\\\n",
    "                                 row=1,col=1, title=label2, secondary_y=False, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "                fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title='Date', row=2, col=1, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "                fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title=label1, side='left', row=2,col=1, secondary_y=False, \\\n",
    "                                 showgrid=True, gridcolor='LightGrey',gridwidth=1, title_font = dict(color='blue'))\n",
    "                fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title=label2, side='right', row=2,col=1, secondary_y=True, title_font = dict(color='green'))\n",
    "            else:\n",
    "                fig.update_xaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title='Date', row=1, col=1, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "                fig.update_yaxes(showline=True, linewidth=2, linecolor='black', mirror=True, \\\n",
    "                                 title=label1, side='left', row=1,col=1, secondary_y=False, showgrid=True, gridcolor='LightGrey',gridwidth=1)\n",
    "            fig.show()\n",
    "        \n",
    "        df1 = filter_df(df1, selected_values[-1]).copy() #Time goes here\n",
    "        interact(update_plot(plot_exp1,plot_exp2,df1,df2))\n",
    "\n",
    "submit_button.on_click(on_button_clicked)\n",
    "\n",
    "def update_dropdowns(*args):\n",
    "    selected_issuer = dropdown1.value\n",
    "    if selected_issuer:\n",
    "        for i in range(2, 14):\n",
    "            dropdown = globals().get(f'dropdown{i}')\n",
    "            if dropdown:\n",
    "                if selected_issuer != 'All':\n",
    "                    x = list([item.split(' ', 1)[1] for item in options if item.startswith(selected_issuer)]) + ['US 5Y','US 7Y','US 10Y']\n",
    "                else:\n",
    "                    x = options\n",
    "                dropdown.options = x\n",
    "        if selected_issuer in list(default_values_dict.keys()):\n",
    "            globals().get(f'dropdown2').value = default_values_dict[selected_issuer][0]\n",
    "            globals().get(f'dropdown3').value = default_values_dict[selected_issuer][1]\n",
    "\n",
    "dropdown1.observe(update_dropdowns, names='value')\n",
    "update_dropdowns()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
